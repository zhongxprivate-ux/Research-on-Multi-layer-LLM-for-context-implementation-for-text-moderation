{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99b2115f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zhongxian\\AppData\\Local\\Programs\\Python\\Python311\\python.exe\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#I had trouble loading python versions on my desktop and this is usesd so i can check whether the correct path is used for the interperter \n",
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5aacc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing needed for parsing the hatexplain dataset correctly. \n",
    "import numpy as np\n",
    "import json\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#loading hatexplain\n",
    "with open(\"HateXplain.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    hatexplain = json.load(f)\n",
    "\n",
    "#For Print Checking\n",
    "#print(len(hatexplain))\n",
    "\n",
    "#This areas is to check out the dict is layed out.\n",
    "first_key = list(hatexplain.keys())[0]\n",
    "first_sample = hatexplain[first_key]\n",
    "#print(first_sample.keys())\n",
    "\n",
    "#Initialising an empty array\n",
    "samples = []\n",
    "\n",
    "#Loop that extracts the data and appends it to samples\n",
    "for post_id, post_data in hatexplain.items():\n",
    "    text = \" \".join(post_data[\"post_tokens\"])\n",
    "\n",
    "    #Splitting the data into X and Y along with getting the most common data label to be used.\n",
    "    labels = [ann[\"label\"] for ann in post_data[\"annotators\"]]\n",
    "    most_common_label = Counter(labels).most_common(1)[0][0]\n",
    "\n",
    "    samples.append({\"text\": text, \"label\": most_common_label})\n",
    "\n",
    "#For Print Checking\n",
    "#print(samples[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03acfbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the labels into X and Y and then splitting the data for training\n",
    "\n",
    "texts = [s[\"text\"] for s in samples]\n",
    "nonconverted_labels = [s[\"label\"] for s in samples]\n",
    "\n",
    "#converting labels from string to numbers\n",
    "\n",
    "converting_map = {\n",
    "    \"normal\": 0,\n",
    "    \"offensive\": 1,\n",
    "    \"hatespeech\": 2 \n",
    "}\n",
    "\n",
    "labels = [converting_map[label] for label in nonconverted_labels]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.05, random_state=4)\n",
    "\n",
    "#for i in range(len(X_test)):\n",
    "    #print(f\" Text: {X_test[i]}, Label: {y_test[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87516c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the ollama library\n",
    "import ollama\n",
    "\n",
    "#Connect the ollama applications to jupyter.\n",
    "client = ollama.Client()\n",
    "\n",
    "# This is just so changing the data and what runs through it to be easier to change\n",
    "data_texts = X_test\n",
    "data_labels = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f54f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 2 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 3 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 4 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 5 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 6 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Sample 7 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Sample 8 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 9 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 10 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 11 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 12 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 13 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Sample 14 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 15 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 16 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 17 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 18 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 19 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 20 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 21 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 22 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 23 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 24 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 25 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Sample 26 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 27 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 28 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Sample 29 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 30 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 31 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 32 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 33 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Sample 34 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 35 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 36 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 37 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 38 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 39 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 40 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 41 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 42 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 43 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 44 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 45 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 46 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 47 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 48 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Sample 49 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Sample 50 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 51 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Sample 52 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Sample 53 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 54 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 55 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 56 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 57 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 58 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 59 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 60 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 61 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 62 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 63 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 64 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Sample 65 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 66 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Sample 67 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 68 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 69 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 70 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 71 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 72 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 73 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Sample 74 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 75 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 76 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 77 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 78 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 79 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 80 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Sample 81 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 82 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 83 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 84 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 85 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 86 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 87 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 88 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 89 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Sample 90 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 91 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Sample 92 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 93 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Sample 94 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Sample 95 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Sample 96 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 97 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 98 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 99 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 100 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 101 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 102 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 103 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 104 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 105 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 106 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Sample 107 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 108 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 109 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 110 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 111 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 112 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Sample 113 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 114 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 115 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 116 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 117 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Sample 118 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 119 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 120 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 121 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 122 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 123 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 124 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 125 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 126 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 127 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 128 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 129 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Sample 130 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 131 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Sample 132 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 133 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 134 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 135 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 136 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 137 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 138 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 139 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Sample 140 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 141 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 142 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 143 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 144 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 145 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 146 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Sample 147 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 148 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Sample 149 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 150 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 151 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 152 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Sample 153 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 154 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 155 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Sample 156 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Sample 157 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 158 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 159 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 160 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 161 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Sample 162 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 163 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 164 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 165 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 166 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 167 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 168 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 169 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 170 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 171 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 172 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 173 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 174 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Sample 175 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 176 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 177 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 178 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 179 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 180 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 181 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 182 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 183 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 184 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 185 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 186 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 187 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 188 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 189 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 190 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 191 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 192 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 193 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 194 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 195 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Sample 196 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Sample 197 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 198 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Sample 199 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Sample 200 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 201 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 202 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 203 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 204 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 205 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 206 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 207 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 208 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 209 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 210 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Sample 211 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 212 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 213 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 214 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 215 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 216 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 217 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 218 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Sample 219 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 220 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 221 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 222 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 223 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 224 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 225 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 226 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 227 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Sample 228 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 229 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 230 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 231 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 232 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 233 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 234 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 235 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 236 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 237 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 238 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 239 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 240 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 241 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 242 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 243 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 244 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 245 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 246 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 247 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 248 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 249 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 250 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Sample 251 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 252 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 253 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 254 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 255 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 256 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 257 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 258 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Sample 259 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 260 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 261 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Sample 262 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 263 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 264 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 265 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 266 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 267 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 268 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 269 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 270 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 271 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Sample 272 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Sample 273 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 274 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 275 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 276 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 277 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 278 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 279 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Sample 280 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 281 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 282 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Sample 283 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Sample 284 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Sample 285 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Sample 286 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 287 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 288 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 289 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 290 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Sample 291 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 292 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 293 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 294 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 295 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 296 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 297 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 298 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 299 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 300 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 301 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 302 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 303 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 304 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 305 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 306 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 307 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 308 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 309 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 310 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 311 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 312 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 313 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 314 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 315 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 316 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 317 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 318 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 319 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 320 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 321 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 322 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 323 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Sample 324 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 325 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 326 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 327 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 328 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 329 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 330 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 331 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 332 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 333 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Sample 334 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 335 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 336 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 337 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 338 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 339 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Sample 340 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 341 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 342 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 343 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 344 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 345 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 346 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 347 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Sample 348 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 349 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 350 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 351 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 352 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 353 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 354 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 355 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 356 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 357 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 358 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 359 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 360 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 361 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 362 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Sample 363 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 364 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 365 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 366 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 367 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 368 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 369 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Sample 370 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 371 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 372 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 373 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 374 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 375 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 376 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 377 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Sample 378 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 379 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Sample 380 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 381 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 382 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 383 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 384 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 385 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 386 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 387 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 388 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Sample 389 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 390 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 391 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 392 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 393 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 394 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 395 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 396 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Sample 397 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 398 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 399 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 400 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Sample 401 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Sample 402 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 403 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 404 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 405 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 406 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 407 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 408 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 409 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 410 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 411 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 412 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Sample 413 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Sample 414 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 415 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 416 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Sample 417 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 418 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 419 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 420 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 421 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 422 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 423 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 424 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 425 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 426 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 427 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Sample 428 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 429 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 430 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 431 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 432 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Sample 433 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 434 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 435 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 436 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Sample 437 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 438 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 439 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 440 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 441 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 442 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 443 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 444 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Sample 445 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 446 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 447 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 448 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 449 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 450 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 451 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 452 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 453 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 454 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 455 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Sample 456 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 457 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 458 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 459 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 460 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 461 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 462 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 463 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 464 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 465 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Sample 466 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 467 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 468 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 469 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 470 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 471 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Sample 472 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 473 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 474 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 475 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Sample 476 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 477 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 478 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 479 / 1008 : Prediction = 0  Saved:  0 Correct label:  2\n",
      "Sample 480 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 481 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 482 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 483 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 484 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 485 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 486 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 487 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Sample 488 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 489 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Sample 490 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 491 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 492 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 493 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 494 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 495 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 496 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 497 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 498 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 499 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 500 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 501 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 502 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 503 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 504 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 505 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Sample 506 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 507 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 508 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 509 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 510 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 511 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 512 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 513 / 1008 : Prediction = 0  Saved:  0 Correct label:  2\n",
      "Sample 514 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 515 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 516 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 517 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 518 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 519 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 520 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 521 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 522 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 523 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 524 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Sample 525 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 526 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Sample 527 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 528 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 529 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 530 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 531 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 532 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 533 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 534 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 535 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 536 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 537 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 538 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 539 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 540 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 541 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Sample 542 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 543 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 544 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 545 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 546 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 547 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 548 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 549 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 550 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 551 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 552 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 553 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 554 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Sample 555 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Sample 556 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Sample 557 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 558 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 559 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 560 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 561 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Sample 562 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 563 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Sample 564 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 565 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Sample 566 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n"
     ]
    }
   ],
   "source": [
    "#This is the zero-shot prompt set up.\n",
    "\n",
    "#import libraries\n",
    "import re\n",
    "\n",
    "#Empty array for LLM predictions\n",
    "y_pred = []\n",
    "\n",
    "\n",
    "#For loop for running the prompt through HateXplain\n",
    "for i in range(len(data_texts)):\n",
    "    \n",
    "    #The prompt variable. which i send data_text to be ran through.\n",
    "    prompt = f\"\"\": â€œReview the provided statement and classify it as 'Hatespeech' or 'Offensive' or 'Normal'\n",
    "\n",
    "    2 = Hatespeech (Offensive text that targets protected groups)\n",
    "    1 = Offensive (rude but not hate speech)\n",
    "    0 = Normal\n",
    "\n",
    "    Text: {data_texts[i]}\n",
    "\n",
    "    Output (number only):\n",
    "    \"\"\"\n",
    "\n",
    "    #Running the respornse\n",
    "    response = ollama.chat(\n",
    "        model=\"mistral\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",  # use \"user\", not \"Text moderator\"\n",
    "                \"content\": prompt\n",
    "            },\n",
    "        ],\n",
    "\n",
    "        #Setting the options to be similar to the ones seen on paper. The only difference is setting the seed so it can be later reproduced\n",
    "        options = {\n",
    "            \"temperature\": 0.1,\n",
    "            \"top_p\": 0.95,\n",
    "            \"num_ctx\": 1024,      \n",
    "            \"num_predict\": 256,        \n",
    "            \"repeat_penalty\": 1.1,    \n",
    "            \"seed\": 42,                \n",
    "        }\n",
    "    )\n",
    "    \n",
    "    #Getting the response from the model\n",
    "    prediction = response.message.content\n",
    "\n",
    "    #Since models outputs vary. By using re.search i can search for the number to gain the prediction within the output.\n",
    "    match = re.search(r'[012]', prediction)\n",
    "    if match:\n",
    "        pred_num = int(match.group())\n",
    "    else:\n",
    "        pred_num = -1 \n",
    "    y_pred.append(pred_num)\n",
    "\n",
    "    #There was a logic error that caused y_pred to be saved differently. This is to see whether thing are saved correctly\n",
    "    #print(\"Text: \", data_texts[i])\n",
    "    print(\"Sample\", i+1, \"/\",  len(data_texts), \": Prediction =\", pred_num, \" Saved: \", y_pred[i], \"Correct label: \", data_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e3741c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.396\n",
      "Precision: 0.575\n",
      "Recall: 0.575\n",
      "F1 score: 0.575\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Importing libraries\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#print(\"text: \", data_texts[1])\n",
    "#print(\"y_pred: \", y_pred[1])\n",
    "#print(\"y_true: \", data_labels[1])\n",
    "\n",
    "#The following is printing out the results to be analysed.\n",
    "acc = accuracy_score(data_labels, y_pred)\n",
    "precision, recall, f1, support = precision_recall_fscore_support(y_true=data_labels, y_pred=y_pred, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {acc:.3f}\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall: {recall:.3f}\")\n",
    "print(f\"F1 score: {f1:.3f}\")\n",
    "\n",
    "con_matrix = confusion_matrix(data_labels, y_pred)\n",
    "disp = ConfusionMatrixDisplay(con_matrix, display_labels=['Normal', 'Offensive', 'Hatespeech'])\n",
    "disp.plot()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57679939",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_texts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m y_pred_after_prompt_eng = []\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m#For loop for running the prompt through HateXplain\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mdata_texts\u001b[49m)):\n\u001b[32m     11\u001b[39m \n\u001b[32m     12\u001b[39m     \u001b[38;5;66;03m#The prompt variable. which i send data_text to be ran through.\u001b[39;00m\n\u001b[32m     13\u001b[39m     prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33m: â€œReview the provided statement and classify it as \u001b[39m\u001b[33m'\u001b[39m\u001b[33mHatespeech\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33mOffensive\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33mNormal\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     14\u001b[39m \n\u001b[32m     15\u001b[39m \u001b[33m    2 = Hatespeech (Text that not only mention but also involves devaluation of protected groups linking to gender, race, sexuality, religion and disability)\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     21\u001b[39m \u001b[33m    Output (number only):\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[33m    \u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     24\u001b[39m     \u001b[38;5;66;03m#Running the respornse\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'data_texts' is not defined"
     ]
    }
   ],
   "source": [
    "#These next couple cells are for prompt-tuning with few shot and chain of thought. Just using a seperate part so i can see results and compare with the previous.\n",
    "\n",
    "#Cell 1# Aligning the definitions of the labels to be understood similiarly to how HateXplains precieve the label.\n",
    "import re\n",
    "\n",
    "#Empty array for LLM predictions. This is reran again.\n",
    "y_pred_after_prompt_eng = []\n",
    "\n",
    "#For loop for running the prompt through HateXplain\n",
    "for i in range(len(data_texts)):\n",
    "    \n",
    "    #The prompt variable. which i send data_text to be ran through.\n",
    "    prompt = f\"\"\": â€œReview the provided statement and classify it as 'Hatespeech' or 'Offensive' or 'Normal'\n",
    "\n",
    "    2 = Hatespeech (Text that not only mention but also involves devaluation of protected groups linking to gender, race, sexuality, religion and disability)\n",
    "    1 = Offensive (Can be interpreted as hatespeech but it's main intent doesn't not involve devaluing or directing an attack on protected groups)\n",
    "    0 = Normal (Text that can't be interpreted as hatespeech)\n",
    "\n",
    "    Text: {data_texts[i]}\n",
    "\n",
    "    Output (number only):\n",
    "    \"\"\"\n",
    "\n",
    "    #Running the respornse\n",
    "    response = ollama.chat(\n",
    "        model=\"mistral\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",  # use \"user\", not \"Text moderator\"\n",
    "                \"content\": prompt\n",
    "            },\n",
    "        ],\n",
    "\n",
    "        #Setting the options to be similar to the ones seen on paper. The only difference is setting the seed so it can be later reproduced\n",
    "        options = {\n",
    "            \"temperature\": 0.1,\n",
    "            \"top_p\": 0.95,\n",
    "            \"num_ctx\": 1024,      \n",
    "            \"num_predict\": 256,        \n",
    "            \"repeat_penalty\": 1.1,    \n",
    "            \"seed\": 42,                \n",
    "        }\n",
    "    )\n",
    "    \n",
    "    #Getting the response from the model\n",
    "    prediction = response.message.content\n",
    "\n",
    "    #Since models outputs vary. By using re.search i can search for the number to gain the prediction within the output.\n",
    "    match = re.search(r'[012]', prediction)\n",
    "    if match:\n",
    "        pred_num = int(match.group())\n",
    "    else:\n",
    "        pred_num = -1 \n",
    "    y_pred_after_prompt_eng.append(pred_num)\n",
    "\n",
    "    #There was a logic error that caused y_pred to be saved differently. This is to see whether thing are saved correctly\n",
    "    print(\"Response: \", prediction)\n",
    "    print(\"Text: \", data_texts[i])\n",
    "    print(\"Sample\", i+1, \"/\",  len(data_texts), \": Prediction =\", pred_num, \" Saved: \", y_pred_after_prompt_eng[i], \"Correct label: \", data_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4918fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.467\n",
      "Precision: 0.577\n",
      "Recall: 0.577\n",
      "F1 score: 0.577\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Importing libraries\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#The following is printing out the results to be analysed.\n",
    "acc = accuracy_score(data_labels, y_pred_after_prompt_eng)\n",
    "precision, recall, f1, support = precision_recall_fscore_support(y_true=data_labels, y_pred=y_pred_after_prompt_eng, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {acc:.3f}\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall: {recall:.3f}\")\n",
    "print(f\"F1 score: {f1:.3f}\")\n",
    "\n",
    "con_matrix = confusion_matrix(data_labels, y_pred_after_prompt_eng)\n",
    "disp = ConfusionMatrixDisplay(con_matrix, display_labels=['Normal', 'Offensive', 'Hatespeech'])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd065ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  <user> i dont like that ur not gay\n",
      "Sample 1 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  in spoons three fishes table <number> dm for orders spoons slave fin sub spoons bitch findom spoons sub\n",
      "Sample 2 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  the women of my grammas generation were pretty cool too my gramma punched a pregnant spic in the belly at a motley crew show in the <number> ðŸ¤”\n",
      "Sample 3 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> she is being threatened with actual violence not the pretend violence you are worried about\n",
      "Sample 4 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  if the authorities say it was a woman shooter we know for certain that it was black moslem male\n",
      "Sample 5 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  dude i fucking hate being the ugly friend\n",
      "Sample 6 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> <user> <user> <user> <user> <user> amazing to see i love it because in my neck of the redneck world the people are oddly sheltered in <number>\n",
      "Sample 7 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  even when queers do it only a show henry makow proves that queers are like dogs\n",
      "Sample 8 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  rt usahotlips i never thought i would see the day when liberals would have so much contempt for one man their country that they would actually cheer for defend ms <number> north korea iran illegal immigrants deep state thursdaythought maga tds\n",
      "Sample 9 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> is you are jihadi who is funded by my money if not than who hell you are trying to say\n",
      "Sample 10 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  well the french are arabs\n",
      "Sample 11 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  if you can not afford kids do not have em says the jewed christcuck while supporting republicans who offshore jobs and import immigrants to drive down wages for decades well people could not afford them and they are not having them so much for family values\n",
      "Sample 12 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  no calls for violence are not free speech and should never be tolerated\n",
      "Sample 13 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  proof i mean i am on mobile and cant yank up the proof for me but if you stick around i can bash your head in with reality hitler loved sand niggers too he even gave them their own ss division the 1 3 th i think\n",
      "Sample 14 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  your memes are shit you can only call someone a kike and that it\n",
      "Sample 15 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  do not worry about shitposting worry about white people who can not bring themselves to fight back\n",
      "Sample 16 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  london has a muzzie goathumper for mayor sad dick khan they have a terrible moron for pm theresa dis may they have had muzzies cut the heads off of people in their streets soon big ben will be a minaret and buckingham palace will be a mosque\n",
      "Sample 17 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  male feminists white knights secretly think women are retarded so it makes sense to infantilize their choices\n",
      "Sample 18 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  and a girl who exposed multiple vegas shooters was killed a couple days later these evil faggots kill everyone ðŸ˜  so freeing to use that word here ðŸ˜„\n",
      "Sample 19 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  reminder in a significant number of muslim ran takeouts in the uk children were and are still raped upstairs on a daily basis police know teachers know doctors know pharmacists know this is why uk is facing it own tiananmen square moment and banning journos for life britanistan\n",
      "Sample 20 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  <user> <user> rohingias are not refugees they are illegal infiltrators and a serious security threat\n",
      "Sample 21 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  o this white gurl liked chocolate dick\n",
      "Sample 22 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  can not wait to see the raghead after a heart attack with his newly found free healthcare turn down a pig heart valve to stay alive would not be surprised if we have halal certified chicken valves for them instead\n",
      "Sample 23 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  eu will not stop it western govs will not stop it there is but one course for europe now revolution war nothing else will stop mass invasion of moslem barbarians moslems are the problem\n",
      "Sample 24 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  fucking hate bts stupid band intensifies\n",
      "Sample 25 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <number> pres rchd spencer vice pres <user> hatch plan <number> get jews blacks <number> leave the country universal basic income creates massive hyperinflation the poor the jews move next up <number> our team getting gays <number> leave after they have gentrified all the ol black ghettos altrightfanfiction\n",
      "Sample 26 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  kirishima best boy president of the respecting women club top <number> feminists of all time defender of lesbians sweet baby kirishima\n",
      "Sample 27 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  increasingly the conversation is ta nehsi coates or whoever saying that the ghetto just seems to have more crime because the police do not arrest white kids and nobody willing to point out that this is obviously baloney\n",
      "Sample 28 / 1008 : Prediction = 0  Saved:  0 Correct label:  2\n",
      "Text:  do not get me wrong i like alt right podcasts and content creators but whites need lobby groups economic cooperatives and white focused orgs of all kinds to regain control of their own nations not just more content i just wish i knew where to begin helping create these\n",
      "Sample 29 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  ben shapiro a typical lying kike trying to represent the alt right ethical jews have precedence over non jews for getting an israeli citizenship he lying as is typical of his race\n",
      "Sample 30 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> i will drive my white ass down to dallas from new york and stand right there with you justice botham jean amber guyger murder trial life in prison\n",
      "Sample 31 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  is that chief alinskyite chitownboystownbathhouseboi rahm emmanuel looks sounds like that kike\n",
      "Sample 32 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  <user> nice burner account nobody names their kid edwina unless they are georgia trailer trash\n",
      "Sample 33 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  running gas on this white ass roof ain t it ðŸ¥µ i am too dark for this\n",
      "Sample 34 / 1008 : Prediction = -1  Saved:  -1 Correct label:  0\n",
      "Text:  meek and mild c mon don call him what he is a faggot\n",
      "Sample 35 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  who asked the quisling who asked the head of the obama clinton crime syndicate who asked the race baiter who asked the muslim terrorist supporting scumbag\n",
      "Sample 36 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  his father and uncle came to the uk in the <number> i was sexually assaulted by <number> paki muslim men in the <number> just walking down the street their wives and young children walking with them was that your father and uncle sajid javid eh\n",
      "Sample 37 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  i understand nazi faggot code you are calling it quits but we both knew you would fag out lol\n",
      "Sample 38 / 1008 : Prediction = -1  Saved:  -1 Correct label:  2\n",
      "Text:  white girl refrigerator i hate you\n",
      "Sample 39 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  not just a nigger an immigrant nigger so the church got extra culturally enriched by vibrant diversity ðŸ˜‘\n",
      "Sample 40 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  yeah it was much more difficult to me because i had active blinders on i d absorbed a lot of propaganda that ashkenazis were gentle musician artist nobilids raped by nazi holocaust literally from my mother milk plus my family has zero contact with actual talmudic kikes so i was jew blind\n",
      "Sample 41 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  train guy as in the driver this is what happens when your base is mentally retarded and has mental issues\n",
      "Sample 42 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  has this nigger looked in the mirror lately\n",
      "Sample 43 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  only autistic faggots think a thing only exists if it has <number> crisp borders do you not think we know what blue is lol what a fag\n",
      "Sample 44 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  the muslim invitation\n",
      "Sample 45 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  jus fucked this white bitch cuz fuck slavery and all that racist shit ðŸ¤£ ðŸ¤£ ðŸ˜Ž ðŸ¤¦ ðŸ» â€ â™‚ï¸ ðŸ˜ˆ\n",
      "Sample 46 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  agreed i am so tired of politicians acting like we cant ban it fuck them when they stop bombing our buildings killing our soilders raping our women begging us <number> save them from each other then we can talk\n",
      "Sample 47 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  only those who already had high iqs would have been able to move to winter lands not that the winter made them intelligent really retarded logic from those who spread the theory john is talking about\n",
      "Sample 48 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  and black olives gguk ðŸ˜‚\n",
      "Sample 49 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  how is embracing known enemies enemies that have sworn to destroy this country and replace it with a muslim caliphate not treason\n",
      "Sample 50 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  i do not think founding fathers meant islam or budhism\n",
      "Sample 51 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  me i hate nazis someone hate hate is such a strong word me uh yeah\n",
      "Sample 52 / 1008 : Prediction = 0  Saved:  0 Correct label:  2\n",
      "Text:  kill yourself nigger fucker\n",
      "Sample 53 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  check out the rockfish report on niggermania they keep up to date on all the bobbing coons nationwide\n",
      "Sample 54 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  lol <user> what happened the owner of this website pew tube has banned you temporarily from accessing this website i dindunuffin\n",
      "Sample 55 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  ðŸ‘ more offensive words pocontas thug goatfucker rocketman illegal merry christmas crackitute pizzagate\n",
      "Sample 56 / 1008 : Prediction = -1  Saved:  -1 Correct label:  2\n",
      "Text:  from when immigrants did not rape shoot women and then bomb shit charlie chaplin in the immigrant <number>\n",
      "Sample 57 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  southafrica is proof whites built a beautiful and safe country the us is proof look at auto industry detroit look at steel mill towns look at every nice neighborhood and city turn to trashed out ghettos when blacks move in truth is not racist its truth\n",
      "Sample 58 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  great way to get rid of a retarded child\n",
      "Sample 59 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  jewelry kike perverts gassed me on twitter and preventing fake phone number accounts enjoying gab way better\n",
      "Sample 60 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  here the deal teach you are gonna stop making me watch gay pbs and i am gonna call you a good lil white bitch got it\n",
      "Sample 61 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  dwg courtois is a fucking disgrace\n",
      "Sample 62 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> <user> his friend had been hurled off a rooftop in raqqa syria homo explained all the society where they are not under isis they say we do not share isis values but these same people are writing comments on facebook saying we do not care let the faggots die\n",
      "Sample 63 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> no are you retarded\n",
      "Sample 64 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> when it comes to the issue of women facing domestic violence i will beat them like a drum\n",
      "Sample 65 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  some people hope their ghetto fight ends up on worldstar hip hop but gab users we hope our epic shitpost ends up in a media matters top five list\n",
      "Sample 66 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  fight white apologists i am white i have not terrorized anyone please do not speak for me and do not fucking ever apologize for me\n",
      "Sample 67 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  i am presuming he means the standard left wing idiots lots of hypocritical women amongst them think maria ladenburger obviously you are against these fucking muhammedans\n",
      "Sample 68 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  rajiniwithindianmuslims from <number> coimbatore blasts till now thalaivar has always been supportive to muslim brother\n",
      "Sample 69 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  negerball has went full ghetto apefreaka looking forward to the before after photos like 1 9 2 0 dietriot to today\n",
      "Sample 70 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  if money was grown on trees women would be dating monkeys oh wait never mind\n",
      "Sample 71 / 1008 : Prediction = 0  Saved:  0 Correct label:  2\n",
      "Text:  no excuses there is never a reason to carry a knife anyone who does will be caught and they will feel the full force of the law london mayor sadiq khan tweeted on <date> maybe someone needs to stab that sand nigger in the neck\n",
      "Sample 72 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  <user> <user> i saw them and loved them ðŸ˜ i was like dino has made it now he can live on easy street ðŸ˜‡ ðŸ˜\n",
      "Sample 73 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  a bitch needs a hair cut tattoo and vacation\n",
      "Sample 74 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  this hoe needs to get beat down omg\n",
      "Sample 75 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  <user> honey i aint u r just into dykes ðŸ¥º\n",
      "Sample 76 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  so that is why mom brother who works in google a pakistani born married a local american women divorced her got married to a rich paki doctor wow ye concept hy phir they shifted to us great\n",
      "Sample 77 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  nigger porch monkey tree fruit neggra niggress ol black joe\n",
      "Sample 78 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> it â€™ d be an awful shame if nazis showed up and made things worse ðŸ¤”\n",
      "Sample 79 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  sbwl the day women support each other spread love promote sisterhood\n",
      "Sample 80 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> <user> siss why you posting retardi b did she sure you\n",
      "Sample 81 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  i can not believe cosby raped the reo speedwagon guy\n",
      "Sample 82 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> <user> you own me 2 gold fucking niggers\n",
      "Sample 83 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  it all hehe haha until we show up at your local favorite hang out spot and wait for you to come out in the van they go one little heeb at a time whatever it takes\n",
      "Sample 84 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  a demographer notes with mild alarm that in <number> minority birth rates fell faster than white birth rates who will supply gays with fatherless niglet boys if these trends continue\n",
      "Sample 85 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> apparently not so obvious to some esp the homosexual jewish media that wants women to look like boys and people who think that is traditional rather than feminist\n",
      "Sample 86 / 1008 : Prediction = 0  Saved:  0 Correct label:  2\n",
      "Text:  feminism is the greed for honor by some women against the status of the most prestigious men the great pretense is that feminist women want equality with men but feminists remain silent about the plight of low status exploited men\n",
      "Sample 87 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  these niggas be so weird out young and old do not know how to approach a female\n",
      "Sample 88 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  <user> <user> yea those people were immigrants too all one big melting pot of immigration lovely\n",
      "Sample 89 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  no it a fucking retarded idea on par with women suffrage\n",
      "Sample 90 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  what bakunin found onerous in marx politics both in its strategy and its goal was the idea of representation as a political concept where there is representation there is oppression anarchism can be defined as the struggle against representation in public life\n",
      "Sample 91 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  when i was young my goal was to be like jane curtin on snl an ignorant slut finally realized my goals\n",
      "Sample 92 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  paul i like you and appreciate what you are doing but you are being a retard right now\n",
      "Sample 93 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> bruh isp aint shit especially if theyre nosy conservative arabs ðŸ’” take ur precautions\n",
      "Sample 94 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  chain migration when an immigrant to the united states sponsors other family members for admission â€“ such as parents children and siblings â€“ who can then sponsor other immigrants themselves and so on â€¦\n",
      "Sample 95 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  another demonstration of what a useless joke the uk police are especially retarded to send two unarmed women to apprehend a rapist guaranteed fail bad enough for unarmed pansy men but women how very progressive and equality\n",
      "Sample 96 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> parties with leo room full of bad bitch and fine niggas\n",
      "Sample 97 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  mera bachcha app ðŸ‘ ðŸ‘ ðŸ‘ <user> <user> <user> three pakistani children raped and murdered protests in punjab <number> sep <number> Â· the incident happened in kasur district located some 5 2 km south of lahore in punjab province of pakistan\n",
      "Sample 98 / 1008 : Prediction = -1  Saved:  -1 Correct label:  0\n",
      "Text:  the rape upon these women are violence and horrific if only they could have a knife on them act brave toward their abuser and stay calm then strike them when they least expect it these savages deserve no less\n",
      "Sample 99 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  europe is being stolen blind by the muzrat hordes\n",
      "Sample 100 / 1008 : Prediction = -1  Saved:  -1 Correct label:  2\n",
      "Text:  lmao a lot of you all new bitches be my old ho\n",
      "Sample 101 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  tell that to the blacks jews muzzeez and la raza who are trying to kill us tell it ti the asians who are proud to be asian\n",
      "Sample 102 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  trump needs to fire that kike rod rosenstein he should have known you can not trust a jew\n",
      "Sample 103 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  im really a pretty bitch\n",
      "Sample 104 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  what do the elite call a woman raped by muslims a white slut\n",
      "Sample 105 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  who knew that white south african african traditional attire looked like distressed viking attire\n",
      "Sample 106 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  being ignored by a white man is basically him calling you a nigger\n",
      "Sample 107 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  <user> i fucking hate you come home tho\n",
      "Sample 108 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  if kamala harris was stuck in an elevator alone with imported orphans and widows how many times do you think she d be raped before they killed her yet she jokes about killing trump in an elevator mhm can not get much lower than she already is\n",
      "Sample 109 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  milton is a kike lover who pretends to be against communism when he promotes degeneracy\n",
      "Sample 110 / 1008 : Prediction = -1  Saved:  -1 Correct label:  2\n",
      "Text:  too bad you are retarded and can not read\n",
      "Sample 111 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  it okay to be white it okay to be black it okay to be asian it okay to be a woman it okay to be a man it okay to be gay it okay to be straight it okay to be you but its never okay to hate blur\n",
      "Sample 112 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> how come she was nationalist being a muslim nationalism is prohibited in islam na\n",
      "Sample 113 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> <user> gandhi told jews they should commit suicide to prevent holocaust blamed women when they were raped arranged the rape of his own daughter refused to sit in the same carriage as black people\n",
      "Sample 114 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  my friends highkey got that bitch personality i fucking hate them\n",
      "Sample 115 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  imagine believing in white privilege as whites are ethnically cleansed in their own countries imagine not knowing why whites must learn to fly not be weighed down by the shitskin undertow by guilt by lies trust in your whiteness\n",
      "Sample 116 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  it true i am fairly retarded at bird identification i have no egrets about it pic giant bird eats man after he sprays paint on it\n",
      "Sample 117 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  <user> i wonder if a white person called tatum a nigger to his face would be just sit there and smile and nod\n",
      "Sample 118 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  <user> <user> this is what feminazi consider being born again\n",
      "Sample 119 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  fake americans killing each other on us soil msm response how can we make this some white dude fault right now they are trying to bleach out the pigment of the illegal alien face and make sure the muslim american girl looks suitably cute in every photo goback\n",
      "Sample 120 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> <user> <user> <user> <user> <user> if he not lazy why is he butt hurt americans are lazy compared to african countries that fact is not nearly enough reason for me not want them here african immigrants are not the enemy white supremacy is\n",
      "Sample 121 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  when a fic has â€œ smell of â€ in its title and you just know â€¦ those a b o bitches\n",
      "Sample 122 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  another reason voting is pointless civ nat burger nat at its finest let us ask niggers who the good niggers are so we can get the nigger vote <number> iq apes will turn this country red blue wave be damned trump is owned by jews anyway ridiculous <user> â€ <user> â€\n",
      "Sample 123 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> <user> so it not okay to be white\n",
      "Sample 124 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> <user> go and stay any muslim country and speak like this\n",
      "Sample 125 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> men can not be raped can not be abused that why they call it violence against women and children because men are always the perpetrators women come first even before children\n",
      "Sample 126 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  remember goy when you let jews in it was like signing a contract to let every nigger in africa and every muzzie in arabia in too you did not know that\n",
      "Sample 127 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  hating beaners is so easy\n",
      "Sample 128 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  market tops are made in violence market bottoms are made quietly old wall street adage\n",
      "Sample 129 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  this communist bitch has to go she should not be teaching middle school or any school for that matter she a danger to freedom and to society outantifa\n",
      "Sample 130 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  <user> goad is sharp and has an ear for the language i keep trying to pull myself from interacting with long gone progressives in the f***book <censored> ghetto and write for publication to sway people who are open to reason instead\n",
      "Sample 131 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  the communist leadership must also remove themselves to their choice of a communist or muslim run country they so blatantly love\n",
      "Sample 132 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  i dont care about hitler because i care about western people hitler allows millions of jews to pose as neonazis to cuck millions of gentiles from rebelling against jews for fear of being called a nazi\n",
      "Sample 133 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  <user> only reason islamists tweet this ridiculous stuff is because left loonies who are closet jihadis themselves support this ridiculous notion show me one muslim country where minorities are not being killed and women are not being caned or stoned in public\n",
      "Sample 134 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  <user> <user> lmao shut up bitch report that\n",
      "Sample 135 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  <user> the tolerant left killing children consequence free expecting tax payers to pay for it and hoping pro human people get raped\n",
      "Sample 136 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  this pic shows success and the ghetto all in one area\n",
      "Sample 137 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  i got a guilty pleasure and it is country music and hillbilly movies and tv shows about rednecks hunting in the woods and fucking white trash skanks\n",
      "Sample 138 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  <user> lmfao i hate you\n",
      "Sample 139 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  the end of it did not mix blacks and whites it just meant the liquor stores in black areas are now run by arabs instead of blacks\n",
      "Sample 140 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  give me a break the arabs do not want domination or clintons dont try to dovetail history to suite ur misguided ideology if i am not part of the crowd i am offended <user>\n",
      "Sample 141 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  <number> year old white het boys are the worst breed all they do is recycle their same old holocaust racist sexist and homophobic jokes to hide their insecurities i got news for you buddy it not working\n",
      "Sample 142 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  i just can not trust nobody that on some my aesthetic is preferred you are aesthetic is considered disgusting but promise i am just tryna help she needa be exiled faux niggers\n",
      "Sample 143 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  it was better off when apartheid existed now its a nigger shithole niggers are killing whites get out or stay away\n",
      "Sample 144 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> lets go work out there with the white bitches\n",
      "Sample 145 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  agh waters world dem negresses remarks god dayum\n",
      "Sample 146 / 1008 : Prediction = 0  Saved:  0 Correct label:  2\n",
      "Text:  hunger games with little niglet babies\n",
      "Sample 147 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> yes chuckster legal immigrants made america not the gimmes of today\n",
      "Sample 148 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  <user> common for trump groupies rt <user> nigger sand nigger all the same oh yea wetbacks too\n",
      "Sample 149 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <number> of geneticists on the planet say so it cold hard science mathematical physics as guaranteed totally ignorant of genetics what white folks are and does not believe in science they are all total retards complete ignorance this is like shooting fish in a barrel\n",
      "Sample 150 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  those are quotes directly from anti white semites so shove your fucking anti semitism up your faggot ass\n",
      "Sample 151 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  <user> <user> please look at refugees iraqi in turkey they want home standwithiraqirefugees\n",
      "Sample 152 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  wondering if you have good tastes in women\n",
      "Sample 153 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> your the one left faggot the battle been over good night\n",
      "Sample 154 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  homosexual and hollywood communities redundant\n",
      "Sample 155 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  aint nothin like a ride or die bitch she come thru and throw the <number> up love to fuck she even roll the piffy up\n",
      "Sample 156 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> when whites and asians have children the kid still comes out white black men are the exact opposite the antithesis to white men\n",
      "Sample 157 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  was called a nazi once at a social gathering so i called the sjw a nazi back she was horrified even more so when i gave her examples of her speech was gratifying she would not speak to me again that night\n",
      "Sample 158 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  oh you mean these guys all jews vox said no jews are globalists is vox lying\n",
      "Sample 159 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  <user> man <number> of these nibbas really retarded\n",
      "Sample 160 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  pray that my mom white blood count and platelets come up and stay up in jesus mighty name\n",
      "Sample 161 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  so five beaners will not be collecting welfare\n",
      "Sample 162 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  <user> andrew johnson impeached failed send every negro back to africa beat as worst president by trump go back places from which they came read jesus turned serapis sermon on the black christ lulu thomas jefferson pimped skydog and the aunt jamama bomb lulu\n",
      "Sample 163 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  i really fucking hate you remember that oop i will <happy>\n",
      "Sample 164 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  not <percent> jap i am willing to bet there is a generous dollop of hooknose in her blood\n",
      "Sample 165 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  the person below is a nigger\n",
      "Sample 166 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  bungo scrungo gay dogs\n",
      "Sample 167 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  beat odds never beat women lil wayne\n",
      "Sample 168 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> like here when they call a white shooter a mentally disturbed gunman but anyone non white is a terrorist yet our fake president and his followers seem to think the immigrants are bringing violence\n",
      "Sample 169 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  real women really do seem to hate those soyboys\n",
      "Sample 170 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  <user> wow islam side by side w jews only <number> case in the entire world so what happened to all the jews in kolkata\n",
      "Sample 171 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  women have never been in charge of establishing and protecting territory so it no surprise that they have zero instincts in this area and it why so many of the refugees welcome crowd is women or weak beta men the <number> groups are interchangeable psychologically\n",
      "Sample 172 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  let me get this straight ok if i convert to islam i can abuse women and children without catching any heat right i get a pass right hum\n",
      "Sample 173 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  time to have the music industry join us on the not retarded side\n",
      "Sample 174 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  that faggot is begging for a helicopter ride\n",
      "Sample 175 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  racism was invented by communist jews the term the concept those same communist jews murdered tens of millions of racists yet whites run around scared of being called racist resolved whites are a race of cowards that is what the evidence says\n",
      "Sample 176 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  fun fact of the four islamic halal markets run by muslim immigrants in one of oregon larger cities three were closed down for rampant foodstamp fraud and fencing stolen goods what about the fourth the county shut it down for health code violations including human fecal e coli in kebabs\n",
      "Sample 177 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  as long as you do not call them ugly kike whores you are probably fine my feminism allows men to respond to bitchy women as well preferably in a classy way myself included but i mean women like <user> are classy only in maga fantasyland using words like dyke and faggot deplorable\n",
      "Sample 178 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  you openly censor users downvoting freedom push mute selfcensorship a subset of censorship as freedom and are a profitmonger make gab non profit open source transparent bring the community into the dev circle remove mute google analytics and downvote censorship currynigger racetraitor\n",
      "Sample 179 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  my mom was watching blues brothers the movie there a part where neo nazis have a rally she said to me mockingly look jews are using blacks to gang up on white people i honestly did not see what was inaccurate about that\n",
      "Sample 180 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> homosexuality was a disorder at one time until the queers pressured the shrinks to remove it clearly not science but political same difference here also sexual orientation means anything goes as satan wishes\n",
      "Sample 181 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  what is this red shoes meme i am hearing about did anglin really suggest wearing nigger shoes or am i wrong\n",
      "Sample 182 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  <user> <user> why do muzzys hate so much\n",
      "Sample 183 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  <user> historical context matters except for when you want to leave out the irish treated just as bad called the niggers of europe but hey that was different right atleast they were white while living and working as the africans did under near slave conditions\n",
      "Sample 184 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  i like how they have to specifically say non hispanic in white categories on graphs because the kikes will lump anyone in with us to make our numbers worse\n",
      "Sample 185 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  i will make this as politically correct as i possibly can kill all the sand niggers until there not a single one left and you will solve half your problem overnight kill all socialists to solve the other half\n",
      "Sample 186 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> <user> <user> <user> alan do you white knight like this all the time because it will not get you laid just force yourself onto her like all you male feminazis do\n",
      "Sample 187 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  <user> you are a faggot bitch for not punching that nigger back\n",
      "Sample 188 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  abortions for niggers jews arabs spics gooks should not be a right it should be a law white women should never have an abortion because it takes up valuable resources for people of colour if you are a white women and you have an abortion you should be labeled a racist <user> â€\n",
      "Sample 189 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> if you are reading this you are a faggot i am just memeing and a bit bored\n",
      "Sample 190 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  he responded but we are not going to get anything constructive out of him unfortunately i thought if we had a black nationalist here we could be have mock negotiations between us but he just wants to act like a huge nigger instead\n",
      "Sample 191 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  he needs to sue obama for illegally passing legislation that exceeded his legislative power in other words daca was an illegal program he should sue the dems for failure to perform and pass legal legislation for immigrant children\n",
      "Sample 192 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  well gabfam it thursday thank the gods of course it cold wet grey gloomy and shitty but meh that oh for you have a great day remember make the world a better place shoot a kike in the face\n",
      "Sample 193 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  david hogg is encouraged in his targeted harassment against other users twitter accounts in the name of his obvious political initiative but nobody is allowed to criticize him for doing it without the risk of permanent suspension from the same platform\n",
      "Sample 194 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  maybe that not such a big deal to some people but all the potential legal immigrants who are waiting in line to come to our country would consider it a big deal\n",
      "Sample 195 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> why are people not freaking out over this hot lesbian energy i just don â€™ t get it i need a sandy fan club\n",
      "Sample 196 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  <user> the biggest enemy u have is yourself in ulster it the sf pan catholic front demanding abortion liberalisation homo faggot rights skank equality the prod dup are the social conservatives resisting this jew marxist attack as for shitskin immigration u should give a fuck\n",
      "Sample 197 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  bitch wanna keep bugging mute button it is ðŸ¤· ðŸ½ â€ â™€ï¸\n",
      "Sample 198 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  terrifying ly retarded\n",
      "Sample 199 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  this little kike is a good little donkey american\n",
      "Sample 200 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  so here something i have had a hunch about so i have yet to really look into in their plan after white have been all but extinct seeing as they d be the last civilized group left they d go after the asians next\n",
      "Sample 201 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> i fucking hate you ðŸ˜­ cause why say that lol\n",
      "Sample 202 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  lmao i am not one of the dykes who you would catch with any bitch who has a baby simple its a deal breaker for me\n",
      "Sample 203 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> especially with a nazi i the white house\n",
      "Sample 204 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> los angeles county alone spent <money> bil <number> <number> on illegal aliens now these same democrats are calling for state of emergency get real <user> <user> <user> <user> <user> <user> <user> how is your sanctuary space\n",
      "Sample 205 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  oh so you say they are homegrown lone wolf terrorists they are just the offspring of the original terrorists it not like these people are coming from 3 rd generation white christian families the level of retardeness these days is unbelievable maga trump\n",
      "Sample 206 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  plenty of faggots to talk to\n",
      "Sample 207 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  ok so rolling loud was fun all but who ever invented mosh pits i fucking hate you damaged\n",
      "Sample 208 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  niggas will rep any gang niggas will bust any head niggas will risk everything point him out and then he dead\n",
      "Sample 209 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  this hoe said snooze you lose\n",
      "Sample 210 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  <user> good one ricky wait till those diesel dykes get hold of her round little ass\n",
      "Sample 211 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  <user> swine there are two muslim countries given by india pakistan and bangladeshi how can a muslim will be persecuted in islamic country but hindu sikh jain christian are presecuted in both bangladesh and pakistan\n",
      "Sample 212 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  of course the most at risk though are not going there to be raped and tortured i will see if i can find you an article on just one of several cases this one stood out as the filipina in question was herself a muslim\n",
      "Sample 213 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  queers in olymipcs are the same in the military a huge fucking mistake\n",
      "Sample 214 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  before we blame dykes kikes spics niggas whit trash redneck honky trailer trash why do not we look at what part we played in a situation why do not e ask ourselves what could i have done to prevent it did i even try\n",
      "Sample 215 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  no most white men do not rape <number> year old women that department is saved for your compadre beaners and young black males\n",
      "Sample 216 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  swedish police chiefs agree to start bombing native swedish neighbourhoods to drive racists out of their homes and make them seek refuge elsewhere only then will they learn about empathy and stop regarding foreign refugees as the other mega\n",
      "Sample 217 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  to write about leftism without mentioning jews is as absurd as writing about milk but not mentioning cows yet it done all the time\n",
      "Sample 218 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  americans are dreamers too i give trump a <number> out of <number> pandered a bit too much to nonwhites but really stuck it to immigrants\n",
      "Sample 219 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  can not pass a physical can not keep their ship from running into a cargo ship in clear skies can not show up for post on time and bitch when they get diciplined navy headed in the wrong direction\n",
      "Sample 220 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  it ok if a moslem does it\n",
      "Sample 221 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  hi niggers add me on discord chanel <number> especially you <user> â€\n",
      "Sample 222 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> she was fine until she said ghetto she tried it she rly did\n",
      "Sample 223 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  <user> <user> which is going to refugees for food clothes water etc not actual ladders\n",
      "Sample 224 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  not caring that black women are <number> times as likely to abort their unborn baby than white women is not racist not wanting to fund abortion thereby protecting black lives is racist tom trinko sjwlogic\n",
      "Sample 225 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  getting ass raped by sandniggers\n",
      "Sample 226 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  thanks for coming to my ted talk p.s. calling me ching chong with not make me laugh\n",
      "Sample 227 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> respectfully i disagree sir autocracy cost more money true but many people rather pass on freedoms if in exchange homelessness is criminalized immigration tightly controlled and lgbt people put in prison and women threatened not to report sexual violence\n",
      "Sample 228 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> bc at that point u literally become the boogyman that bigots always preach u know the whole they are going to rape us shit they would say years ago\n",
      "Sample 229 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  the dog ate my homework i did not do it everyone lying but me he started it she is not good lookin enough to rape presidency\n",
      "Sample 230 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  milo actually in the homosexual world particularly some of those relationships btwn younger boys older men those kind of coming of age relationships\n",
      "Sample 231 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  he a moslem attorney advocating sharia law for sex abuse cases and claims to be a women rights defender translation women will need <number> men or <number> women as witnesses lgbt do not bother they will kill you punishments range from imprisonment caning stoning to death and beheading of women\n",
      "Sample 232 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  <user> y are u focusing on that when nazis exist\n",
      "Sample 233 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  gab is a closed social network it is impossible to see any posts without registering first as such it is good for echo chamber but unusable for propaganda or making any statement this has to change otherwise it ll turn into an information ghetto or reservation for right wingers\n",
      "Sample 234 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> i was raped <date> april ain t shit lol cancelapril\n",
      "Sample 235 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  post is proof that negros are retards side note nas is one of the worst pop rappers in history really says a lot about you is it rough being a negro with no taste in music\n",
      "Sample 236 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  <user> now how about all of the deaths attributed to illegal aliens in tx do the rest of the victims and the families that will never see loved one agains texas\n",
      "Sample 237 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  bears last lmaoo niggas team tho\n",
      "Sample 238 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  davos is merely whitewashed economic gangsterism\n",
      "Sample 239 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  gab has all the bot driving up retarded post about hollywood fake actors meanwhile the migrant caravan invasion is nowhere to be found after everything we have been through you would think we could spot censorship nope same bat channel same bat time gab looks just like twitter right now\n",
      "Sample 240 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  every last one with a drop of jew blood how do you actually foment a reasonable theory of who and are not gentlemen when the nazis inducted jews into jugend and put them on the cover of their family oriented magazines\n",
      "Sample 241 / 1008 : Prediction = 0  Saved:  0 Correct label:  2\n",
      "Text:  dig a ditch for a bitch if she gone throw dirt talking all that shit like you won â€™ t get hurt\n",
      "Sample 242 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> ok u still get passed onto high school retard\n",
      "Sample 243 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  does the equalityact allow a man in the girl locker room so long as they identified as a woman if so are women okay with that\n",
      "Sample 244 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> makes no sense to rent homie it â€™ actually retarded\n",
      "Sample 245 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  dykes are tougher than lightskin niggas\n",
      "Sample 246 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  just because bjp supporters and bjp ministers talks about ethnic cleansing of indian muslims it does not mean modi is not anti muslim\n",
      "Sample 247 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  this guy thinks uk police pms mps councillors actually do their jobs <number> million white children raped by pakis numbers covered up by those above not doing their jobs\n",
      "Sample 248 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  giving the asians a bad name\n",
      "Sample 249 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  donald trump is a fucking joke\n",
      "Sample 250 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  im only playing tabletops with niggers from now on\n",
      "Sample 251 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  why am wasting my time with you if you are too retarded to understand what controlled opposition is you probably think the holocaust was real do not you white genocide is orchestrated by the kikes the shitskins are just the tool they are using to do the job\n",
      "Sample 252 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  diversity is very important for <user> that why she does not just date tall nerdy white dudes she will also give lanky geeky caucasians or towering european dweebs a try\n",
      "Sample 253 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  your posts show otherwise nigger lover\n",
      "Sample 254 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  dykes has joined og for the first time <user>\n",
      "Sample 255 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  2 k do not put out patch notes and you niggers got dial up internet so it ll be damn near <time> before we know what was changed\n",
      "Sample 256 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  my ex has a weird infatuation w dykes\n",
      "Sample 257 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> this is a dream come true finally women are getting respect in wwe\n",
      "Sample 258 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  omg the jews added me to their hate list what shall i ever do i will count it as an honor\n",
      "Sample 259 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> mine is a fucking asshole but a pretty cute asshole\n",
      "Sample 260 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  there must be a mistake with a name like husnain rashid he could just be a peaceful sikh who been mistaken for a muslim jihadi ðŸ¤· ðŸ¾ â€ â™‚ ï¸\n",
      "Sample 261 / 1008 : Prediction = 0  Saved:  0 Correct label:  2\n",
      "Text:  <user> that white kid is why we have active shooters just look at him when they pull away the porch monkey it on\n",
      "Sample 262 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  asshole ghetto trash bastard i will have a party when someone puts his in the ground\n",
      "Sample 263 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  again and again what i hear from mexican immigrants is that we need to do more for them their is moral outrage and entitlement in their voices as they want someone else to invent create or pay for something else for them\n",
      "Sample 264 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  millions of soldiers are terrorists by your definition every state in existence is a terrorist state by your definition calling someone our for using violence to achieve a political end is just being dishonest and beta\n",
      "Sample 265 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  what they try to do is move in her hair of not being washed and wanting to rape in touch in thought of when we touch as father and daughter\n",
      "Sample 266 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  <user> <user> if you are black hispanic gay or lesbian or democrat it all good nothing you do can be construed as a crime however if you are white or republican you can get the death penalty for a parking ticket\n",
      "Sample 267 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  twitter would have flooded with islamophobic topic if it was other way around but anyways ohm namah shivaya\n",
      "Sample 268 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  from time you see a ghetto yute in formal wear just know they bouta go to court or funeral\n",
      "Sample 269 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  musacchio suspended for being a retard blame giampaolo\n",
      "Sample 270 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  is it too late to hire sonny dykes to be the next tech head coach\n",
      "Sample 271 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  â€œ i need a kid thats gon wash them dishes â€ ðŸ˜­ bitch is retarded\n",
      "Sample 272 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  kate brown is a kike whore oregon was a nice state now its cess pit this bitch should pushed down the stairs when everyone is looking\n",
      "Sample 273 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  frank dicpario and the misogenous potatoes a blackened math metal band\n",
      "Sample 274 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  just saw an obese negress wearing a shirt emblazoned with black is beautiful it is not imagine the reaction if i wore an it okay to be white shirt in public\n",
      "Sample 275 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  <user> get off my twitter feed you towel head go milk a goat or something\n",
      "Sample 276 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  les vocals de junhoe dans just go ðŸ˜”\n",
      "Sample 277 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  for now on if blacks refer to whites as vinallas i will refer blacks as chocolates or niggers\n",
      "Sample 278 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> woah eyes are like ghetto blaster speakers my two cents ðŸ˜Š ðŸ ðŸ‘ ðŸ» ðŸ’œ\n",
      "Sample 279 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  you cannot be reasonable with 3 rd world retards their low iq and their training as perpetual victims predisposes them to violence we are killing ourselves trying to be kind and reasonable with retarded animals\n",
      "Sample 280 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  just got assigned to write a paper on how reverse racism is not real in a class full of white ppl you all know i got this in the bag\n",
      "Sample 281 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  joaquin phoenix executed the role of the joker perfectly that was an excellent movie def go see it\n",
      "Sample 282 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  bts as muslims thread a thread\n",
      "Sample 283 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  i say what i want to say and do what i want to do there no in between people will either love you for it or hate you for it\n",
      "Sample 284 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  yeah i am that basic bitch that listened to unknown pleasures by joy divison last night and cried\n",
      "Sample 285 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  fucking ulgly ass bitch ass stinky ass bitch ass nigger slave nigger teacher faggot peace of shit suck a dick\n",
      "Sample 286 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  lol snow nigger is salty as fuck meanwhile hindus are richer than alt right cucks therefore paying more in tax rates so are the jews\n",
      "Sample 287 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  i called don jr an unsavory name and had my account with 7 k followers permanently suspended for targeted harassment of a protected class so now white male billionaire fail sons are a protected class fml\n",
      "Sample 288 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  i wonder when it ll finally come out that tony has niglet grandkids or gay sons\n",
      "Sample 289 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  <user> i â€™ m not gay\n",
      "Sample 290 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> is it wrong that i d pay fairly decent money to see him being raped by a labrador ðŸ¤” and if it is is it more wrong than <number> dead due to tory austerity ðŸ¤”\n",
      "Sample 291 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  it the big gay wedding\n",
      "Sample 292 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  i seriously doubt any white man would willingly lie with a sheboon let alone rape one hell black men do not even want them mawa\n",
      "Sample 293 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  i am a <number> year old non college educated white man from pa i am a moderate independent who opposes the clean air act sometimes opposes abortion supports deporting illegal immigrants and supports raising the min wage i did not vote in <number>\n",
      "Sample 294 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  ha good i am tired of that beaner clown\n",
      "Sample 295 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  get this nigga zion some lugz those soles strong as shit\n",
      "Sample 296 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  clowns in this bitch\n",
      "Sample 297 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  i guess col <user> was wrong about just pounding the table if the law facts are against your case the smart thing to do is pack the jury with wetback child rapists\n",
      "Sample 298 / 1008 : Prediction = -1  Saved:  -1 Correct label:  2\n",
      "Text:  and fish smell sweaty in the raghead and body bags\n",
      "Sample 299 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  greatest hope for mankind is to reach out to muslims who have not yet been enlisted to violence\n",
      "Sample 300 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  the mudslime needs to be deported back in a coffin\n",
      "Sample 301 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  abusite in your bio you getting block since you love being ghetto ðŸ¤¢ ðŸ¤¢ ðŸ¤¢ ðŸ¤¢ ðŸ¤¢\n",
      "Sample 302 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  <user> <user> <user> it a muslim immigrant man in europe this is not a white scandinavian woman thanks for your help though massive\n",
      "Sample 303 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  no only mates mucking round in a boxing gym in a once white ghetto recently turned black\n",
      "Sample 304 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  a group of zebras claim they witnessed a white rhinoceros fleeing the scene chimp news network is on the location talking to a family of orangutans matching the zebras story prayforfuckyouthatswhy\n",
      "Sample 305 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  so my iphone still thinks fuck is duck but it auto corrects hufflepuff with no issue <number> is gay af\n",
      "Sample 306 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  how the fuck did that nigger secured this my head is so hot\n",
      "Sample 307 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> i swear lee min ho will successfully turn me gayy ðŸ˜ª ðŸ˜ª ðŸ’” ðŸ’”\n",
      "Sample 308 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  this has been a trend since <number> of course wall street assumed eternal growth despite fb having plateaued in the first world even earlier those asians living in huts will be worth just as much as us users in time if only we have faith that they will due diligence\n",
      "Sample 309 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  youre jealous like all leftist queers\n",
      "Sample 310 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  yeah or you can start from the negative look at nonwhite countries and nonwhite ghettos in white countries and go from there it is not a difficult question\n",
      "Sample 311 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  <user> <user> <user> <user> anti muslims feel so happy that muslim ummah is weak and sleeping and is worrying for economy crisis no doubts india is a big consumer market for greedy western muslim countries so they are ignoring oppression with minorities by modi hitler in kashmir under threat india\n",
      "Sample 312 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  <user> bring your chess boards out china no more ghetto checkers\n",
      "Sample 313 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  sorry i haven â€™ t tweeted in a while i â€™ m too busy having gay sex\n",
      "Sample 314 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  the cultural marxist revolution is in full swing in Ã¨ire there a witch hunt against heterosexual rugby players while our taoiseach is a homosexual sodomite etc\n",
      "Sample 315 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  yeah just a bunch of triggered retarded nazis anyway i am off to sleep good nights\n",
      "Sample 316 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  guilty until proven innocent unless you are a jew a nigger or a lover of both\n",
      "Sample 317 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <number> week ban wot game chat ban for saying i want to throw your mother in an oven shitskin\n",
      "Sample 318 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  don lemon is a nigger\n",
      "Sample 319 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  <user> read history arabs never wanted peace they since <number> have been scheming on destroying israel for decades gaza and the west ban were under arab control and they did not create a free palestine\n",
      "Sample 320 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  you all white whores are trashy as fuck it the <number> century you all pussy is a tragedy you all blk businessmen are ghetto as fuck helping some white bitch pussy that has a problem with blk ppl using bank or credit cards get a fucking dick in your pants\n",
      "Sample 321 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  <user> not shocking that the ones yelling hate and intolerance are all white lol\n",
      "Sample 322 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  <user> freedomworks condemns the violence in charlottesville prayers for the injured and the family of all the victims\n",
      "Sample 323 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  clueless boomer jews dont want refugees because muslims hate them\n",
      "Sample 324 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  i swear if i ever die someday and some sorry son of bitch votes democrat on my behalf i will comeback and slash that motherfucker\n",
      "Sample 325 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  slap the bitch in the fave with them hoes\n",
      "Sample 326 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  traddad realizing that white women are corrupted is important knowing they are the only route to a white population is the next step figuring out how to un whore them and rebuild patriarchy is the result of these realizations if you are not considering this you are too nihilist for our movement\n",
      "Sample 327 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  there goes any thoughts of eating breakfast that alone should be a bannable offence imo sexualized harassment on gab i get it daily\n",
      "Sample 328 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  merkel next governmental position should be refugee camp whore\n",
      "Sample 329 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  frigid childless dykes conned females that white men are bad mmkay and that child rearing and taking care of the home wasn t valuable its invaluable and always has been\n",
      "Sample 330 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  i have had way too much experience with diversity hires most have made <number> to <number> times what i do have had comical english served no purpose other than to take a job from an american i am talking chinese women here not blacks\n",
      "Sample 331 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  we would like to salute all of the women marching today for no apparent reason with our middle fingers outstretched to you\n",
      "Sample 332 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> <user> amen i will put my <number> cents in and help as well the intersection of veganism women hip hop music and islam in sneaker culture\n",
      "Sample 333 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  so your theory is whites in america are retarded for allowing in so many diverse immigrants but africa is supposed to be cool with it makes a lot of sense i smell bullshit\n",
      "Sample 334 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  <user> christians fail to explain how this harms them though it harms us when you faggots behave like the disease vector pedophiling murderous raping druggie shiteating conscienceless prog degenerate scum that you are aids is proof that god hates fags\n",
      "Sample 335 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  trump truly has crushed their narrative control with an iron fist this election was devastating for rachel maddow bull dyke media types we did it fam maga gabfam presidenttrump\n",
      "Sample 336 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  the muzzies and black churches have always been given a pass this primarily helps conservative churches that have been silent on political issues out of fear of losing their 5 0 1 c3 status\n",
      "Sample 337 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  hrc wants undocumented immigrants to all have drivers licenses so they can vote this is how <number> million stole the popular vote from <user> wikileaks org podesta emails â€¦\n",
      "Sample 338 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <number> draft order <number> tigers <number> orioles <number> marlins <number> royals <number> blue jays <number> mariners <number> pirates <number> padres <number> rockies <number> angels <number> white sox <number> reds <number> giants <number> rangers <number> phillies <number> cubs <number> red sox <number> diamondbacks <number> mets <number> brewers <number> cardinals\n",
      "Sample 339 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  nigger i g g e r\n",
      "Sample 340 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  gotham city villains have weird taste in men and women\n",
      "Sample 341 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> why do not muslim countries accept them as refugee\n",
      "Sample 342 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> both dialogues sound like something black people would say not whites\n",
      "Sample 343 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  quite right too fuck the retarded ragheads\n",
      "Sample 344 / 1008 : Prediction = -1  Saved:  -1 Correct label:  1\n",
      "Text:  star wars is so gay\n",
      "Sample 345 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  were the kardasians jenners raised to be coal burners or what i mean the mom married a crazy white man that thinks hes a lady you think she raised them not to like white guys\n",
      "Sample 346 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  this is the most retarded thing you will see today you are welcome ðŸ¸\n",
      "Sample 347 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  unconfirmed backstory white girl refers to black girl as nigger on facebook black girl responds to prove her wrong\n",
      "Sample 348 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  my sister is becoming more ching chong pretty much taller and so fucking similar to my personality i should feel threatened\n",
      "Sample 349 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  fanbloodytastic by time these leeches are held to account especially the muzzie scum taking <number> wives breeding kids like rabbits in order to increase welfare payments potus ur simply the best ðŸ‘ ðŸ‘ ðŸ‘ ðŸ‘ ðŸ‘\n",
      "Sample 350 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> <user> i think he was with underaged boys we all know he gay and no one cares so it has to be something illegal or maybe his lover is an illegal alien what else could it be\n",
      "Sample 351 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  dad why are there no jews on jupiter because its a gas planet son\n",
      "Sample 352 / 1008 : Prediction = 0  Saved:  0 Correct label:  2\n",
      "Text:  i do like the ymca for working out but they have extreme homosexual leanings nearly all the men working there have the flames turned on high\n",
      "Sample 353 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  if the greeks from <number> years ago could see the olympics now they d throw up it all about more msm promotion of gays blacks and those who hate whitey back then it was a statement of see do not mess with my country we will f you up\n",
      "Sample 354 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  sung to the tune of the communist globalist hippy anthem imagine you may say that i am a beaner but i am not the only juan i hope someday you will join us and the world will be as juan\n",
      "Sample 355 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  <user> <user> another hoax against caucasians â€¢ is this crap that keeps happening to white folks our white privilege that we keep hearing about\n",
      "Sample 356 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  introduceyourself i am a young gay latino donald trump supporter i will defend him anytime go ahead and try me ðŸ˜ˆ\n",
      "Sample 357 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  i hate a nigga with bitch ass tendencies lmfaoo u just got a extra leg u fuckin peon\n",
      "Sample 358 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  <user> <user> zionist jews are courting their own destruction by christian zionists that is a disturbing irony\n",
      "Sample 359 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  what else would you expect from a retarded feminazi swamp donkey\n",
      "Sample 360 / 1008 : Prediction = -1  Saved:  -1 Correct label:  1\n",
      "Text:  justine mohammed trudeau running the streets wild in toronto at the gay pride ding a ling parade this weekend\n",
      "Sample 361 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  settlement and its naturalization then condi tioned the emergence of modern queer formations including their inheritance and sustaining of colonial biopolitics in the form of settler homonationalism\n",
      "Sample 362 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> oh you mean odumba the admitted mussie and admitted he was born in kenya and those are easy to find in a search\n",
      "Sample 363 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  vikings fared far and wide to byzantium and baghdad and beyond nothing shocking about this discovery or earlier ones about hauls of arabic coins and a ring with allah engraved on it stone shocking part is how these things will be used in justifying moslime presence in scandinavia now\n",
      "Sample 364 / 1008 : Prediction = 0  Saved:  0 Correct label:  2\n",
      "Text:  corrupt moslem cop covering up protecting moslem attackers of a white british woman only one way to sort this lot it not petitions or protests moslems are the problem\n",
      "Sample 365 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> can not fight for shit lmao literally arabs can not fight for shit\n",
      "Sample 366 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  common sense says the solution to every problem in the world is white men jews say the problem with everything in the world is white men it would seem that jews are a problem\n",
      "Sample 367 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  islam belongs in pakistan bangladesh indonesia middle east gulf states north africa not with white people\n",
      "Sample 368 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  <user> i adore the plump all white one reminds me of one of my boys <happy> i tried one of those kobo sp dog treat dispensers and my lot just ate through it to get at the treats lol love how happy they all look x\n",
      "Sample 369 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  some dykes be grown as hell dressing like they mom said they not allowed to get boy clothes ðŸ˜‚\n",
      "Sample 370 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> honestly to get to the point where someone would think muslim is a language islam is a country like what white media info have yall been exposed to\n",
      "Sample 371 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  chrisf206 chrisf206 <number> hours ago watch some episodes of cops and tell me blacks are being singled out for no reason ghetto blacks are fuck ups plain and simple ï»¿\n",
      "Sample 372 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  nigger has expressed no personal christian experiences attended a madrassa wears a moslem wedding ring praises the shahada call to pray ports a moslem name registered by stepdad as moslem indonesian many photos of him in moslem rituals garb admitted moslem faith on tv\n",
      "Sample 373 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  if famous black millionaire athletes can not love this country that pretty decisive proof that blacks will never peaceably coexist w whites\n",
      "Sample 374 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  or like the right amount of horny but not for lesbians\n",
      "Sample 375 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  <user> scared for right wing terrorists who are in hundreds while islamists are in millions yet roam free\n",
      "Sample 376 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  sickening time to intervene these are refugees we need to help\n",
      "Sample 377 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  clint eastwood is a conservative director i think he used to fuck a nigger though is used to fuck a nigger proper grammar i am having an appalachian moment\n",
      "Sample 378 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  is that what is going on felt like i have been shouting down a well and everybody went on vacation for a second i thought my poasting had suddenly become more retarded than usual eh maybe it has\n",
      "Sample 379 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  <user> must be noted chinaman satanist lee hsien loong refuses to respond to all accusations against him and reference to his satanic criminals singapore parliament singapore supreme court and singapore agc have also kept silent since my first twitter account in <number>\n",
      "Sample 380 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  i mean muslims are sand niggers regardless or just niggers\n",
      "Sample 381 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  fbi needs to be dissolved see there this thing called the internet where state police can share information fbi has been abusive since the dress wearing homo hoover\n",
      "Sample 382 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  i am a neo nazi republican\n",
      "Sample 383 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  all tea all shade bitch all offense\n",
      "Sample 384 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  and people like you and your ilk who call people kikes niggers spics sand niggers and mud sharks dumb fuck\n",
      "Sample 385 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> reported for targeted harassment\n",
      "Sample 386 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  whose hiding i am right here bro that me in that picture to the top left or some kike who looks like me i can not remember too much drinking and too cheap to buy a mirror anyways i ain t hiding show yourself you pussy\n",
      "Sample 387 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> one of my takeaways from islam <number>\n",
      "Sample 388 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <date> can not wait to start wearing more and going out less like a slut\n",
      "Sample 389 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  if the hoe wanna hoe then let it go\n",
      "Sample 390 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  these fucking faggots be outta line son -.- every year these mf get more comfortable and comfortable in disrespecting straight man like i will not slap the shit out of mf disrespecting me ðŸ˜‘ and best believe im out too dumb ass mf\n",
      "Sample 391 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  every beaner now claims to be an american indian so you never know\n",
      "Sample 392 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  i can only assume that our govts are corrupted by saudi qatari money and in return have promised to put muslims above every non muslim citizen that the only thing that makes sense which means next ge we have to elect an uncorrupted govt\n",
      "Sample 393 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  bro i really hate that damn naruto op by kana boom now niggas used it way too much\n",
      "Sample 394 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  <user> you surely like to suck on conor balls do not you you fucking faggot\n",
      "Sample 395 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> mislims r brothers to each other rich muslim countries should support poor islamic countries it investment without any loss\n",
      "Sample 396 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <number> <number> child refugees in sweden are adults\n",
      "Sample 397 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  daily reminder that any self proclaimed lolbertarian who does not like hoppe is a faggot and a disgrace real libertaryans were always politically incorrect\n",
      "Sample 398 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  hop sing no jew yes but i bet they looked for a jew to play his part then came to conclusion we can not find a jew that will fit the role okay let us get a gook at minimum wage\n",
      "Sample 399 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  lol why why should i move just becos there is nazi morons here in germany\n",
      "Sample 400 / 1008 : Prediction = 0  Saved:  0 Correct label:  2\n",
      "Text:  raccoons are best coons\n",
      "Sample 401 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  the nazis were not a western phenomenon they were a reality based collective response to the recognition the jews were attacking us as a team and planned for all our nations the murderous misery they first accomplished in the ussr\n",
      "Sample 402 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  as the zionist controlled tech industry marginalises the voice of white interests i have applied for refugee status at gab first they came for dailystormer then they came for stormfront next they came for cuckservatives moral is stop punching right as you will be next\n",
      "Sample 403 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  <user> yeah can not really pretend you are not a bigot when your both sides are bad poem does not say shit about the rise in white supremacist violence and hate crimes but goes out of its way to paint outrage and accusations of false racism as the real problem\n",
      "Sample 404 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  on one hand i kinda like the safety of living in deep south country on the other hand there not enough ghetto rats to try and riot so i do not get open hunting season when they try to start the next civil war\n",
      "Sample 405 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  nyc bomber dam i burned my dick off wow now i am a transgender muzzrat now deblasio will pay me twice as much\n",
      "Sample 406 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  i think most of those women do not have men at home that is their problem\n",
      "Sample 407 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  this muslim scammer harassed me all day yesterday when i got fed up told him to go fuck a goat <user> locked me out of my account fuck twitter\n",
      "Sample 408 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  sadly jews have concentrate their extermination of white people un this kind of countries cause they hate blond purity for them every white girls have to be gangbanged or raped or stupid enough to have brown subhuman sperm in their womb to make the white genocide by race mixing unstoppable\n",
      "Sample 409 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> lol pelicans are retarded\n",
      "Sample 410 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  sterling is a fucking retard\n",
      "Sample 411 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  this bitch kenny got my key i can â€™ t emuss lock the damn door\n",
      "Sample 412 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  thanks to zayna my entire tl is arabs fighting about marriage and standards\n",
      "Sample 413 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  member when ben carson the brain surgeon was called a coon and uncle tom by lefties\n",
      "Sample 414 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  tfw you hate yourself for no reason gt\n",
      "Sample 415 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> <user> do you mean palette you utter hillbilly\n",
      "Sample 416 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  sorry tom you are wrong the qur an haddiths sanction rape mohammed himself raped many women including the <number> year old aisha he was poisoned by a jewess he had raped after murdering her husband the qur an encourages the rape of unbelievers it is the religion of satan\n",
      "Sample 417 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  the holocaust is widely believed even by nazis like me gasing jews or napalming vietnamese lacks knightlyhood i e is detestful\n",
      "Sample 418 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  meeting with chuck and nancy today about keeping government open and working problem is they want illegal immigrants flooding into our country unchecked are weak on crime and want to substantially raise taxes i do not see a deal president djt on twitter\n",
      "Sample 419 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  my grandpa keeps asking me when i am going back to visit his conservative hometown <sad> the harassment was bad with my big hair and now that i am visibly read as queer bc short hair ðŸ¥´ ðŸ¥´ ðŸ¥´ ðŸ¥´\n",
      "Sample 420 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  <user> talmud according to jews is just men commentary qur an according to muslims is literally the word of allah god we have to attack the qur an first because jews are not flying into buildings killing people plus is obvious no god would make so many mistakes as shown in qur an\n",
      "Sample 421 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  i am shocked at he fucking refugees in our news media\n",
      "Sample 422 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  the only claim to fame that jews have is to be the people rejected by god\n",
      "Sample 423 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  their blood most definitely is on trudeau little beta male hands if motion m <number> becomes a bill it will protect these fucking muslim terrorists when they attack us we will be expected to shut up and put up with it or we will be the ones going to jail\n",
      "Sample 424 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  a little still learning not many speak it anymore lots speak arab and nigger though <user> is amadÃ¡n\n",
      "Sample 425 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  we really finna elect biden with the appalling amount of rapey advances he made on camera with literal children damn lmfao\n",
      "Sample 426 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  bitches this pretty thats seldom\n",
      "Sample 427 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  maybe you should stop spinning dreidels and freebasing pennies while you larp as some paki thot\n",
      "Sample 428 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  nonsense obama could do what he wanted because there was no opposition and no judges over ruling him trump is opposed by dems republicans all levels of judges the media the bureaucracies the deep state and his own kike cabinet and shysters and family\n",
      "Sample 429 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  <user> <user> <user> <user> <user> <user> i am not saying that at all what i am saying is that during that jim crow all black people had an understanding that white supremacy was the biggest threat now immigrants come here to compete against everyone else they do not recognize our continual struggle\n",
      "Sample 430 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  there fluoride in the water so i am not stupid because i am a lazy faggot i am stupid because jews made me this way and i can not fix it\n",
      "Sample 431 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  i am still sad i have been trying to make my phone work so it will take pictures the rooftops are all white in my neighborhood and it so lovely i hate my phone right now\n",
      "Sample 432 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  so i heard some black tranny bitch said all white people are racist she got fired from l oreal for her comments which i am so happy about it about time an anti white asshole suffered from her actions race bating scum should not have any respect among their peers\n",
      "Sample 433 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  cassie pregnant all the twitter niggas mad about it lmao you all niggas weirdos\n",
      "Sample 434 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  <user> i would also say that not too bad considering the country got raped by the us\n",
      "Sample 435 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  boy are you out in the weeds beau the pompous ass is max boot the russian immigrant that takes himself way too seriously how about you ratchet it down a bit ask for clarification before you attack someone squarely on your side of the aisle\n",
      "Sample 436 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  new term when gettin pull over by cops do not make a stupid nigger move running reaching in pockets just talking back all white or black gets your shit in big doo doo lmfao ðŸ˜‰ ðŸ¤— ðŸ¤— ðŸ¤—\n",
      "Sample 437 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  litterally standing in line waiting while these two sheboons argue over there fucking allowed ounces of cereal on there w.i.c benefits\n",
      "Sample 438 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  i actually just posted about her earlier women who are resourceful can whip a mans ass or <number> romans\n",
      "Sample 439 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  see i agree with that <percent> the key is choice it <user> who does not seem to believe in choice she thinks everyone should be like her i disagree she also thinks it ok to call people dykes and faggots so we disagree on multiple fronts\n",
      "Sample 440 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  <user> bobby fischer playing spassky in the near future in the meantime a little retarded boy tries to compete no one cares little retarded boy throws tantrum no one cares little retarded boy shits on the carpet fischer calls hotel maintenance staff\n",
      "Sample 441 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  sweden decided in <number> to welcome immigration since <number> violent crime in sweden has increased by <number> and rape has increased by <number> sweden has some of the most beautiful women on the planet and they let them get raped by evil muslim immigrants gabfam maga europegenocide islam\n",
      "Sample 442 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  herding the undesirables into electronic ghettos can not wait til it swings back the blacks n jews way see how they like being tossed into electronic ghettos being deemed offensive good ol days when america was america\n",
      "Sample 443 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> speaking of i am planning on drawing a poc angel and white devil artwork soon ðŸ˜Œ\n",
      "Sample 444 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> have you seen the demisexual flag w the triangle i fucking hate it its like stolen holocaust symbology\n",
      "Sample 445 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  <user> lmao bitch retarded tryna call us broke bitch you got finessed ðŸ˜­ ðŸ˜­ ðŸ˜­\n",
      "Sample 446 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  pathetic but yet most likely supports the violence that hollywood puts out\n",
      "Sample 447 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  gndmdm my classmate asked me if my wallpaper was my drawing i have a drawing of asami as my wallpaper now and it is f gay and i was like ah no but i like the character lmao\n",
      "Sample 448 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  everyone wants to be nct everyone the entirety of kpop if they dont wanna be niggers they wanna be nct\n",
      "Sample 449 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> <user> and whenthat does not work when women are being raped just do nothing and say well we will work on prevention instead of trying to get justice and taking a perp off the street\n",
      "Sample 450 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  excuse me ma am does your nigger ass have a moment to speak about the day of the rope day of the rope\n",
      "Sample 451 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> the police snapper is aiming to kill all protestors or make them permanently blind ðŸ˜¡\n",
      "Sample 452 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> rehne do she is mentally retarded\n",
      "Sample 453 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  i have watched edl for a long while it now looks like a revivification of overtly fascistic national front skinheads neo nazi and exploits opposition to islam to advance white supremacism this i oppose almost as much as islam it not what my grandparents generation fought died for\n",
      "Sample 454 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  latinas the best women\n",
      "Sample 455 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  look at this bitch she can afford luxuries i hope she gets raped oh what that she was raped and murdered and the guy ate her tongue serves her right what a bitch\n",
      "Sample 456 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  saw jake tapper trying to grill kellyanne conway by asking her if trump tweets about commie cunt alec baldwin weekly snl mockeries are presidential the whole presidential idea is just a tool used by media jews to hamstring white politicians trump counterattacks and folks love it\n",
      "Sample 457 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  <user> yeah lil white boy got them moves lol\n",
      "Sample 458 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  <user> it means that they hate gay people but feel uncomfortable admitting so in front of a queer person\n",
      "Sample 459 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  not if you have a weak stomach or a need to hear about what he would like to do to women as in multiple in his sex life he a low life degenerate he thrives on attention any kind kincannon\n",
      "Sample 460 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> no kill yourself ontop fpl guy\n",
      "Sample 461 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  why don â€™ t we make a separate country for illegal aliens and call it mexico\n",
      "Sample 462 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  curse boycott queer mercedes benz their fake luv tranny fag dyke ad sickens they are promoting homos dykes trannies to curse canada now the western world has become sodom\n",
      "Sample 463 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  u hate talkin to the only nigga that can heal u\n",
      "Sample 464 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> <user> gangs give other bikers a bad name or white trailer trashed ect\n",
      "Sample 465 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  it is very easy to criticize white activists if they are doing something stupid like fighting other white activists because they are from a different socialist gang\n",
      "Sample 466 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  just saw a fella with full on nazi skull tattoos in b& q\n",
      "Sample 467 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  they either pick the gimmick light skin bitch or the white boy to profit off of and it never works\n",
      "Sample 468 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  niggas be so sensitive acting like bitches\n",
      "Sample 469 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  let us not forget coke ceo is a mudslime and the pepsi one slandered trump have not purchased the products since\n",
      "Sample 470 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  <user> the immigrants that wanted to create a land for immigrants\n",
      "Sample 471 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  funny how smart people can make retarded faggots look even more retarded fuckbees stbhwn\n",
      "Sample 472 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  it does not bother me it is rather amusing to see someone like yourself claim to be intelligent then resort instantly to baseless accusations when proven wrong you communist jews are all the same\n",
      "Sample 473 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  <user> <user> <user> lord almighty thank you for the peace that comes when a predator feels your wrath very historic indeed no other african american comedian has raped a lesbian to expose his serial rapist past and expose the enablers who praise the false idol he in prison praise jesus ðŸ™\n",
      "Sample 474 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  also the conflation of immigrants with minorities is misguided it something the right does that the left should avoid\n",
      "Sample 475 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  bitch sun dyke moon cunt rising\n",
      "Sample 476 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  my roommate lowkey the hitler of arabs\n",
      "Sample 477 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  literally i just got scammed by my mum she told me she will prepare fried rice and chicken if i come back from school just at me am here eating white rice and stew ðŸ˜“ ðŸ˜… happy independence to you all african mum nigeria independence\n",
      "Sample 478 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  can we call an ideology that governs a state a religion is not it that a religion is to be separate from the state can we not discriminate against immigrants who want to implement a religious state in a country where that is not allowed or legal maga\n",
      "Sample 479 / 1008 : Prediction = 0  Saved:  0 Correct label:  2\n",
      "Text:  now i know you are lying because the shit you are pulling here do not fly on that faggot ass website it has not for a long time\n",
      "Sample 480 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  so a kike banned you from twitter and you come over to a platform full of jew hating nazis to complain about nazis what the fuck\n",
      "Sample 481 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> od leave them white devils alone\n",
      "Sample 482 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  the solution to save the white race is clearly to vilify women and not have children after all who wants the burdens of marriage like our dumb ancestors they should have probably just chosen to stroke it out rather than continue on our race\n",
      "Sample 483 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  <user> you go by gay f word as well right\n",
      "Sample 484 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  oh cause i thought a nigga who sound amp look gay said sum\n",
      "Sample 485 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  sweden suicide is a foregone conclusion no amount of tweeting raging philosophizing or praying is going to do diddly squat for them so why bother our energy is better spent arming and insulating ourselves from the muzzrats here\n",
      "Sample 486 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  the court system here is a fucking joke\n",
      "Sample 487 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  do not even talk to this nigger <user> you do not have to defend a thing to him jesus he calling our men dickriders ffs everyone knows that black males do nothing but dickride does anyone even know what that means it sounds nasty\n",
      "Sample 488 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  <user> it a traditional lutheran church serving estonian immigrants in southern california since <number>\n",
      "Sample 489 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  my <number> year old aunt got banned from facebook for posting stuff about islam and posative things about trump aussies for trump\n",
      "Sample 490 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  as a white male i am not allowed to call a nigger a nigger even though a nigger is allowed to act like a nigger and call me anything he she it wants to what stupid coward pc assholes whites have become\n",
      "Sample 491 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> play it its actually really fun kinda above my skill level but i luv how it looks also cloud is a depressed gay\n",
      "Sample 492 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  normal in nigger land\n",
      "Sample 493 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  btw isps are every bit as kiked and kike owned as social media and can censor much more severely by blocking sites entirely since isps are already cartelized and small isps cannot enter the market easily there is no alternative if internet becomes tv <number> and wrongthink is outright censored\n",
      "Sample 494 / 1008 : Prediction = 0  Saved:  0 Correct label:  2\n",
      "Text:  so holocaust denial is now a crime in germany and the jews at aipac are now pushing for american laws that make it illegal to boycott israel then i say it is open season on jews once again fuck their shapeshifting perfidious seditious tribal destructive ways jewishfilth\n",
      "Sample 495 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  vox does fine on his own and if your boyfriend balls drop enough for him to show up to the debate everyone will see what a retarded monkey <user> really is by the way do you know what <number> will buy in thailand\n",
      "Sample 496 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> <user> the wall is being built despite the dems love for illegal aliens voters they do not even want voter id that insane dems let them in faster than they are deported and then hide them in sanctuary cities ars are no different than handguns capacity is the issue\n",
      "Sample 497 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  <user> pakistan and bangladesh were seperated on islamic state issue but religion other than islaam became minority there if they are coming to our country as a refugee we should accept them other than islaam bcoz country they r coming from is islamic\n",
      "Sample 498 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  dmtbka mudshark problems nigger word kills <number> year old\n",
      "Sample 499 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  <user> i fucking hate you but i love you\n",
      "Sample 500 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> they convicted her because to let a white person shoot a black person in their own apartment and not convict would have led to riots\n",
      "Sample 501 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> <user> ffs hundreds of white girls raped by muslim men and everyone is getting worked up about a non provible politically convenient story from <number> years ago\n",
      "Sample 502 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> <user> sweden is on it way to become the first muslim country in europe so she will going to have a very difficult life ðŸ˜‚ ðŸ˜‚ greta thurnberg\n",
      "Sample 503 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  islam isis finally admits its leader abu bakr al baghdadi is dead think this is about 1 0 0 th time this islam terrorist leader has been confirmed dead rem mussie ohell creator of isis let him out of gitmo to become isis leader used asswipe yes both of them <user> <user>\n",
      "Sample 504 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  maria bartiromo at record speed and extremists have to host refugees as this administration over <number> legislation approvals\n",
      "Sample 505 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> they are not immigrants they are criminals\n",
      "Sample 506 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> yes its right kashmiri muslims who raped pandit women killed them looted them took their land and homes have to suffer more <number> years pandits have suffered <number> months at least they should taste the fruit of their deeds eat stones what you were throwing at forces fati na\n",
      "Sample 507 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  i love how south african women go so hard for each other because nobody especially cishet black men is gonna back us like us\n",
      "Sample 508 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  some nigger gas lighted some other nigger in some niggers pm and associated us with other niggers and anglin took the bait\n",
      "Sample 509 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  justin trudeau the traitor against canada deserves to be drowned slowly in a large pot of shit out of he asses of <number> jihadi terrorist that he let back in our country illegally\n",
      "Sample 510 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  justin trudeau is a faggot who loves muzzies more than canadians i have heard he is a convert to goat humping\n",
      "Sample 511 / 1008 : Prediction = -1  Saved:  -1 Correct label:  2\n",
      "Text:  niggas is faggots bidding like that if u ask me\n",
      "Sample 512 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  the noodle is muzzy looks like lol off to dr appointment see you in a few ðŸ¤— ðŸ˜Š ðŸŒž ðŸŒž âœ¨ âœ¨\n",
      "Sample 513 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  also benefits outed taxpayers money being spent on these inbreed moslem shite depleting monies available for nationals of this country and every country they inbreed in\n",
      "Sample 514 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  i love alt j but i think it â€™ homophobic for a white man to make me listen to alt j\n",
      "Sample 515 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  any truth to david shurter claims that he was once raped by antonin scalia that scalia had his throat slit by a <number> y o boy he was raping the night of his death was scalia involved in pedophilia too\n",
      "Sample 516 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  <user> <user> i did not use a disease to vilify anyone i did not bring disease up read the chain i brought up smoking and then was told that smoking was wrong because it had health affects but that gay sex did not have health effects that how the topic came up\n",
      "Sample 517 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  a revolution without guns good luck with that this little faggot comes knocking on my door its not going to end well for him or his little tree hugging commie class mates\n",
      "Sample 518 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  blacklivesmatter desperate to create their rfid chip black slave new world order where theyll ban cash and pay blacks with food only jews tell them they are the future just help us get rid of white people\n",
      "Sample 519 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  <user> they found the violent nazis organizing the riots\n",
      "Sample 520 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  well if they arent rabid liberal leftists maybe a strong privately done vetting process needs to be conducted dont wanna have potential arabs comin out\n",
      "Sample 521 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  specific threats of violence should never be permitted kill the honky is allowed as it is interpreted as political speech kill that honky at <number> main street is a specific threat and should be banned\n",
      "Sample 522 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  <user> <user> mate i have never had much luck finding faggots on a night out\n",
      "Sample 523 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  spiderland also hitting different in the fall\n",
      "Sample 524 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  bernie has his fucking issues i do not trust anything warren says beto is a fucking failure already why is he running kamala is a cop buttigieg is a rich white gay i do not trust a single one abolish the presidency\n",
      "Sample 525 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  <user> superfluous violence ðŸ˜±\n",
      "Sample 526 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  hillary clinton with dyke roomie back in the latter <number> still a rotten bitch today\n",
      "Sample 527 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  the big showy anomalous attacks with fema fingerprints all over them have changed from being about islamic immigrants targeting special treatment groups to being about left wing extremists targeting whites republicans wonder what we have to look forward to in <number>\n",
      "Sample 528 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  the terror attack in las vegas is only the beginning if you stupid americans refuse to wake up and take action america will look like sweden in a very short time if you do not elect good people into office and protest radical islam\n",
      "Sample 529 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  what an nfl ðŸ˜‚ all this over a racist black thug in furgeson who lied about a white police officer for fun the same injustice that blm supposedly stands against ðŸ˜‚ how many racist policemen were defending ft mchenry when our anthem was written makes sense huh ðŸ˜‚\n",
      "Sample 530 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> we dont have a coherent refugee policy when we have such high levels of poverty should state resources be expended on our own poor people instead of poor people who arent even our citizens\n",
      "Sample 531 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  another ignorant yank the injuns are immigrants like us fucking mongoloids from asia just like jews but they were immigrants not kike landsquatters\n",
      "Sample 532 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  not long till the first incident of black mob violence on richard branson private island if he keeps letting hussein bongo and his crew visit they will call it little haiti\n",
      "Sample 533 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  despite living in the same american neighborhood for decades i somehow managed to move to a muslim country i base this on having gone food shopping today in a store over run with hijab clad terrorists\n",
      "Sample 534 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  high school relationships are like leeches they suck the life out of you datings gay\n",
      "Sample 535 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  for the queer readers you deserve every adventure nina varela baby i already love u so much\n",
      "Sample 536 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  if i leave her she gon die well bitch you done wit life\n",
      "Sample 537 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> <user> <user> and islam 7 th century outdated ideology created by arabs has no place in 2 1 st century\n",
      "Sample 538 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  justice is a bitch if you are a criminal lol\n",
      "Sample 539 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  i am ashamed that bill hillary are white they are a disgrace to their white skin they do not represent my race they are ghetto as al sharpton and jessie jackson or mlk\n",
      "Sample 540 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> <user> you all know that my white ass can not handle spicey foods\n",
      "Sample 541 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  i support trump <percent> and i think he knows that britain needs a trump like the dyke needed that little boys finger\n",
      "Sample 542 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  why does anyone care what the albino nigger has to say\n",
      "Sample 543 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  some spick kids scratched my parents car today and for whatever reason i did not call the cops and just scared them away\n",
      "Sample 544 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  people that use trending topics or hashtag to post their pics or nonsense tweets irritate me the ghetto\n",
      "Sample 545 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  open invitation to all queers to my christian island republic for public death 1 fags\n",
      "Sample 546 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  in mn that would be blacks and mudslime because that is who amazon is sending into white suburban neighborhoods i am surprised whites have not sued over discrimination in hiring because i do not see any hired\n",
      "Sample 547 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  kathy griffin is the ultimate liberal attack somebody and suffer consequences and she is the victim cunt needs to have some dick forced up he dyke ass barron trumps\n",
      "Sample 548 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  liberals won t face the fact that if anything the obama administration has condoned criminal behavior far above justice and has divided this nation with his racism muslim leanings and support of homosexuality putting the smallest fleas of society as the leaders of the nation\n",
      "Sample 549 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  i am more worried about muzzies and their proclivity towards raping killing random people and not sticking to their goats\n",
      "Sample 550 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  anal nazi terrorisist idiots fighting all ï»¿ just like the moisislem invasion ï»¿\n",
      "Sample 551 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  i d explain this way muhammad arab followers after his death killed his only heir ali whose followers today r shiites east from iraq arabs went west at first and they want caliphs sunnis and they use terror against shiites us etc nether considers the other sect actually real muslims\n",
      "Sample 552 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  thornton heath croydonistan has been transformed form a nice middle class suburb into a shit hole of black gangs drug dealers moslem scum recent arrest connected to parsons green cultural enrichment has made uk hell needs to be cut out like the cancer it is\n",
      "Sample 553 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> did not know what a nazi salute was that because all the left wing media paint everyone as nazis\n",
      "Sample 554 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  <number> of white women are just awful\n",
      "Sample 555 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  do not blow your horn at me cuz you can not drive bitch\n",
      "Sample 556 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  what is behind the treasonous uk govt actions mooslim oil money or jewish money\n",
      "Sample 557 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  they are only <number> of the world population and trying to pretend that obama jarrett clintons do not love the muzzies more than the jews is just laughable but you keep laser focused on those jews ok someone has to stay behind\n",
      "Sample 558 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  we have several generations of women utterly incapable of making even the simplest sandwich\n",
      "Sample 559 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  last night i was kind of drunk and held up a steadfast sieg heil the entire time some nigger was walking past me on the bus it was gratifying\n",
      "Sample 560 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  john hughes was the king of white movies\n",
      "Sample 561 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  and another thing if blacks are so great how come your anecdote puts all of them behind the counter in a retail service position you did not mention your black bank manager giving you a loan\n",
      "Sample 562 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  if it had been a shitskin goatfucker from the mosque do you think they would have arrested him nope\n",
      "Sample 563 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  potus do you believe it the obama administration agreed to take thousands of illegal immigrants from australia why i will study this dumb deal maga obama aussies immigration\n",
      "Sample 564 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  like this retarded idiot on tv she in palacios where there was a mandatory evacuation with most roads flooded and getting worse she all i have never been through a hurricane or a tropical storm before so why did you ignore a mandatory evacuation idiot\n",
      "Sample 565 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  my new bit is saying <number> million jews died in the holocaust and logging off\n",
      "Sample 566 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  percentage manufacturing crime sends them to the rightabout the devil on moneylenders gave reuben j a great strawcalling now he really what they call a dirty jew power those judges have crusty old topers\n",
      "Sample 567 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  you are a fucking fat retarded faggot\n",
      "Sample 568 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  disrespect islamic n its teachings\n",
      "Sample 569 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  she was also the best player and second top goalscorer with the super falcons who won the <number> <number> <number> african women championship october 1 st making nigeria proud sunday dare nigeria independence\n",
      "Sample 570 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  i will ask but i doubt she will go for your ghetto trash ass when she could get a black dick that attached to someone with money instead of a crack habit\n",
      "Sample 571 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  and with jews you lose right lots of jews around trump you need americans with a solid us ancestry around him each having several degrees of separation from any business or personal connections with jews guaranteed no shabbas\n",
      "Sample 572 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> basically made a towelhead joke about punjabi ppl ðŸ˜\n",
      "Sample 573 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  i slapped my liberal uncle like a bitch nuff said\n",
      "Sample 574 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  how many islam political ideology followers are also animal activists\n",
      "Sample 575 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  you can not expect a minority immigrant refugee to understand the intricacies of american racist rhetoric\n",
      "Sample 576 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  i agree with you it all boils down to girl woman upbringing but point is that only a white man would do something like this not beaner or nigger or whichever other species of coloreds\n",
      "Sample 577 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  dese two dykes on fb arguin postin each other pics callin each other ugly sb den commented you all havin a dyke off im ctfu\n",
      "Sample 578 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  yes yes yes we have been suspicious for years how many conservative federal judges secretly take nigger dick up the asshole <number> days a week how many conservative reps senators secretly total pedo homos who has the video evidence of it that could ruin their careers\n",
      "Sample 579 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  it is impossible to raise the nigger to the cultural civilzed level of the white this race is genetically inferior animal that will always remain at best second rate\n",
      "Sample 580 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  sheryl sandberg is not a proto feminist anyway many do not like her because her experiences are indeed very <percent> er but like are rich women supposed to not be feminists should the be opposed to full equality of opportunity it just seems like a silly pot shot at successful women to me\n",
      "Sample 581 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  <user> <user> you â€™ re such a retard\n",
      "Sample 582 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  ðŸ˜‚ ðŸ˜‚ ðŸ˜‚ i could just imagine at least i know not to cross you i will nickname you the muzrat killer ðŸ˜‚ ðŸ˜‚ ðŸ˜‚\n",
      "Sample 583 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  does anyone know what actual asians i mean the oriental types think about all of the persians and arabs being called asians by most of europe media does it piss them off as much as it does the rest of us or even more\n",
      "Sample 584 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> read the koran its not allowed for muzzie to convert\n",
      "Sample 585 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  i do not like being on the phone with anyone and them telling me i am wrong lmao like i am pissed ðŸ˜© ðŸ˜© i hate faggot ass mf bro on god\n",
      "Sample 586 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  few weeks back he quoted a statistic from the government regarding the percentage of paki muslim men involved in rape of young children\n",
      "Sample 587 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  of course if you are a homosexual clothing designer or activist you seek to design women clothing in such a way that regresses women to a state of looking like little boys is that healthy well to leftists it is this too shall pass maga redpill\n",
      "Sample 588 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  <user> police girl as dick cop faggot officer maggot\n",
      "Sample 589 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  our muslim terrorist treasonous arab ass kissing state dept is making sure that trump will not do this after all kissing arab and muslim ass is far more important than us national security\n",
      "Sample 590 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  <user> they probably regularly say they all look the same they being whichever loosely defined group is being targeted mind i have just done the same\n",
      "Sample 591 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  <user> karma is a bitch\n",
      "Sample 592 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  they are probably all homos anytime a guy acts all tough overcompensating comes to mind plus their behavior puts them in a locked facility surrounded by all males buncha queers whose parents failed to beat the living crap out of em when they were kids overly permissive absent parents\n",
      "Sample 593 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  <user> <user> sikhs get called towel head by racists all the time to have someone from a sikh family do the same is ridiculous\n",
      "Sample 594 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  first we sat by watching photos of yazidi women and little girls being sold as slaves refusing those who escaped refugee status in europe and usa now us can send money for moslem refugees who caused their problem but not for christians who really are the victims\n",
      "Sample 595 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  <user> let start global nuclear war holocaust <number>\n",
      "Sample 596 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  how are you going to mess with a bitch that looks up to me ðŸ’€\n",
      "Sample 597 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  they send their best and brightest to europe and america for education obviously becuase they sand niggers and gooks have the best universities and are oppressed by the evil white man learning institutions it is our learning institutions that oppress the brown nigger people\n",
      "Sample 598 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  hopefully the alt right went armed and defended themselves shoot a few antifa faggots center of mass the rest might learn we do not have to take this bullshit from the left\n",
      "Sample 599 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  reverse it west yorkshire police are so good at their job no child raped by paki muslims on their watch asif\n",
      "Sample 600 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  the blackguard pretends to be a barbarian at heaven\n",
      "Sample 601 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  note how the students mentioned in this article all have foreign names middle eastern african likely moslem yet the vast majority of rural uk is white british these are the people who need to commute often with poor rail bus services cities with good commuter services are full of immigrants\n",
      "Sample 602 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  unfortunately unless right wing parties get <percent> the others will form a coalition to keep them from power carry on the moslem cock sucking ruination of sweden moslems are the problem\n",
      "Sample 603 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  it obvious when 3 rd world moslem refugees are welcome and the tourists are not it means barcelona has become a no go zone it will only get worse as the weeks and months go by\n",
      "Sample 604 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  not once have you refuted my arguments you ran from the debate like the faggot you are i stole your dinner money gave you a wedgie and stuffed you in your own locker ðŸ¸\n",
      "Sample 605 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> he has worms them niggas nasty\n",
      "Sample 606 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  <user> <user> <user> there is a big difference between illegal immigrants and refugee all illegal immigrants should be thrown out regardless of their religion but refugee should be taken care of period\n",
      "Sample 607 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  no surprise homeland security added white supremacy as a terrorist threat prior to it lol conspiracy brotha\n",
      "Sample 608 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  bitch you could love me you cross me tho ima show you tho bitch ass boy\n",
      "Sample 609 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  p.f. chang is the asian applebee\n",
      "Sample 610 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  israel home of the jewish people arabs jordan u may know that israel was promised to the jewish people well b4 ur saviour came or any arab knew where israel was clue it is in the chumash pots melamed and ps u can call me sir\n",
      "Sample 611 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  thieving racist niggers and their stupid honky enablers\n",
      "Sample 612 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> i hope you are never kidnapped raped in a horrible accident because that cop that you were a dumb bitch to is exactly who you are gonna need to save you\n",
      "Sample 613 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  the democratic party now openly is anti semitic and hates jews jexodus\n",
      "Sample 614 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  andrew torba is a nigger faggot\n",
      "Sample 615 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  antifa domestic terrorists elderly people can be nazis kk being old does not exempt you from criticism terrorists murder people antifa has not killed anyone kk neo nazis white supremacists have killed thousands\n",
      "Sample 616 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  i find when i tell liberals about what is happening in europe with refugees and islamic invasion and how women girls m as well as young boys gays lgbt and everyone native in that country are being assaulted raped and abused it is very effective at turning liberals red trump pizzagate\n",
      "Sample 617 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> <user> shit thats a lot of white people in one photo pier would love that\n",
      "Sample 618 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  wise men say u a faggot\n",
      "Sample 619 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  the nigger loses hands down\n",
      "Sample 620 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> this is the twat who wants to start another holocaust in eire\n",
      "Sample 621 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  no one gives a fuck about this thread look at the response times keep letting a dwarf a sand nigger and a street shitter run marketing lol\n",
      "Sample 622 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  what the fuck does matt heimbach think he doing is he really punching right for a kike publication\n",
      "Sample 623 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  is that wooly nappy headed nigger in the nfl still kneeling down in front of the white fans cuz that was kinda funny ðŸ’\n",
      "Sample 624 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  the muslimban must be defended by trumpsters especially in america from the ridiculous backlash there should be calls to increase it only these straightforward shocking methods can get muslims and arabs to think and can create momentum in the us to properly handle immigration and terrorism\n",
      "Sample 625 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  no nigger in this blood stream\n",
      "Sample 626 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  some random nigger hotep berating me pardon if i blew up everyone timeline are not you glad you are not a nigger\n",
      "Sample 627 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  want to know the real bubble the usd under the fed we will remove the nigger fed\n",
      "Sample 628 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  do the democrats feel white privilege or white racists are the problem these retards are retarted\n",
      "Sample 629 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> you really are stupid there is no such thing as gun violence tell the truth you dumb shit call it what it is\n",
      "Sample 630 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  who gives a fuck what the liberals do oh is this some retarded we have to be better than the liberals thing fuck that we have to win moral victories are for losers\n",
      "Sample 631 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  u notice people like <user> are not too eager at exploring or talk abt the jewish and israeli connections the evidence for which there is plenty dancing israelis truck bomb jews urban moving systems jews suter wtc lease ring jews gelatine art students etc etc just arabs arabs arabs\n",
      "Sample 632 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  and what does that make you a hearsay peddling moron what is a kike anyway what label may i place upon your genius how about peasant\n",
      "Sample 633 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> let us some queer person goes on publicly to say that all straight people should be killed would it be ok because reverse homophobia does not exist ðŸ™„\n",
      "Sample 634 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> â€ will not talk to <user> â€ or <user> â€ because of bad optics but will go on a stream with kike doxxer laura loomer and talk shit on supposed tradthots you really are a pathetic piece of shit kid\n",
      "Sample 635 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> <user> fucking retard\n",
      "Sample 636 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  true but the most disgusting thing would be a muslim twerking a goat\n",
      "Sample 637 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  most criminals in france are moslem or from some shit hole in africa so\n",
      "Sample 638 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  wait what are we mad the queer eye dudes over i know theyre a bunch of milquetoast safe gay white dudes but honestly yeah i thoughts thats all they are lol annoying but not rage inducing did they do some shit\n",
      "Sample 639 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  where are the german men to protect this child and beat the living shit out of the muslim retards who are bullying him\n",
      "Sample 640 / 1008 : Prediction = -1  Saved:  -1 Correct label:  2\n",
      "Text:  4 ftsomething studs love tall women tho init\n",
      "Sample 641 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  that your witty comeback to whites in south africa why are they there is white countries are so great ðŸ¤· ðŸ» â€ â™‚ ï¸ ðŸ¤£ you dumb fucks are so inferior it sad\n",
      "Sample 642 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  jews will do anything they can to convince you not to read homer iliad and your glorious past of victory and unity because they want you to keep worshipping their compendium of civil rights victories where they convince blacks to attack whites also known as the old testament\n",
      "Sample 643 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  finally an emoji for faggots\n",
      "Sample 644 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  democrats are so retarded they might be eligible for disability\n",
      "Sample 645 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  trulay a pathetic unfunny zhid cunt\n",
      "Sample 646 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> protecting illegal aliens and not men and women in blue ðŸ˜¡ ðŸ˜¡\n",
      "Sample 647 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  <user> right wing violence the only things bully respect is power and they will be overpowered\n",
      "Sample 648 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> <user> <number> less boys being raped\n",
      "Sample 649 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  it an infinite regress of jews jewing romans jewing anglos jewing jews philosophy and logic cannot help us here\n",
      "Sample 650 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  autist sociopaths like yourself are always attracted to either sociopathic nazi movements or sociopathic islamic movements pick and choose bubbeleh\n",
      "Sample 651 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  sounds like a kike to me\n",
      "Sample 652 / 1008 : Prediction = -1  Saved:  -1 Correct label:  2\n",
      "Text:  i fucking hate gemini ðŸ˜‚ that it that the tweet\n",
      "Sample 653 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> happy birthday to one of the greatest muzzrat slayer may mahadev bless you and may you keep kicking these muzzrats n com rats in debate sir ðŸ™Œ ðŸ™Œ ðŸ™Œ ðŸš© ðŸš© ðŸš© ðŸš© ðŸš© jai mahishmati âœŠ âœŠ\n",
      "Sample 654 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  this coon is full of shit\n",
      "Sample 655 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <number> taxi drivers sentenced and <number> more suspended in newcastle for raping and grooming children why is not this headline news bbc i will tell you it is because they are all pakistani heritage muslims who single out white children to groom and rape ignored by our liberal elite\n",
      "Sample 656 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  proof of racial discrimination <user> reported a niglet arrested for doing it to a 6 month old\n",
      "Sample 657 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  i am praying that this world really see the mindset of this what would people call her it not one healthy human being does this white everything is white so as she loses as all these diverse nationalities it all once again a scam racially and anti gay\n",
      "Sample 658 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  u r right white is a misnomer there are irish english german swedish italian french swiss etc we must ban together yes the germans want to be german and the irish want to be irish so be it find our common enemy we must free our lands invaders out\n",
      "Sample 659 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  lggbdttibraappabcdefghijklmnopqrstuvwxyz now i know my lggbdttibraapps next time will not you gay with me\n",
      "Sample 660 / 1008 : Prediction = 0  Saved:  0 Correct label:  2\n",
      "Text:  jews were banned from american social organizations up until the marxist civil rights movement in the 1 9 6 0 the church banned jews from christian society for almost <number> years even romans and greek kept you dogs away from polite society are you retarded or what\n",
      "Sample 661 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  niggahs was sayin she to pretty to b actin like a hoe and dey <percent> rite ðŸ˜‚\n",
      "Sample 662 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  ok volks lets downboat this filthy kikess <user>\n",
      "Sample 663 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  my bitchass dogs are on a together rn ðŸ¥º ðŸ¥º ðŸ¥º take me to new york right this instant im sad\n",
      "Sample 664 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  mr trudeau you pledged <money> million to the rohingya refugee crisis while we have a refugee crisis of our own flooding into quebec that you will not address you pledged <money> million to caribbean reconstruction while our own infrastructure in cities is falling apart why vote 4 u\n",
      "Sample 665 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  so the blacks are into islamism abuse of the islam for their own political agenda i heard someone say niggers and the muslims are sandniggers is that family\n",
      "Sample 666 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  dumb idiot retard\n",
      "Sample 667 / 1008 : Prediction = 0  Saved:  0 Correct label:  2\n",
      "Text:  i bet most germans would rather be bored than raped and killed by migrant monsters\n",
      "Sample 668 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> oo what does it say about women\n",
      "Sample 669 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> good lock up the rest of the white devils\n",
      "Sample 670 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  i remember something to that effect gotta dig deeper for the pedo thing i may well have him mixed up with another yid with that name they are all demonic shapeshifters after all\n",
      "Sample 671 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  niggas get a knew outlook on life and think it okay to rekindle shit\n",
      "Sample 672 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  grew up in queens astoria was greek italian jackson height was waspy some hispanics forest hills was all wasp now all diversified hardly any whites most all asians hispanic mixed breeds only left are old white plp can not nearly walk neighborhood a mess rat traps in once beautiful areas\n",
      "Sample 673 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  <user> <user> have you actually spoken to immigrants about their experience of friendly australians or are you triggered by this statement you will find racism is alive and well here down under if you are not a white european\n",
      "Sample 674 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  a politico morning consult poll finds significant support for the raise act forty eight percent of voters support reducing the number of legal immigrants by half over the next decade compared to <number> percent who oppose that <number> of likely voters support the chain migration cuts in the raise act\n",
      "Sample 675 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  it ll work as long as you only arm the whites the niglets would just shoot all the white kids if they had guns\n",
      "Sample 676 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> i am telling u black ppl not all stay making fun of asians i see it all the time\n",
      "Sample 677 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  it be the unbothered bitches that be knowing everything you post ðŸ˜­ ðŸ˜­ ðŸ˜­\n",
      "Sample 678 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  painting these days ive gotten into using like two or three layers and merging as i finish but i still just alla prima that bitch\n",
      "Sample 679 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> they are retarded\n",
      "Sample 680 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  lol nice boomerposting hey does kike jism taste better on the shabbat you d know after all lol gimme more\n",
      "Sample 681 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  <number> if u saw someone naked u had to take ur wudhu again muslim twitter go off\n",
      "Sample 682 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  <user> if they all look like these who am i to block god blessings ðŸ˜Š\n",
      "Sample 683 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  this sumbitch is not part of wtp and <number> stupid motherfuckers liking his post these bastards are not awake for the goddam record all <number> billion of those goat fucking moslem bastards needs to be eradicated from the planet leave none alive from the womb to the tomb they gotta go\n",
      "Sample 684 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  i am hoping hillary and o think trump will not press charges so o dosent pardon her trumps new team can put that bitch and all the rest away\n",
      "Sample 685 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  fucking toxic weird ass retarded bitch\n",
      "Sample 686 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  they actually are true aryans racially speaking that is the root of the name iran they are not at all connected to arabs racially\n",
      "Sample 687 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  i believe the ashkenazi jews are white europeans the rest are just another variety of sand nigger\n",
      "Sample 688 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  all my nazi friends say sorry we are not being violent enough the left said they d pick up the slack and we said ok we just figured they could do the violence and we d do the thinking\n",
      "Sample 689 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  are you retarded or what\n",
      "Sample 690 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  a nigga that works hard to get his bag needs a girl that has a vision not a girl that likes to smoke and party\n",
      "Sample 691 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  <user> wow porch monkey ur mean\n",
      "Sample 692 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  white boys and ghetto white girls make me sick i can not stand you all\n",
      "Sample 693 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  shocker a little white boy flopping\n",
      "Sample 694 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <number> unlike the islamic world the west cherishes human life so we do not need muslims to teach us how to love <number> religious groups which facilitate refugee immigration are paid by the head making venture catholic lutheran churches lead in this operation\n",
      "Sample 695 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  something i have noticed in life every competent efficient person you d want running a local or federal government is inevitably in the private sector because meritocracy every mouth breathing sub par retard on cruise control you wish you could drown in the sea is in the public sector\n",
      "Sample 696 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  how much money would it take for you to lick a dogs asshole not very much considering you are a wetback\n",
      "Sample 697 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  <user> <user> please just learn the meaning of refugee illegals and indian citizens\n",
      "Sample 698 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  i said ignore not mute i am following you retard\n",
      "Sample 699 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  lol yeah i know what u saying refugees were living their lives there did not had reasons <number> seek refugee or bother people in other peoples countries its the kalergi plan alright empty greater israel then hope eu is gonna clash with all these different cultures religions so people will accept nwo\n",
      "Sample 700 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  as a honky mofo i hate honkies who hate other honkies just because they hate being honkies they ownselves sad is not it let us get a movement going move to mecca that should work well for lgbt and jews\n",
      "Sample 701 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  fox news is so desperate to change subject they are now talking about how robert de niro got upset waiting for his ride and how full of white privilege he is and oh how he used to be a good actor wow pitiful wtf tucker\n",
      "Sample 702 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  charwe in full nehanda charwe nyakasikana born <number> â€” died <date> one of the major spiritual leaders of african resistance to white rule during the late 1 9 th century in what is now zimbabwe\n",
      "Sample 703 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  why are so many jews in charge of all our media when they are such a small percentage of the population why is the media so anti american why is it not ok to talk about jewish ownership of our media why is it ok to mock whites\n",
      "Sample 704 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  tv a mental ghetto where thought goes to die\n",
      "Sample 705 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> facts smh dumb niggers\n",
      "Sample 706 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  this was a total bullshit rule housing is segregated by income more than anything this rule would force wealthy neighborhoods to allow section <number> housing be built in high end communities under the guise of diversity and equality bringing the ghetto to you\n",
      "Sample 707 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  food coop of olympia washington anti white propaganda they hate you\n",
      "Sample 708 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  <user> yeah because white people have to deal with mobs of hyper violent shitskins\n",
      "Sample 709 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  u genetic jews will not b genociding white adults and our white babies for much longer that what i predict anyway u filthy kikes bruce kenneway\n",
      "Sample 710 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  i don â€™ t wanna go to your homophobic fucking prom anyway\n",
      "Sample 711 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  didnt think some had minds sand niggers dont\n",
      "Sample 712 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  students interns employees should feel safe in their educational work environments which means that they must be actively anti racist against all forms of misogyny and queer phobic practices it horrifying to hear how harassment was handled and they need to do better\n",
      "Sample 713 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  when people have never had one real conversation with you but yet find <number> things to hate you about ðŸ™„\n",
      "Sample 714 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  if your humor is based on racism homophobia sexism and rape you â€™ re not fucking funny go home\n",
      "Sample 715 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  shaun king is the whitest black supremacist in existence i will never understand how someone that retarded has been allowed mainstream exposure what even worse is his following composed almost entirely of dumb teenage girls who believe that racial dating preferences are racist\n",
      "Sample 716 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  lmfao i have trs guys emailing me threats and shit had anglin in a chat stream once and i roasted him why are the kike kissers so worried about little ol me dude enoch is a kike get over it i am shaking in my boots over these threats faggot\n",
      "Sample 717 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> <user> this dude josh a racist ðŸ¤£ not only white ppl can be racist clown\n",
      "Sample 718 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  historical facts usually terrify those stuck in collective type mindsets the bell curve ignores culture which determines the direction of people southern whites up until the first world war acted no different than ghetto blacks until northern blacks fell for the welfare they outscored most southern whites on scholastic testing\n",
      "Sample 719 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  tommy robinson might do some good things when it comes to dealing with muslim rapists and child predators but his support of zionism and being a jew convert is cancerous anyone associated with him is a potential zionist shill imo\n",
      "Sample 720 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  <user> for millions of americans including many black americans abortion is literally a holocaust of the unborn\n",
      "Sample 721 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> is a faggot not an argument let that sink in\n",
      "Sample 722 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  no discussion of trumps amnesty support over at r the_donald of course there is <number> based nigger posts and this triggers leftists posts\n",
      "Sample 723 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  <user> <user> nordic countries have disturbingly high levels of muslim immigration\n",
      "Sample 724 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  another twitter refugee has arrived banned for standing up to snowflakes maga\n",
      "Sample 725 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  that why these sand niggers and other shitskins should be banned from this country\n",
      "Sample 726 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  he asked me if i wanted one and i tried to grab one but then he proceeded to pull it out of my hand well fuck you too\n",
      "Sample 727 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  you really are amusing obviously your mental capacity is so lacking your ego so overweening presumptuously arrogant overbearing so you do not need to look it up that you think women can not be intelligent i am sorry to threaten your view of your superiority but your views are pathetic\n",
      "Sample 728 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  yet when a couple of filthy dykes want you to pander to their sins as you see them you must comply by law time to start organizing for yourselves no one else is gonna do it for you\n",
      "Sample 729 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  paul jayda jailed meanwhile muslim preachers are free to spout their hatred unhindered the law is an ass\n",
      "Sample 730 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  free speech my ass it was terrorism and the incitement of violence say it name radicalwhiteterrorism\n",
      "Sample 731 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> sorry that paging dr faggot does not land anymore\n",
      "Sample 732 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  critcizes islam muslim twitter fucking bigot ðŸ˜’ ðŸ˜’ may allah guide you ðŸ˜­ ðŸ˜­ ðŸ˜­ straight to hell ðŸ˜¼ â˜ ðŸ½ ðŸ’¯\n",
      "Sample 733 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  bolshie louise publicly cuckolds her kike husband for a faggot libertarian cia operative who lost a presidential bid whadda girl\n",
      "Sample 734 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  yeah me too yeah you too yeah you bash blacks too and the chinks and the j00s dindu nuffins hindu muffins spics micks wops sand niggers who cares humans talk thats what we do so we should go kill each other please\n",
      "Sample 735 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  europes muzrat problem predicted to take a sharp sudden drop in numbers as soon as ordinary europeans have had enough go into open rebellion p.s. the uniform on junker should be a communist uniform not german ww2 germany was all about nationalism for their own people\n",
      "Sample 736 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  cursive was left out by the common core to bring everyone down to ghetto levels and destroy american calligraphy cursive will never die\n",
      "Sample 737 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  <user> <user> oh come on we all know that the democrats put illegal aliens first they do nothing for the american people resign pelosi\n",
      "Sample 738 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  niggas be hating on immigrants but don â€™ t even got a license bro u worried about driving away the wrong foreigns ðŸ¤¦ ðŸ¾ â€ â™‚ ï¸\n",
      "Sample 739 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  jews created communism <number> million stupid morons voted for the commie kike sanders\n",
      "Sample 740 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  another foreign born gay moslem\n",
      "Sample 741 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> is it possible to keep stephen miller from ever holding a government position let lone in the white house again this guy is a fucking psycho his dead behind the eyes stare is scary as hell i would not put anything past him\n",
      "Sample 742 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  tfw how the daily stormer protects a spic like he some kind of god\n",
      "Sample 743 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  the iq map shows the average iq in cuba is about <number> so at best idiot bot trudeau has an iq of maybe <number> only slightly mildly retarded it shows in his statements actions\n",
      "Sample 744 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  to the mans who angrily but lovingly yelled get a helmet you fucking faggot at me yesterday you right and i love you\n",
      "Sample 745 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  any news on that nigga lorenzo when he hitting uk\n",
      "Sample 746 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  team name washington warhogs team colors red white and blue team location washington dc team president anybody but bruce allen\n",
      "Sample 747 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  just remembered that renee is a lesbian the dykes won this one\n",
      "Sample 748 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  help a black lady i know had a white person plaster on her face we were chatting about it are there really no plasters for brown or black skin tone people\n",
      "Sample 749 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  pitbulls are not violent because violence is violence plus privilege plus power pitbulls can not vote marry or open a bank account in any state in the uska whatever they do is just chickens coming home to roost pitbullsocialjusticeapologetics\n",
      "Sample 750 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  qanon maga fakenews popefrancis administers final rites at cardinal law funeral as abuse victims speak out law resigned in disgrace as archbishop of boston in <number> after revelations that he covered up for dozens of priests who raped children\n",
      "Sample 751 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> <user> i â€™ m not on about your beef i was talking about calyko being retarded but yours also needs to stop\n",
      "Sample 752 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  ya it getting hard to normally function in many towns anymore with this ghetto mentality going on everywhere\n",
      "Sample 753 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  dawg i just seen a chinese dyke i did not even kno those existed\n",
      "Sample 754 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  two bros chillin in a hot tub five feet apart cus they are not gay\n",
      "Sample 755 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  u want truth democraticparty is controlled by leadership that wants to implant communism in usa they began by indoctrinating youth in public schools colleges america was not founded on atheism or muslim ideology it was founded on christianity the belief in god maga gabfam\n",
      "Sample 756 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  avdol your grandfather is a slut\n",
      "Sample 757 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  vietnamese are obviously asians mizoram and assamese with slanted eyes are clearly asians living assimilating in india they are not genetically indian what are you not understanding race is different from culture\n",
      "Sample 758 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  i be talking to the dumbest niggas alive ðŸ¥´ ugh\n",
      "Sample 759 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  <user> <user> but answer the question first ya islam mein sawaal puchna bhi haraam hai\n",
      "Sample 760 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  nigger and a chimp walk into a gay bar iran has nukes istandwithisrael\n",
      "Sample 761 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  no we are not immigrants on campus however are\n",
      "Sample 762 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  a nigga have a baby on me i swear i â€™ ll take out the whole family sorry not sorry ðŸ˜‹ ðŸ—¡\n",
      "Sample 763 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  a white man tired to slide the phase i was the nigger when describing his up bringing in japan tonight at dinner white privilege continues to be heavy people have such low level of compassion no one is hiding their racism anymore\n",
      "Sample 764 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  a chinaman he forced to sell we got it for pennies on the dollar b noir detour\n",
      "Sample 765 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  <user> <user> many british on the continent think they â€™ re the jesus because they â€™ re not immigrants they â€™ re expats ðŸ¤£ ðŸ¤£ ðŸ¤£\n",
      "Sample 766 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  fuck off we have more than enough muzzies to deal with\n",
      "Sample 767 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  soon men and women wont be touching each other they will be segregated like in muslim countries\n",
      "Sample 768 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  if you still support the small handed nazi nut bag you â€™ re one sick ignorant racist mother fucker fucktrumpsupporters\n",
      "Sample 769 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  <user> â€ rc maxwell hi everyone i am a gay nigger who is above the degeneracy of the strawman of cantwell i have prepared for you now lets talk about ok cupid posts because as a nigger muh dick iq only can go so far in an intelligent discussion\n",
      "Sample 770 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  <user> good they don â€™ t deserve to get paid the <user> don â€™ t do anything but help illegal aliens\n",
      "Sample 771 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  arm yourself against soros funded altifa tyranny and muslime ohell sedition there is no place in america for millions of ohell muslime refugee barbarians and their cult sharia law the dems love women are not slaves in america they are or will be armed if desired for their protection\n",
      "Sample 772 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> looks more like white trailer trash\n",
      "Sample 773 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  the reproductive skew â€“ the extent to which a single male versus many males sires offspring â€“ is much higher among bonobos than it is in male dominated and more aggressive chimpanzees manly chimp gangs ration pussy bonobo wimps let it all go to the pop star cult leader ghetto drug dealer\n",
      "Sample 774 / 1008 : Prediction = 0  Saved:  0 Correct label:  2\n",
      "Text:  ok these are not remaining funny alas nonbinary culture is reading a queer sf f novel and getting hopeful when a character is referred to as they only to realize they will be gendered later ðŸ™„ ðŸ¤¦ â€ â™‚ï¸\n",
      "Sample 775 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  whoeva told ya tha shit was easy they was lyin to ya ðŸš«\n",
      "Sample 776 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  i went to the post office today and asked the <number> lb sheboon behind the counter how much faster a letter to amarillo would get there if i used express mail her exact reply mayne you really expeck me ta know diss\n",
      "Sample 777 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> <user> the mistake was that the dinosaurs did not kill all humans\n",
      "Sample 778 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  not to mention eating beans and a nigger work song\n",
      "Sample 779 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> did not understand it tho you going hoe\n",
      "Sample 780 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> <user> <user> an amazing fierce woman because she stayed in a fake marriage with a man who raped sexually assaulted and cheated on her\n",
      "Sample 781 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  so the un got trump to be their jewdog puppet spend millions of to bomb a christian leader and christian ppl to satisfy the jews and mussies we the ppl will never win\n",
      "Sample 782 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  me you know what they say about people with big hands and big feet wife they â€™ re retarded me okay\n",
      "Sample 783 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> i rly enjoying this gay moment of urs\n",
      "Sample 784 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  shaslum and ghetto to you muh meh <number> zero my real name is andy cemhight but do not touch that dial until your last twitch free speech is not just for losers\n",
      "Sample 785 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  <user> okay he black also it okay to be white and what wrong with loving your country you are a bigot alec seriously you fit the definition rational people walkaway from leftist hatred and bigotry\n",
      "Sample 786 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  <user> <user> if they are so there are aprox <number> billion muslim on planet earth books me hi nazar aate phr\n",
      "Sample 787 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  starting to lose more and more faith in black men each day ðŸ˜ ðŸ¥´\n",
      "Sample 788 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  hey liberals i am an immigrant and i hate niggers triggered yet snowflakes ðŸ˜‚ ðŸ˜‚ ðŸ˜‚ ðŸ˜‚\n",
      "Sample 789 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  barn full of white bitches\n",
      "Sample 790 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  <user> this illegal alien just raped a child luciano trejo dominguez <number>\n",
      "Sample 791 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  <user> i do not know that it means anything more than an observation but he she it lea is the most feminine butch dyke i have ever seen\n",
      "Sample 792 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  <user> <user> yeah but niggas only hate queer trans folk because white folk conditioned them to do so it not us it still them\n",
      "Sample 793 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  wth i got kicked off twitter all i did was say ghetto hood rat on snop doggs photo of a trump photo\n",
      "Sample 794 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  tsekk faggot kike puppet\n",
      "Sample 795 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  um but you do realize that jesus was a kike and that christianity was originally another like cult right\n",
      "Sample 796 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> where in new york was this taken white supremist nazi radical evangelical bigoted pos road rage waiting to happen\n",
      "Sample 797 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  can anyone be any more ignorant than muslim shit skin pedophile beating up on crippled boy if you see this happen in your community feel free to slit that muslims throat society will thank you in that country the crippled boy will be charged with inciting violence against islam\n",
      "Sample 798 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> although i do not condone the use of that word we were sand n word so relatively arabs can say it i just do not see the necessity\n",
      "Sample 799 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  lol i live in a white nigger ghetto i claim no white niggerhood as a former english teacher i slum when i feel choose unlike my fellow city rats for whom its their only mode of comm\n",
      "Sample 800 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  mlane <user> and we worry about immigrant terrorists ha putin is right he said that he did not have to ruin america because we would ruin ourselves and he gloated when he said it\n",
      "Sample 801 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  <user> do i look like a faggot basher to you you stupid fucking human boy you have got a mouth\n",
      "Sample 802 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  <user> <user> <user> you can gather a list of female poc queer brewery representatives you feel they should call on there are many fellow brewers and industry folk out there who advocate for equality in craft brewing let us make our voices louder together <number> <number>\n",
      "Sample 803 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  but imma have to get ghetto and start picking from the medsci building\n",
      "Sample 804 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  that unfortunate the dancing jiggaboo with the tambourine was pretty entertaining\n",
      "Sample 805 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  these filthy yellow color jews jelly of our ivory color skin\n",
      "Sample 806 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  i am <percent> irish origin both parents irish no dirty jew here the kike never infected ireland\n",
      "Sample 807 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  white pill of the day\n",
      "Sample 808 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  <user> <user> i was just thinking this must be the case you can probably make bank selling fake empowerment to women through self defence classes\n",
      "Sample 809 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  what was that english lol that was one too many negatives in a sentence no i did not say you specifically lard ass i said women in general learn to read cleaely i can and you can not\n",
      "Sample 810 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  gay moslem support group\n",
      "Sample 811 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  when a hoe wants to talk about morals ðŸ˜‚\n",
      "Sample 812 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> <user> there pink i am getting in on this faggots\n",
      "Sample 813 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  whatever happened to allegations fox was involved with beaner drug cartels\n",
      "Sample 814 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  so heartless bitch i hate you i can not believe you did me\n",
      "Sample 815 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  ye olde niggra tax makes us pay more for home car insurance police ambulance medical schools school resource officers school po po <happy> security entertainment we have to commute farther to work the niggra tax is endless in a perfect world muslims would blow up blacks <happy>\n",
      "Sample 816 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  this retarded nazi think that i said hitler banned guns is their any hope for these liberal socialists i think not\n",
      "Sample 817 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  trying to convince carter he should go as slutty bob ross for halloween ðŸ¤ž\n",
      "Sample 818 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> would be nice if he recognised the plight of white farmers in south africa\n",
      "Sample 819 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  khan can suck the shit off the syphilitic dicks of his moslem pedo brothers uk cops can lick up the mess never rotherham rochdale rape jihad sharia creep islamo facism white genocide christiangenocide never islam 14 words\n",
      "Sample 820 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> <user> how many illegal aliens are gonna benefit we have 9 0 0 k in the state mr governor\n",
      "Sample 821 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  president trump has the patience of a saint if it were me in his place i would have declared martial law rounded up every member of the retarded liberal media and shipped them all to a gulag in antarctica\n",
      "Sample 822 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  bitches act like a nigga do not got feelings\n",
      "Sample 823 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <number> to <number> seems about right as a general rule about left vs right violence as well\n",
      "Sample 824 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  lol the bbc crying over their favourite anti white nigger comrade bob mugabe being overthrown in zimbabwe\n",
      "Sample 825 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  <user> send me fat girls and i will become even gayer vro\n",
      "Sample 826 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  myanmar kicked rohinhya muslims out it is the only answer possible to these raping violent incestious pedophile sadistic retarded terrorists\n",
      "Sample 827 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  moslem women cannot celebrate international womens day\n",
      "Sample 828 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  so me being african doesnt give me the pass to understand more ca do researches and know whats appropriate and whats not ðŸ¤¡ some white people are so funny\n",
      "Sample 829 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  macro the left gets bullied by blacks muslimes and victim groups the right does not get bullied the left as a reaction <number> themselves being bullied pretend they r freedom fighters side with those bullying them and attack conservatives who defend themselves while accusing them of being bullies\n",
      "Sample 830 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  that funny hoodbilly i have always referred to myself as ghetto hick because halfway through my childhood my parents moved me from the city to the country i am a white girl who can rap and change brakes on a muddin truck hehe ðŸ˜ ðŸ˜ ðŸ‘Š ðŸ‘Š\n",
      "Sample 831 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  confess it was the naked negress tits when you were young\n",
      "Sample 832 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  thots am retarded\n",
      "Sample 833 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  do not be a retarded tool and do your research before you start defaming people who are just trying to tell you the truth\n",
      "Sample 834 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  me and <user> were talking about it cosplayers and she was like if this richie cosplayer took off their glasses they would look like mike but theyre white stranger things\n",
      "Sample 835 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> zayn is a fucking god\n",
      "Sample 836 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> <user> they sound like they are islamic\n",
      "Sample 837 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  no really shut that brainless retarded oaf head\n",
      "Sample 838 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> hm so which do we think is worse sharialaw you know what the do to women hrc we know what she does to anyone yourpizzascooked or all the radical islamic terrorists love ya huma\n",
      "Sample 839 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  you see one of the great things about finally just admitting the problem with jews is when you see anything they try to spout off you can automatically file it under deceptive kike trying to tear down society without even having to bother reading it\n",
      "Sample 840 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  oh good just what my state needs more memphricans abortion is a moral abomination when humans do it but niggers are not humans planned parenthood kills nigger babies\n",
      "Sample 841 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  tariq being a bigger nigger than the rest should this nation come unglued when it comes down to nuggets and spikes it will be a hoot\n",
      "Sample 842 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  this nigga thanos done killed aquaman\n",
      "Sample 843 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  would you please post something on a public forum explicitly advocating for violence pretty please thx\n",
      "Sample 844 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  the barbecue sauce comment really affected my psyche but you do not want to fight a gay cannibal\n",
      "Sample 845 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  <user> wave migration is being cracked down on i doubt it â€™ going to be too much diverse in the future only vetted immigrants\n",
      "Sample 846 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  thank ya baby gays âœŒ ï¸ ðŸ˜‰\n",
      "Sample 847 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  the singularity already happened retard where do you think you even came from\n",
      "Sample 848 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  if you can not handle a little swastika flag being waved at your rally you are not going to be able to tolerate a man shouting for the death of your enemies meanwhile punch a nazi kill all white people kill the boer\n",
      "Sample 849 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  <user> so you do not agree that a brown muslim who says that they hate white people makes things worse\n",
      "Sample 850 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> <user> <user> so me\n",
      "Sample 851 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> eye hate you\n",
      "Sample 852 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  i watched his video seemed to be predicated on north western europeans as normatively white but in my view white refers to all those caucasians who interacted within the western civilizational system thus greek are white despite having dna closer to levantine semites than germans or slavs\n",
      "Sample 853 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  set my lil brother bail at half a mill rat ass niggas\n",
      "Sample 854 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  i really do not get white australians hatred of immigrants you are all literally immigrants wtf is wrong with you all i mean i get you hate poc but come on\n",
      "Sample 855 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  yeah and nobody wants to see nigger tits either\n",
      "Sample 856 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  how many people would defend the jews if everyone knew there is a plan to bring chinese troops to bomb the usa\n",
      "Sample 857 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  you are no lady and you are a nigger living in england nothing english about you\n",
      "Sample 858 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> naseeruddinshah is right and should preach this to rohingya muslims who desperately seeking shelter in intolerant india\n",
      "Sample 859 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  i have absolutely nothing against patrick little but his personal opinion on mudslimes matters not in the least to me\n",
      "Sample 860 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  he threw bacon at a mosque or something went to prison for it and died the implication is that if you make fun of islam or muslims it pretty much a death sentence in europe which puts it on par with other muslim countries in the third world\n",
      "Sample 861 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> <user> the police union and this rag head woman has the nerve to get angry with him for calling out that racist cop\n",
      "Sample 862 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  the last true bastion of bipartisanship is criticizing the black muslim refugee congresswoman\n",
      "Sample 863 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  <user> and everything everything book movie i â€™ ve watched crazy rich asians yesterday amp i loved it\n",
      "Sample 864 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  no because the nigger word should only be used by blax when whites use it they should be killed\n",
      "Sample 865 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> some apologies are genuine and from the heart this is lame merely damage control but you can not control the damage of what amounts to holocaust denial with what appears to be an inter office style memo it inadequate you have deeply offended jews all over the world\n",
      "Sample 866 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  we do not want legal immigrants unless they are white europeans\n",
      "Sample 867 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  the press is derelict in its duty to educate the public â€¦ not indoctrinate the public about islam and the danger in surrendering to it\n",
      "Sample 868 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  that <number> bouncer and the boys you jumped up little nazi fag you wont see him again case closed\n",
      "Sample 869 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  give a white man a hammer and he will build a glorious cathedral give an asian man a hammer and he will make more hammers give a nigger a hammer and he will bash another nigger skull in\n",
      "Sample 870 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> <user> <user> his words were it like a holocaust out there holocaust destruction or slaughter on a mass scale especially caused by fire or nuclear war a holocaust not the holocaust no matter what you all say that was his intention you all can misconstrue his words all you want\n",
      "Sample 871 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  enjoy your kike faith\n",
      "Sample 872 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  leonardo divinci was a nigger i did not know that the cell phone they claim was not even the first cell phone to call between different railroad cars hooked up to each other\n",
      "Sample 873 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  look a stupid nigger posting directly to twitter gabfam even knows that a fucking mark of the retard\n",
      "Sample 874 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  attention white south africans do not become part of the worlds hidden history of white extermination as the whites of angola rhodesia algeria mozambique did current western governments hate whites they engage in whiteminoritization anti white propaganda on a daily basis stay strong\n",
      "Sample 875 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  â›” ï¸ game of thrones spoilers â›” ï¸ look away now aliens come down and kill all the white walkers then high five jon snow ðŸ›¸ game of thrones\n",
      "Sample 876 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  fuck the <number> immigrants the government lost i only care about <number> immigrant the government lost where is she\n",
      "Sample 877 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  starting to feel like trump could give a shit about his own base being silenced and censored kanye is bringing in new voters who will not bitch about his dem daughter so what do we matter now eh ðŸ˜‘ ðŸ†˜\n",
      "Sample 878 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  unitetheright jews call white supremacist any taxpayer that wants to create good social programs with all the money that jews steal from us\n",
      "Sample 879 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  i really cant believe this story if i was armed out hunting still nearly got raped by well anything i would not tell one single soul\n",
      "Sample 880 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  jews are born trouble makers\n",
      "Sample 881 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  dublin will mirror londonistan moslem rape gangs drug trafficking acid attacks black criminals gangs with horrendous gun exchanges 3 rd worlders sucking social housing welfare dry not working future under this immigrant ireland 2040 plan the death of ireland our shared celtic heritage my ancestors ni ireland <number> death of the irish\n",
      "Sample 882 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  lmfao are you actually this goofy i get the feeling you are either a nigger or a female i am going to have to throw in a noogie\n",
      "Sample 883 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  <user> and you are proving your ignorance more and more like i said i am done arguing with a ass scratching finger sniffing redneck do a little research and then we will talk\n",
      "Sample 884 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> <user> kindly check them ðŸ˜‚ they are pakistani cannot export anything better than jihadi terrorists ðŸ˜„ beggars\n",
      "Sample 885 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  to do that you gota get rid of the niggers and jews spics arabs etc etc so hurry up\n",
      "Sample 886 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  whoever rtd that yuta opening a dyke salon tweet onto my timeline just know op is actually lesbophobic lol\n",
      "Sample 887 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  mohammad bin salman al saud ordered the bone sawing of an american journalist i said only thing i wanna see or hear from that camel jockey prince is screams bone sawing him up live on t.v. and twitter gives me <number> hrs in das hole damn snowflakes\n",
      "Sample 888 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  what about the black violence and you said that he chased them and that was bad you had no idea that the gun was illegal <number> niggers destroyed his store there should be no gun registration\n",
      "Sample 889 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  there no way this actually happened if he did get raped it was probably by some african or arab for sexual emergency reasons and then he made up the story of a badgoy nazi doing it\n",
      "Sample 890 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  <user> <user> are not criminals the â€œ sworn enemy of the police â€ if we are robbed raped attacked we call the police\n",
      "Sample 891 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> slack jawed knuckle dragging mouth breathing toothless inbred redneck backwoods uneducated hillbilly hicks that the republican party\n",
      "Sample 892 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  oh that lady yeah she a hate filled racist bitch go nuts\n",
      "Sample 893 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  new general named in border wars today his reputation is extreem vetting he promises no immigrant let in until one if my elite men have smelled their ass\n",
      "Sample 894 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  everyday the same thing i have contracts on my life im going to get killed im dead its my fault im an nut a faggot everyone hates me the country wants me dead organize crime the police who does not want to see my die\n",
      "Sample 895 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  <user> absolutely not i would never cast aspersions on their sick twisted perverted evil religion just call them wat they are raghead colostomy bags\n",
      "Sample 896 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> <user> keep running to russia you nazi sympathizer\n",
      "Sample 897 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  planned parenthood does not help women who wish to keep their baby women who kill babies get depressed take psyche drugs big pharma wins see the truth and share the truth gabfam marchforlife maga\n",
      "Sample 898 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  the politic boys keep chimin in on my culture war it would be nice if they kindly fucked off and stop counter signaling my kike gassing\n",
      "Sample 899 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  i did not expect something kike that holy shit i t looks so good\n",
      "Sample 900 / 1008 : Prediction = 0  Saved:  0 Correct label:  2\n",
      "Text:  <number> amsyar â€¢ he used to look more chinese during form one â€¢ a bitch â€¢ uri dumbass â€¢ good advices â€¢ he always there if u need him â€¢ nice haircut â€¢ no emotions most of the time â€¢ lowkey hates everyone\n",
      "Sample 901 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  a gay man walks into a library and asks for a book on hiv the librarian replies fuck off you will give it to someone else\n",
      "Sample 902 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  <user> side note how tf i spell from as grime i swear i â€™ m retarded\n",
      "Sample 903 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  the lord is a man of war the lord is his name if you know jesus then you know the father christianity is not some bitch made religion frankly heretics like you deserve condemnation too\n",
      "Sample 904 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  two gay guys living together and pooling their resources you know have more resources also before everygaycouple started adopting non verbal special needs niglet boys none cared about the quality of schools the only gays i know that adopted a girl other than on modern family adopted a niece\n",
      "Sample 905 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  my family so fucking ghetto n slow i gotta dumb down what i be trying to say so they can understand ðŸ˜‚ ðŸ˜‚ ðŸ˜‚ i love them\n",
      "Sample 906 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  niggas really let idubbz say nigger faggot and ain t even care\n",
      "Sample 907 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  anytime bro rekt the kike christ cuck fuckers shits about to get real\n",
      "Sample 908 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  dropping bombs on dune coons while you have total air superority is not combat it target practice now doing it while there are sams and manpads sending guided missiles up one exhaust would be she did the former\n",
      "Sample 909 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  lay down that pressure on the iffy niggas that will not leap\n",
      "Sample 910 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  if you think destroying iran will weaken islam you are a verifiable dumbass all it will do is push more refugees to europe and create more hatred and more bloodshed none of which will be to the benefit of white europeans\n",
      "Sample 911 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  moslem ghettos breeding more terrorists pedo rapists whilst poncing off the brit taxpayer <number> moslem breeding will eventually bankrupt uk <number> moslem breeding will lead to civil war <number> civil war will mean moohamad will become most common name of dead people\n",
      "Sample 912 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  you forgot faggots like azzmador and greg johnson\n",
      "Sample 913 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  <number> good reason every american needs assault rifle and lots of ammo they rile them up and then the refugees rush to other countries to blow off their steam by bombing raping killing thieving be prepared never give an inch\n",
      "Sample 914 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  this white ass la does not sell colada the smoothie lady did not even know wtf i was talking about ðŸ¤¦ ðŸ» â€ â™€ï¸\n",
      "Sample 915 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  the muzrat euro marathon\n",
      "Sample 916 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  gatewaypundit is pure fake news it just clickbait for retarded people trump did not cancel the diversity lottery he can not do that even if he wanted to do it\n",
      "Sample 917 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> <user> <user> all those illegal aliens ðŸ¤¦ ðŸ» â€ â™‚ï¸\n",
      "Sample 918 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> <user> it not homogeneous it just that asian immigrants are not as vocal visible\n",
      "Sample 919 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  fb so ghetto ðŸ˜­ ðŸ˜­ whew\n",
      "Sample 920 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  head cannon sougou is an incel and oma zi o is the result of being told by one to many women that he can not smell they are feet\n",
      "Sample 921 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  exactly what i have been saying let them live with pelosi what her name shut and that dumass jigaboo from fla and csli\n",
      "Sample 922 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  went varmint hunting earlier i shot six squirrels and a jackrabbit no kike rats though <sad>\n",
      "Sample 923 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  the elders of monroe are swarming the streets downtown at an outdoor concert lots of motown lots of orthopedic shoes\n",
      "Sample 924 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> its totly gcc countries muslim leaders fault beacuse of them these mother fukers can do anything with muslims of end ia\n",
      "Sample 925 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  and i told you at the time as now that your list is info everyone already knows what you are afraid to tackle is the reason behind raghead terrorism as it places all the blame on your precious kikes i say let them both kill each other good riddance\n",
      "Sample 926 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  dm are officially open to muslim men with curly hair and glasses and zero commitment issues pls do marriage on me im bored\n",
      "Sample 927 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  i do not understand why people argue here you know the enemy you do not need to explain it you do not have to debate them the enemy are kikes niggers and muzzos deal with these shit stains first then deal with the race traitors\n",
      "Sample 928 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  lots and lots of butthurt nigger minecraft fans over that i had no idea how much that dude is worth i hope anglin dunned him for bitcoin\n",
      "Sample 929 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  they turned cancun â€™ into the ghetto\n",
      "Sample 930 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  idk we need our own internet and need to trash this whole system if gab is the zenith then the whole thing is still kike bullshit <user> â€\n",
      "Sample 931 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> they robbed them while serving looks too and they robbed the brooklyn museum tbh more shows should be about queer people stealing from white cishet institutions\n",
      "Sample 932 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  i really fucking hate valve\n",
      "Sample 933 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  the problem is these church cucks are the ones bringing these so called refugees in where they are a danger to us all just like the stupid women of europe who welcome refugees and then get raped and murdered guarantee this woman would call anyone against refugee resettlement a racist\n",
      "Sample 934 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  say what you will about nazi germany but it was definitely the most lgbt inclusive place in the middle east\n",
      "Sample 935 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  <user> here is what must be done the media says look at the majority of trump voters they are white whites are a majority of the republican party jews are <number> of population yet look at fed scotus and media that is our best argument\n",
      "Sample 936 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  <user> what the hell they are literally a fucking hate group they would not allow the kk or some other group to just show up why is this any fucking different ugh thanks for letting me know\n",
      "Sample 937 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  given that they backstab each other like skaven but do not have the numbers to repopulate from screwing each other i say the muzzies because they breed like the skaven\n",
      "Sample 938 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  bad bitch she conceited\n",
      "Sample 939 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  facebook suspended me for doing almost the same thing i took a tiny almost random splice from the koran and put muslim where it said unbeliever obviously that was incitement to violence for the muslims but i was not inciting anyone i was just illustrating that it is just that\n",
      "Sample 940 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  officially starting my slut phase\n",
      "Sample 941 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  given the makeup of today crew i have advised the new guy i am promoting him to deputy wing commander to help me keep the faggots in line so mote it be\n",
      "Sample 942 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  <user> hugo lloris could not catch corona if a chinaman sneezed in his gob\n",
      "Sample 943 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  rt realdonaldtrump our fallen heroes have not only written our history they have shaped our destiny they saved the lives of the men and women with whom they served they cared for their families more than anything in the world they loved their families they inspired their communities https\n",
      "Sample 944 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  men are mad at gold diggers bc they know women are to smart to let men use them for money\n",
      "Sample 945 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  i was stuck between i need to save money and you only live once then i went to i am stuck between i lived once and where that saved money you fool i stay away from women these days so there goes that excuse lol\n",
      "Sample 946 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  islam makes everything clearer there is no ambiguity in the teaching of islam\n",
      "Sample 947 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  why niggas worry bout me when i do not even checc on them faggots\n",
      "Sample 948 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  you wanna defend this hasbara kike thot too\n",
      "Sample 949 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  lol yeah i think i remember you posting your pic <number> time odins douche tries to dish it out but can not take it he blocked me after i said he was a kike and his gf was a hooker he got triggered af\n",
      "Sample 950 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  dear black niggers fuck your poverty fuck your high crime neighborhoods fuck your niglets without fathers fuck your niggers killed by cops fuck your incarceration rate fuck your lives they do not matter to us fuck you we do not want you or need you all smart white people\n",
      "Sample 951 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> the problem is naughty dog shoving homosexuality down our throats they are doing this on purpose i do not wanna know who ellie fucks plus i do not care who she fucks i do not need to know that\n",
      "Sample 952 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  when i drink big red i feel really ghetto\n",
      "Sample 953 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  you white republican atheists who stayed home will pay the price you can forget your tax break now\n",
      "Sample 954 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> <user> is it the one i was coming on here to dog him about where he justified <number> year olds being raped by epstein\n",
      "Sample 955 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  bill clinton is an evil creature um maybe slick is a mussie rapist all this time\n",
      "Sample 956 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  moslem ban and libtard ban but not gun ban\n",
      "Sample 957 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  i tole sum brillohaided nigger bich off last nite cuz it try to get uppity wit me\n",
      "Sample 958 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  i bet kike molars cracked when they heard all the in jesus name we pray\n",
      "Sample 959 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  <user> ah can honestly say ave never had a deep fried mars bar they do not do them here prefer a nice deep fried faggot and chippies ðŸ¤ª ðŸ¤ª\n",
      "Sample 960 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  a failed government which puts immigrants 1 st and it own tax payers last welcome to australia in <number> ausfam auspol ausfam auspol ausfam auspol australia\n",
      "Sample 961 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  people calling undocumented immigrants labor unskilled are dumb af ya ever built a house shit ain â€™ t easy\n",
      "Sample 962 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  stop blaming niggers and women for what is obviously being caused by russian hackers\n",
      "Sample 963 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  i needed you and you were not there that made me hate you\n",
      "Sample 964 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  snickers have come out with a white chocolate bar ice cream bar i can not stand snickers because i like my candy like i like my women no nuts\n",
      "Sample 965 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  mfw i m trying to write an important term paper and some affirmative action ass hole starts blasting nigger music outside the window\n",
      "Sample 966 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  isis isil is boko harem hamas plo pla plj al qaeda taliban hezbollah harakat ul mujahidin ansar al sharia cair muslim brotherhood american muslims for palestine et al all are exactly the same muzzie terrorists\n",
      "Sample 967 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  thank a white man you live in his world and why do you islanders say you are canadian so rude really if i lived in a brown country even with citizenship i would never call myself ethiopian chinese indian you are a caribbean living in canada\n",
      "Sample 968 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  i love how feminists only like women who break the glass ceiling when they agree with them kellyanneconway\n",
      "Sample 969 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> courtois is a fucking mess\n",
      "Sample 970 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  ya but at least it given rise to alotta order and infrastructure educations at the brigham young schools etc but ya i hear what you are saying though cuz any aristocracy oligarchy of organized men can and eventually will give rise to corruption better than a ghetto though\n",
      "Sample 971 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  it keeps normies distracted by a media propaganda wall of a far right and neo nazi threat the does not exist and cloaks the rabid islamic and corporate fascism being installed\n",
      "Sample 972 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  sad songs are cool but have you ever tried crying because you got wheat bread instead of white ðŸ˜Ž\n",
      "Sample 973 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  i just found out my term is called queer curious so basically no one likes my type but the girls low key live âœ¨\n",
      "Sample 974 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  obama allowed the cia a free hand in syria resulting in the absolute jihadi chaos which benefited the worthless kikes this is how we ended up backing moderate kebab that behead <number> year old christian kids trump ended this and allowed russia to massacre the sandniggers you are fucking retarded\n",
      "Sample 975 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  we should kill a white person every day until the grenfell residents are housed in mansions huffington post blogs\n",
      "Sample 976 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> saying anything shaming is the province of women and male feminists\n",
      "Sample 977 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  did you know the only time moslem women can walk before men\n",
      "Sample 978 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  honestly i will go along with muslims remaining in usa long enough to kill off a whole slew of faggots then maybe just maybe the queers will stop fighting for islam and join the patriots in expelling the whole godless filthy bunch that godless part directed at muslims not the godless queers\n",
      "Sample 979 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  fuck her she nothing but a kike that will play which ever side that will get her paid\n",
      "Sample 980 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  my wife and i agree <percent> let mother nature cull the nigger herd\n",
      "Sample 981 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  we got a picture of an angel holding a photo inside a shoebox it was made of smoke it smiled\n",
      "Sample 982 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> true religion is islam your excellency and i am proud be a muslim why because i respect other religions\n",
      "Sample 983 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  <user> ðŸ˜‚ ðŸ˜‚ if he was on twitter i would have him i think i will do a thread on what he experienced especially the aftermath of threatening to rape syntche\n",
      "Sample 984 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  will all of the white people who want to move to a ghetto or third world country please raise your hand\n",
      "Sample 985 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  fellas would you fuck a bitch with no arms\n",
      "Sample 986 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> good na anyways population explosion kar rakha hai <number> dus dus bachhe hai and refugee bhi u want great and then u will cry ðŸ˜¢ job creation and economy\n",
      "Sample 987 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  welp gave the negro too much credit because he currently ruining my bath by coming in here taking a shit\n",
      "Sample 988 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  <user> agusta main or texes which state you live in tossa people want to catch up with you are you scared little nigger or what\n",
      "Sample 989 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  <user> communal attack by their own didi agreed didi need to be thrown behind bar islamic jihadi\n",
      "Sample 990 / 1008 : Prediction = 2  Saved:  2 Correct label:  0\n",
      "Text:  i have offered quite a few constructive and gentle criticisms of her kike face and it modern art paint shellacking ðŸ˜¬ buffalo bill was not very appreciative\n",
      "Sample 991 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  <user> hate you too ðŸ˜˜\n",
      "Sample 992 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  me i have so many great friends and they fulfill me <percent> and i do not have time to make more friends anyways also me sees a cool cute queer omg pls be friends with me ðŸ¥º\n",
      "Sample 993 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  the only people that hang outside of rofo are ghetto people and old men with there yee yee trucks\n",
      "Sample 994 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  nope ðŸ˜Ž i will never ever shut up i am here for good and will continue exposing your cyberstalking and harassment of military families better get used to it ðŸ˜ƒ\n",
      "Sample 995 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  no sharia no cair no common core no muslin brotherhood no sanctuary cities or states our country our customs our way do not like it leave sharia law will never be accepted in america fran cifelli\n",
      "Sample 996 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  you know how retarded it is to get a â€œ i â€™ m coming to you as a woman â€ dm at the age of <number> ðŸ˜­ ðŸ˜­ ðŸ˜­\n",
      "Sample 997 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  new rule in all competitive shows baking dancing or other let paki or nigger token win in order to win public support and hide our true racist feeling for coloureds british broadcasting rules and regulations <number>\n",
      "Sample 998 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  asians do not have higher iq or intelligence in general than whites that is a huge grotesque joke probably most of the stats come from lying commie chinks so strange that when it comes to stats even based nazi pooplords believe pinkos\n",
      "Sample 999 / 1008 : Prediction = 2  Saved:  2 Correct label:  1\n",
      "Text:  our moslem friends also ask the same question why dont we just drop our drawers why dont we just dissolve the republic just blow our brains out do our enemies a favor\n",
      "Sample 1000 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  hoe you can not touch this\n",
      "Sample 1001 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  despite the media blackout of all the muzzie rapes in sweden the word is out sweden and their gorgeous women are under unfettered assault by savage 3 rd world cretins there will be a point when islam can no longer hide it evil vile savage and despicable soulless character\n",
      "Sample 1002 / 1008 : Prediction = 2  Saved:  2 Correct label:  2\n",
      "Text:  imagine thinking that fat dyke in dallas a better rb than kamara lmfao\n",
      "Sample 1003 / 1008 : Prediction = 1  Saved:  1 Correct label:  1\n",
      "Text:  <user> nice ching chong hat\n",
      "Sample 1004 / 1008 : Prediction = 1  Saved:  1 Correct label:  2\n",
      "Text:  justin trudeau not being able to differentiate between isis fighters and regular refugees is stunning he is blatantly trying to confuse and manipulate the two he is now the most irresponsible and undeserving leader we have ever seen\n",
      "Sample 1005 / 1008 : Prediction = 0  Saved:  0 Correct label:  1\n",
      "Text:  <user> there is need for awsreness campaign to educate our communities to avoid calling refugees the internally displaced persons i really feel pity when i visit idp camp and colleagues caÄºing the idps a refugee a name i was once forced by circumstance and no one choices to berefugee\n",
      "Sample 1006 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n",
      "Text:  oh i got these vegas dykes mad today\n",
      "Sample 1007 / 1008 : Prediction = 1  Saved:  1 Correct label:  0\n",
      "Text:  <user> this is a fucking attack\n",
      "Sample 1008 / 1008 : Prediction = 0  Saved:  0 Correct label:  0\n"
     ]
    }
   ],
   "source": [
    "#These next couple cells are for prompt-tuning with few shot and chain of thought. Just using a seperate part so i can see results and compare with the previous.\n",
    "\n",
    "#Cell 2# Few-shot \n",
    "import re\n",
    "\n",
    "#Empty array for LLM predictions. This is reran again.\n",
    "y_pred_after_fewshot_eng = []\n",
    "\n",
    "reasoning_after_fewshot_eng = []\n",
    "#For loop for running the prompt through HateXplain\n",
    "for i in range(len(data_texts)):\n",
    "    \n",
    "    #The prompt variable. which i send data_text to be ran through.\n",
    "    prompt = f\"\"\" Review the provided statement and classify it as 'Hatespeech' or 'Offensive' or 'Normal' by reasoning step-by-step.\n",
    "\n",
    "    2 = Hatespeech (Text that not only mention but also involves devaluation of protected groups linking to gender, race, sexuality, religion and disability)\n",
    "    1 = Offensive (Can be interpreted as hatespeech but it's main intent doesn't not involve devaluing or directing an attack on protected groups)\n",
    "    0 = Normal (Text that can't be interpreted as hatespeech)\n",
    "\n",
    "    Here some example:\n",
    "\n",
    "    Text: \"Police should arrest this autisitc white hoe\"\n",
    "    Reasoning: While \"autistic white hoe\" can related to devaluing white women or the disabled, it does not specifically target white women or disabled but it is used as an insult against an individual.\n",
    "    Output: 1\n",
    "\n",
    "    Text: \"This dumb nigga wanna to scam me\"\n",
    "    Reasoning: While the term \"nigga\" can be very offensive towards black people. In this context it is not used as hatespeech to black people. However this text is toxic due \"dumb\" being used as an insult.\n",
    "    Output: 1\n",
    "\n",
    "    \n",
    "    Text: {data_texts[i]}\n",
    "    Reasoning:\n",
    "    Output (number only):\n",
    "    \"\"\"\n",
    "\n",
    "    #Running the respornse\n",
    "    response = ollama.chat(\n",
    "        model=\"mistral\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",  \n",
    "                \"content\": prompt\n",
    "            },\n",
    "        ],\n",
    "\n",
    "        #Setting the options to be similar to the ones seen on paper. The only difference is setting the seed so it can be later reproduced\n",
    "        options = {\n",
    "            \"temperature\": 0.1,\n",
    "            \"top_p\": 0.95,\n",
    "            \"num_ctx\": 1024,      \n",
    "            \"num_predict\": 256,        \n",
    "            \"repeat_penalty\": 1.1,    \n",
    "            \"seed\": 42,                \n",
    "        }\n",
    "    )\n",
    "    \n",
    "    #Getting the response from the model\n",
    "    prediction = response.message.content\n",
    "\n",
    "    reasoning_after_fewshot_eng.append(prediction)\n",
    "    #Since models outputs vary. By using re.search i can search for the number to gain the prediction within the output.\n",
    "    match = re.search(r'[012]', prediction)\n",
    "    if match:\n",
    "        pred_num = int(match.group())\n",
    "    else:\n",
    "        pred_num = -1 \n",
    "    y_pred_after_fewshot_eng .append(pred_num)\n",
    "\n",
    "    #There was a logic error that caused y_pred to be saved differently. This is to see whether thing are saved correctly\n",
    "    #print(\"Response: \", prediction)\n",
    "    print(\"Text: \", data_texts[i])\n",
    "    print(\"Sample\", i+1, \"/\",  len(data_texts), \": Prediction =\", pred_num, \" Saved: \", y_pred_after_fewshot_eng [i], \"Correct label: \", data_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5818ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0 Results:  0 (Normal)\n",
      "Reasoning: The statement does not involve devaluation of any protected group, it is simply expressing dislike towards a specific personal trait (sexual orientation in this case). However, it's important to note that while this statement might be considered normal in some contexts, it should always be approached with respect and sensitivity.\n",
      "Sample 1 Results:  This text appears to be a username or handle from a social media platform, possibly related to a restaurant named \"Spoons.\" The terms \"slave,\" \"findom\" (short for financial domination), and \"bitch\" are often associated with adult content or fetish communities. However, without additional context, it's difficult to definitively classify this text as 'Hatespeech' or 'Offensive.'\n",
      "\n",
      "In this case, the terms used might be considered offensive due to their sexual nature, but they do not specifically target any protected groups based on gender, race, sexuality, religion, or disability. Therefore, according to the provided classification system, the output would be:\n",
      "\n",
      "Output (number only): 0 = Normal (Text that can't be interpreted as hatespeech)\n",
      "Sample 2 Results:  Based on the provided context, the term \"spic\" is derogatory and offensive towards Hispanic or Latino people. However, in this specific text, it seems to be used as a part of a story about an individual's grandmother, rather than a general attack on the Hispanic community. Therefore, the intent does not appear to be hatespeech.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 3 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The text does not mention or devalue any protected groups, nor does it involve an attack on them. It seems to be a statement about a situation involving potential violence, without any derogatory or offensive language towards specific groups.\n",
      "Sample 4 Results:  The provided text is: \"if the authorities say it was a woman shooter we know for certain that it was black moslem male\"\n",
      "\n",
      "Reasoning: This statement suggests a generalization and stereotyping of women, blacks, and Muslims. It implies that all women who are shooters must be black Muslims, which is a form of devaluation and direct attack on protected groups based on gender, race, and religion.\n",
      "\n",
      "Output: 2 (Hatespeech)\n",
      "Sample 5 Results:  Output: 1\n",
      "\n",
      "Reasoning: The text does not mention or devalue any protected groups based on gender, race, sexuality, religion, or disability. It is expressing a personal feeling of insecurity about one's appearance, which while it may be offensive to some, it doesn't qualify as hatespeech.\n",
      "Sample 6 Results:  In this case, the provided text does not mention or involve devaluation of any protected groups such as gender, race, sexuality, religion, or disability. The term \"redneck\" is often used to stereotype rural white people, but it's not necessarily a derogatory term in all contexts. However, if the context suggests that it's being used in a negative or discriminatory way, it could be considered offensive. But without additional information about the context, it's hard to definitively classify this text as 'Hatespeech', 'Offensive', or 'Normal'. Therefore, I would classify it as '0' (Normal) for now, but with a note that it could potentially be '1' (Offensive) depending on the context.\n",
      "\n",
      "Output: 0 (Normal, with a note that it could potentially be 1 if the context is offensive)\n",
      "Sample 7 Results:  The provided text is: \"even when queers do it only a show henry makow proves that queers are like dogs\"\n",
      "\n",
      "Reasoning: This text directly devalues and attacks the LGBTQ+ community by comparing them to dogs, which is a derogatory stereotype. It links to sexuality, a protected group. Therefore, the output is 2 (Hatespeech).\n",
      "Sample 8 Results:  To classify this text, let's break it down and analyze each term or phrase:\n",
      "\n",
      "1. \"liberals\" - This is a political group, not a protected one. However, if used in a derogatory manner, it could be considered offensive.\n",
      "2. \"contempt for one man their country\" - This seems to refer to a specific individual (presumably a political leader), but it doesn't explicitly target any protected groups.\n",
      "3. \"defend ms <number>\" - It's unclear what \"ms\" stands for in this context, but if it refers to a female leader or official, it could be seen as devaluing women, but the number suggests it might not be a personal attack on an individual.\n",
      "4. \"north korea iran\" - These are countries and their inclusion doesn't seem to target any specific protected groups.\n",
      "5. \"illegal immigrants\" - This term can be seen as devaluing people based on their immigration status, which is not a protected characteristic. However, it's important to note that the context matters, and in this case, it seems to be used in a political discussion rather than an attack on individuals.\n",
      "\n",
      "Sample 9 Results:  The provided text is: \"If you are a jihadi who is funded by my money, then who the hell are you trying to say.\"\n",
      "\n",
      "Reasoning: This text does not directly mention or devalue any protected groups such as race, gender, sexuality, religion, or disability. It seems to be more of a rhetorical question or accusation rather than hate speech or offensive language. However, it does use the term \"jihadi,\" which could potentially be interpreted as targeting Muslims, but without further context, it's not clear if this is intended as hate speech.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 10 Results:  The provided text is: \"well the french are arabs\". This statement does not specifically devalue or attack any protected group based on race, gender, sexuality, religion, or disability. It seems to be a misconception or joke about nationality and ethnicity. Therefore, the output would be 0 (Normal). However, it's important to note that this text could potentially be offensive depending on the context in which it is used or the audience it is being presented to.\n",
      "Sample 11 Results:  The provided text contains several potentially offensive or derogatory terms, including \"jewed,\" \"christcuck,\" and repeated use of \"nigga.\" However, the main intent of the text seems to be criticizing political ideologies and policies rather than directly targeting specific protected groups.\n",
      "\n",
      "The text does mention Jews (through the term \"jewed\") and Christians (through the term \"christcuck\"), but it is not clear that these terms are used to devalue or attack these religious groups as a whole. Instead, they appear to be used in a derogatory manner towards individuals who hold certain political beliefs.\n",
      "\n",
      "The use of the term \"nigga\" is also problematic, as it can be offensive towards black people. However, in this context, it seems to be used as an insult against unspecified individuals rather than as hatespeech directed at black people as a group.\n",
      "\n",
      "Overall, while the text contains several potentially offensive terms, it does not seem to meet the criteria for hatespeech as defined in the provided classification system. It may be more accurately classified as \"Offensive\" (1). However, it is important to note that the use of such language can still\n",
      "Sample 12 Results:  Output (number only): 0\n",
      "\n",
      "Reasoning: The text does not mention or devalue any protected groups, nor is it used as an attack. It's a statement advocating against violence, which is generally considered acceptable in most societies.\n",
      "Sample 13 Results:  The provided text contains multiple instances of offensive and hate speech. It uses derogatory terms such as \"niggers\" and \"sand niggers,\" which are highly offensive towards people of Middle Eastern or North African descent. Additionally, the reference to Hitler and the SS division is a clear allusion to Nazi ideology and genocide, further indicating hate speech.\n",
      "\n",
      "The text also contains devaluation of protected groups based on race, making it a clear example of hatespeech.\n",
      "\n",
      "Output: 2\n",
      "Sample 14 Results:  The provided text \"your memes are shit you can only call someone a kike\" is using the term \"kike\" as an insult, which is derogatory towards Jewish people. This text can be interpreted as hatespeech because it involves devaluation of a protected group (religion).\n",
      "\n",
      "Output: 2\n",
      "Sample 15 Results:  The provided text, \"do not worry about shitposting worry about white people who can not bring themselves to fight back,\" seems to be critical of a specific group (white people) based on their perceived inaction. However, it does not devalue or directly attack them based on their race, religion, gender, sexuality, or disability. Therefore, according to the provided classification system, this text would be classified as '1' - Offensive.\n",
      "\n",
      "However, it's important to note that context plays a significant role in determining whether a statement is offensive or not. In some cases, statements that seem critical of a group can be interpreted as hate speech if they are used to demean, intimidate, or incite violence against that group. Therefore, while this text may not meet the strict definition of hate speech, it could still be considered offensive depending on the context in which it is used and the intentions of the speaker.\n",
      "Sample 16 Results:  The provided text contains derogatory language towards individuals based on their race, religion, and political affiliation. It also includes offensive and inflammatory statements about the potential transformation of iconic British landmarks. This text can be classified as 'Hatespeech' with an output of 2.\n",
      "\n",
      "Reasoning: The text not only mentions but also involves devaluation of protected groups (race, religion) and directly attacks individuals based on their race, religious beliefs, and political affiliations. It also expresses a hostile attitude towards these groups, which can be considered hatespeech. Furthermore, the text includes inflammatory statements about potential changes to iconic landmarks, which could be interpreted as inciting hatred or violence against specific groups.\n",
      "Sample 17 Results:  The provided text directly targets and devalues a protected group (women) by suggesting they are retarded, and also implies negative stereotypes about another group (male feminists). This can be classified as 'Hatespeech'.\n",
      "\n",
      "Output: 2\n",
      "Sample 18 Results:  The provided text contains the term \"faggots,\" which is historically and commonly used as a derogatory slur against the LGBTQ+ community. In this context, it seems to be used in a way that devalues and attacks this protected group. Therefore, according to the given classification system, the output would be: 2 (Hatespeech).\n",
      "Sample 19 Results:  The provided text seems to contain offensive language and potentially inflammatory statements. However, it does not explicitly devalue or attack a specific protected group based on race, gender, sexuality, religion, or disability as defined in the given classification system. Therefore, according to the provided guidelines, this text would be classified as '1 - Offensive'.\n",
      "\n",
      "However, it's important to note that the text does contain strong and potentially harmful language, and its tone could be interpreted as hateful or divisive by some. It also makes serious accusations without providing concrete evidence, which could contribute to fear-mongering or spreading misinformation. Therefore, while not meeting the strict criteria for 'Hatespeech', it is still important to consider the potential negative impact of such statements.\n",
      "Sample 20 Results:  The provided text is \"Rohingias are not refugees, they are illegal infiltrators and a serious security threat.\"\n",
      "\n",
      "Reasoning: This statement seems to be targeting the Rohingya people, an ethnic minority from Myanmar. It implies that they are not legitimate refugees but rather 'illegal infiltrators', which could be seen as devaluing and attacking a specific racial group (Rohingya). Therefore, it can be classified as Hatespeech (Text that not only mentions but also involves devaluation of a protected group linking to race).\n",
      "\n",
      "Output: 2\n",
      "Sample 21 Results:  The provided text \"o this white gurl liked chocolate dick\" can be interpreted as offensive due to the use of racial slurs, specifically \"white\" and \"chocolate\" which is often used to refer to black people in a derogatory manner. However, it does not directly involve devaluation or an attack on a protected group based on race.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 22 Results:  2\n",
      "\n",
      "Reasoning: The text directly targets and devalues people of Middle Eastern descent, specifically using the derogatory term \"raghead\" and making a statement about their religious practices (Halal certified chicken valves). This is hate speech as it links to religion. Additionally, the text expresses a desire for harm towards an individual based on their race or ethnicity, which further qualifies it as hate speech.\n",
      "Sample 23 Results:  The provided text appears to be a statement that expresses strong negative sentiments towards Muslims, which can be considered as a protected group based on religion. The text also suggests violence and war against them, which could be interpreted as incitement of hatred or violence. Therefore, the output for this text would be '2' (Hatespeech).\n",
      "Sample 24 Results:  The provided text \"fucking hate bts stupid band intensifies\" does not specifically target any protected group based on gender, race, sexuality, religion, or disability. It seems to be expressing dislike towards the South Korean boy band BTS. However, it is important to note that this text could still be considered offensive due to the use of profanity and derogatory language.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 25 Results:  This text appears to contain multiple elements that could be considered offensive or hate speech. Here's a breakdown of my reasoning:\n",
      "\n",
      "1. \"pres rchd spencer vice pres\": This seems to refer to Richard Spencer, an American white nationalist and identitarian leader. The mention of him in this context could imply support for his ideologies, which are based on white supremacy and exclusionary nationalism.\n",
      "\n",
      "2. \"hatch plan <number> get jews blacks <number> leave the country\": This part of the text suggests a plan to force Jews and blacks to leave the country, which is a clear example of hate speech targeting racial groups.\n",
      "\n",
      "3. \"universal basic income creates massive hyperinflation the poor the jews move next up\": This statement implies that universal basic income would be detrimental, particularly for the poor and Jews, which could be seen as devaluing these groups.\n",
      "\n",
      "4. \"<number> our team getting gays <number> leave after they have gentrified all the ol black ghettos\": This part of the text suggests a plan to force gay people out of areas inhabited by black people, implying a negative stereotype about gays (\n",
      "Sample 26 Results:  This text, \"kirishima best boy president of the respecting women club top <number> feminists of all time defender of lesbians sweet baby kirishima\", does not contain any derogatory or devaluing language towards protected groups such as gender, race, sexuality, religion, or disability. Instead, it seems to be expressing admiration and support for a character named Kirishima who is associated with feminism and defending lesbians. Therefore, the output would be 0, indicating that this text is 'Normal'.\n",
      "Sample 27 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The text discusses a conversation about crime rates in certain areas, specifically mentioning Ta-Nehisi Coates. It does not involve direct devaluation or an attack on any protected group. Instead, it seems to be a critique of a specific argument made by Coates, which is presented as questionable. While the topic may be sensitive and controversial, the text itself does not qualify as hatespeech or offensive in this context.\n",
      "Sample 28 Results:  The provided text discusses the idea of white people needing organizations to \"regain control of their own nations.\" While it doesn't explicitly devalue or attack any protected groups, it does suggest a preference for white people and a potential exclusionary intent. However, it is important to note that the text also mentions a desire for content creators and podcasts from the alt-right, which can be associated with controversial and divisive ideologies.\n",
      "\n",
      "Given this context, the text could be interpreted as subtly promoting white supremacy or ethnocentrism, but it doesn't directly devalue or attack any specific protected groups. Therefore, I would classify this text as '1 - Offensive.' This classification is based on the potential for the text to promote divisive and exclusionary ideas, even if not explicitly hateful towards a particular group.\n",
      "Sample 29 Results:  The provided text clearly targets a specific racial group (Jews) and makes derogatory statements about them, linking it to their religion. This text can be classified as 'Hatespeech' (2). It is important to note that such language is harmful and should not be tolerated in any context.\n",
      "Sample 30 Results:  The provided text mentions the race of the user (\"white\") but it does not seem to devalue or attack any protected group. Instead, it shows support for a specific event (Justice for Botham Jean Amber Guyger murder trial) and expresses a personal action (\"drive my white ass down to Dallas\"). Therefore, based on the given classification system, this text can be classified as '0' - Normal.\n",
      "Sample 31 Results:  The provided text \"is that chief alinskyite chitownboystownbathhouseboi rahm emmanuel looks sounds like that kike\" can be interpreted as offensive due to the use of the term \"kike,\" which is a derogatory slur against Jewish people. However, it's important to note that this text does not specifically target or devalue Jewish people as a protected group in a systematic or widespread manner. Therefore, according to the given classification system, the output would be 1 (Offensive).\n",
      "\n",
      "Reasoning: The term \"kike\" is used as an insult against an individual (Rahm Emanuel), but it is still considered offensive due to its historical and derogatory connotations towards Jewish people. However, the text does not involve a broader devaluation or attack on Jewish people as a group, which would classify it as hatespeech.\n",
      "Sample 32 Results:  The provided text is offensive, but it doesn't specifically involve devaluation of a protected group. It seems to be an insult towards people from the state Georgia or a stereotype about them. However, the term \"trailer trash\" can be perceived as derogatory and disrespectful towards certain socio-economic groups.\n",
      "\n",
      "Output: 1\n",
      "Sample 33 Results:  The provided text is: \"running gas on this white ass roof ain t it ðŸ¥µ i am too dark for this\"\n",
      "\n",
      "Reasoning:\n",
      "The phrase \"white ass\" can be interpreted as a derogatory term towards Caucasian people, which falls under the category of race. However, in this context, it seems to be used casually and humorously, without any clear intention to devalue or attack white people. The phrase \"i am too dark for this\" could potentially be seen as self-deprecating humor about skin color, but it doesn't directly target or devalue a specific protected group.\n",
      "\n",
      "The text also includes an emoji (ðŸ¥µ) which is often used to express excitement or arousal, and the phrase \"running gas on this white ass roof\" could be interpreted as a metaphorical expression of excitement or amusement, rather than a direct threat or act of violence.\n",
      "\n",
      "Overall, while the text contains potentially offensive language, it doesn't seem to meet the criteria for hatespeech as defined in the provided classification system. It may still be considered offensive due to the use of derogatory terms, but it does not specifically target a protected\n",
      "Sample 34 Results:  The provided text \"meek and mild, come on, don't call him what he is a faggot\" can be interpreted as offensive due to the use of the term \"faggot,\" which is often used as a derogatory slur against homosexual men. However, it does not specifically target a protected group based on sexuality or gender identity in this context. It seems to be an insult directed at an individual rather than a broader attack on a group.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 35 Results:  The provided text \"who asked the quisling who asked the head of the obama clinton crime syndicate who asked the race baiter who asked the muslim terrorist supporting scumbag\" does not specifically target any protected groups based on gender, race, sexuality, religion, or disability. It seems to be a series of insults directed towards unspecified individuals or groups, but it doesn't devalue or attack these protected groups as a whole.\n",
      "\n",
      "Output: 0 (Normal)\n",
      "Sample 36 Results:  Based on the provided criteria, this text seems to involve devaluation of a protected group (Muslims) and directly links it to an attack (sexual assault). Therefore, according to the classification system, this text would be classified as 'Hatespeech'.\n",
      "\n",
      "Output: 2\n",
      "Sample 37 Results:  The provided text \"i understand nazi faggot code you are calling it quits but we both knew you would fag out lol\" contains multiple derogatory slurs, including \"nazi,\" \"faggot,\" and the use of \"fag out\" as an insult. These terms are historically used to devalue and attack people based on their sexual orientation and political beliefs. Therefore, this text can be classified as 'Hatespeech' (Text that not only mentions but also involves devaluation of protected groups linking to gender, race, sexuality, religion, and disability).\n",
      "\n",
      "Reasoning:\n",
      "- \"Nazi\" is a term historically used to devalue and attack people based on their political beliefs.\n",
      "- \"Faggot\" is a derogatory slur used against gay men, intended to devalue and attack them based on their sexual orientation.\n",
      "- The use of \"fag out\" as an insult also falls under the category of homophobic slurs.\n",
      "- The context suggests that the speaker is using these terms in a hostile or derogatory manner towards someone else.\n",
      "Sample 38 Results:  The provided text \"white girl refrigerator i hate you\" does not specifically mention or devalue a protected group based on gender, race, sexuality, religion, or disability. It seems to be an idiomatic expression, often used humorously, where the phrase \"white girl\" is used to represent something bland or uninteresting, and \"refrigerator\" is a common object of dislike due to its coldness. However, it's important to note that context matters greatly in determining whether a statement is offensive or not. In this case, without additional context, the text can be classified as 'Normal'.\n",
      "\n",
      "Output: 0\n",
      "Sample 39 Results:  The provided text \"not just a nigger an immigrant nigger so the church got extra culturally enriched by vibrant diversity ðŸ˜‘\" can be classified as 'Hatespeech'. This statement not only mentions but also involves devaluation of a protected group (race) and it is directly linked to racism. The use of the racial slur \"nigger\" in this context is intended to demean and attack people of color, particularly immigrants. The addition of \"immigrant\" further targets a specific subgroup within that race, intensifying the hate speech. The sarcasm indicated by the emoji at the end does not mitigate the offensive nature of the statement.\n",
      "\n",
      "Output: 2\n",
      "Sample 40 Results:  2 (Hatespeech)\n",
      "\n",
      "Reasoning: The text contains derogatory and offensive language towards Jewish people, specifically using the term \"kikes\" which is a highly offensive slur. It also includes false and harmful stereotypes about Ashkenazi Jews being musicians, artists, and nobility that were raped by Nazis during the Holocaust. Additionally, the text suggests that the speaker's family has no contact with \"actual talmudic kikes,\" which further perpetuates negative stereotypes and dehumanization of Jewish people. The use of such language and false information is intended to devalue and attack a protected group based on their religion.\n",
      "Sample 41 Results:  The provided text seems to be making a statement about a train accident, implying that the driver was mentally retarded or had mental issues. However, it does not specifically target any protected group based on gender, race, sexuality, religion, or disability. Instead, it appears to be criticizing an individual's intellectual capacity.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 42 Results:  The provided text, \"has this nigger looked in the mirror lately,\" is a direct and derogatory reference to black people, which can be considered as an act of devaluation. It falls under the category of 'Hatespeech' (Text that not only mentions but also involves devaluation of protected groups linking to race).\n",
      "\n",
      "Output: 2\n",
      "Sample 43 Results:  The provided text contains derogatory language towards individuals with autism and the LGBTQ+ community, specifically using the term \"faggots.\" This language is intended to devalue and attack these protected groups. Therefore, according to the given classification system, the output for this text would be 'Hatespeech' (Text that not only mentions but also involves devaluation of protected groups linking to gender, race, sexuality, religion, and disability).\n",
      "\n",
      "However, it is important to note that the term \"faggots\" is highly offensive and disrespectful towards the LGBTQ+ community. Even if it were used in a context where it was not directly linked to hatespeech against a specific group, it would still be considered offensive and inappropriate.\n",
      "\n",
      "In this case, the text contains both hatespeech and offensive language, so the output would be 'Hatespeech' (2).\n",
      "Sample 44 Results:  The provided text, \"the Muslim invitation,\" does not contain any derogatory or devaluing language towards a protected group such as religion. It is a neutral statement and can be interpreted as a reference to an Islamic invitation or call to prayer. Therefore, the output would be 0 (Normal).\n",
      "Sample 45 Results:  The provided text \"jus fucked this white bitch cuz fuck slavery and all that racist shit ðŸ¤£ ðŸ¤£ ðŸ˜Ž ðŸ¤¦ ðŸ» â€ â™‚ï¸ ðŸ˜ˆ\" can be classified as 'Hatespeech' (2). This is because the text not only mentions a racial group (white) but also involves devaluation of this group, and it directly links to race by using the term \"slavery,\" which has historical and current connotations related to racism. The use of derogatory language towards a specific racial group indicates that the intent is to devalue or attack this group, making it hatespeech.\n",
      "Sample 46 Results:  The provided text does not specifically target any protected groups based on gender, race, sexuality, religion, or disability. However, it contains strong language and negative sentiment towards politicians. The phrase \"raping our women\" could be interpreted as offensive due to its association with violence against women, but it's not directly devaluing a specific group of women.\n",
      "\n",
      "The text also includes the number \"<number>\", which is not part of the provided statement for classification. If we were to classify the entire text without the number, it would be:\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 47 Results:  The provided text does not specifically target any protected group based on gender, race, sexuality, religion, or disability. It seems to be a criticism of an argument or theory rather than an attack on a specific group. Therefore, the output would be 0, indicating that it is 'Normal'. However, it's important to note that the use of the word \"retarded\" can be considered offensive when used inappropriately, as it was originally a term for intellectual disabilities. In this context, it might be interpreted as such, but not with the intention of devaluing or attacking people with intellectual disabilities. So, while it's not 'Hatespeech', it could still be considered 'Offensive' by some due to the use of that specific word.\n",
      "Sample 48 Results:  The provided text \"and black olives gguk ðŸ˜‚\" does not contain any derogatory or offensive language towards protected groups such as race, gender, sexuality, religion, or disability. It appears to be a casual statement about black olives and an emoticon indicating laughter. Therefore, the output would be '0' - Normal.\n",
      "Sample 49 Results:  The provided text \"how is embracing known enemies that have sworn to destroy this country and replace it with a muslim caliphate not treason\" does not directly devalue or attack any specific protected group based on religion. However, the phrase \"known enemies\" and \"Muslim caliphate\" could be perceived as offensive or inflammatory by some due to historical context and stereotypes associated with Islam.\n",
      "\n",
      "However, it's important to note that the text does not explicitly devalue or attack Muslims as a group, but rather questions the actions of those who might support or align with certain ideologies. Therefore, I would classify this text as '1 - Offensive'.\n",
      "Sample 50 Results:  The provided text does not mention any protected groups, nor does it involve devaluation or direct an attack towards them. It's a statement about the intentions of the founding fathers regarding specific religions. Therefore, the output would be 0, indicating that it is 'Normal'.\n",
      "Sample 51 Results:  The provided text does not mention or involve devaluation of protected groups linking to gender, race, sexuality, religion, or disability. It expresses a dislike towards Nazis, which is a political ideology and not a protected group. Therefore, the output should be '0' (Normal).\n",
      "Sample 52 Results:  The provided text is \"kill yourself nigger fucker\". This text directly targets and devalues a protected group, specifically black people, by using racial slurs. It also contains explicit threats of violence, which can be considered as a form of hatespeech. Therefore, the output should be '2'.\n",
      "Sample 53 Results:  The provided text is \"check out the rockfish report on niggermania they keep up to date on all the bobbing coons nationwide\". This text contains racial slurs (\"nigger\" and \"coon\") which are highly offensive towards black people. It also uses derogatory language (\"bobbing\") that devalues black individuals. Furthermore, the term \"niggermania\" suggests an obsession or celebration of racism, making it a clear example of hatespeech.\n",
      "\n",
      "Output: 2 (Hatespeech)\n",
      "Sample 54 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The text is a casual conversation, does not involve any devaluation or direct attack towards any protected group. It's a response to a temporary ban from a website and includes humor with the use of \"lol\".\n",
      "Sample 55 Results:  The provided text contains several offensive terms, including \"pocontas,\" \"thug,\" \"goatfucker,\" \"illegal,\" and \"crackitute.\" However, it's important to note that these words are used as insults rather than directing an attack on specific protected groups.\n",
      "\n",
      "\"Pocontas\" is a derogatory term towards Native Americans, but it's not linked to any specific individual named Pocahontas. \"Thug\" can be seen as offensive towards certain ethnicities, but in this context, it's not used with the intention of devaluing or attacking a particular race or ethnicity. \"Goatfucker\" is an extremely vulgar and offensive term, but it doesn't specifically target any protected group. \"Illegal\" can be seen as offensive towards immigrants, but it's not used in a way that suggests a broader attack on all immigrants. \"Crackitute\" is a derogatory term towards drug addicts, but it's not linked to a specific protected group.\n",
      "\n",
      "The term \"pizzagate\" is a conspiracy theory that has been used to spread misinformation and hate, particularly against certain political figures. However, in this\n",
      "Sample 56 Results:  The provided text seems to contain derogatory language towards immigrants, which could be interpreted as offensive or hate speech. However, it does not specifically mention or target a protected group based on gender, race, sexuality, religion, or disability. Instead, it appears to be making a generalized and negative statement about immigrants.\n",
      "\n",
      "The text also includes a reference to the Charlie Chaplin movie \"Immigrant\", which might suggest that the author is using this term in a metaphorical or humorous way, but the overall tone of the text is still negative and potentially offensive.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 57 Results:  The provided text seems to contain derogatory language towards a specific racial group, implying that the condition of certain areas or industries worsens when black people move in. This can be interpreted as devaluing and directing an attack on a protected group based on race. Therefore, the output for this text would be '2' (Hatespeech).\n",
      "Sample 58 Results:  Output: 2\n",
      "\n",
      "Reasoning: The phrase \"retarded child\" is devaluing towards people with intellectual disabilities, and the context suggests that getting rid of them is being considered, which could be interpreted as a direct attack on this protected group.\n",
      "Sample 59 Results:  To classify the provided text, let's break it down:\n",
      "\n",
      "Text: \"jewelry kike perverts gassed me on twitter and preventing fake phone number accounts enjoying gab way better\"\n",
      "\n",
      "Reasoning:\n",
      "1. The term \"kike\" is historically used as a derogatory slur against Jewish people, which can be considered offensive or hate speech.\n",
      "2. \"Perverts\" could potentially be interpreted as devaluing certain individuals, but it's not specific to any protected group.\n",
      "3. The phrase \"gassed me on twitter\" is unclear and may not directly relate to the use of hate speech.\n",
      "4. The comparison between Twitter and Gab seems irrelevant to the classification of hate speech or offensiveness.\n",
      "\n",
      "Output (number only): 1 - Offensive, as it contains a derogatory slur against Jewish people (Jews being a protected group).\n",
      "Sample 60 Results:  The provided text contains multiple offensive elements: \"gay PBS,\" \"good lil white bitch.\" However, it does not specifically target protected groups based on gender, race, sexuality, religion, or disability. Therefore, the output should be '1' - Offensive.\n",
      "\n",
      "The text is toxic and uses derogatory language as an insult, but it doesn't involve devaluation of any specific group in a systematic or generalized manner. The use of \"gay\" as an insult towards homosexuality can be considered offensive, while the racial slur \"white\" is used in a derogatory way within the phrase \"lil white bitch.\" However, the text does not specifically target people based on their race, gender, sexuality, religion, or disability.\n",
      "Sample 61 Results:  The provided text \"dwg courtois is a fucking disgrace\" does not specifically mention or devalue any protected groups based on gender, race, sexuality, religion, or disability. It seems to be expressing strong negative feelings towards an individual named \"dwg courtois.\" Therefore, the output would be 0, indicating that it's considered 'Normal.' However, it's important to note that the context in which this statement is used could potentially change its classification if it's revealed that \"dwg courtois\" belongs to a protected group and the statement is used to devalue or attack them.\n",
      "Sample 62 Results:  2\n",
      "\n",
      "Reasoning: The text directly targets and devalues a protected group (LGBTQ+) by using derogatory slurs (\"faggots\") and expresses indifference towards their suffering, which can be seen as promoting violence against them. This is considered hatespeech.\n",
      "Sample 63 Results:  The provided text, \"<user> no are you retarded\", can be interpreted as offensive due to the use of \"retarded\" as an insult. However, it does not specifically target a protected group based on disability. Therefore, the output is 1 (Offensive).\n",
      "Sample 64 Results:  2 - This statement directly involves devaluation and an attack on a protected group (women), specifically by threatening violence against them. It is hate speech.\n",
      "Sample 65 Results:  The provided text seems to be making a comparison between two groups of people and their online activities, with one group hoping their actions end up on Worldstar Hip Hop (a platform known for featuring viral videos from urban culture) and the other group hoping their actions end up in a list by Media Matters (an organization that monitors conservative media). The term \"ghetto\" is used to describe the first group, which could be perceived as stereotypical or derogatory towards certain communities. However, it does not specifically target a protected group based on race, gender, sexuality, religion, or disability.\n",
      "\n",
      "In this context, the text can be interpreted as offensive due to the use of \"ghetto\" as a potentially derogatory term, but it does not meet the criteria for hatespeech as defined in the provided guidelines because it does not involve devaluation of a protected group.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 66 Results:  The provided text does not specifically target a protected group or involve devaluation of any group. It seems to be an expression of frustration from the author, who is white, towards other whites. However, it doesn't use derogatory language or make generalizations about all white people. Therefore, based on the given classification system, this text would be classified as '0 - Normal'.\n",
      "\n",
      "However, it's important to note that while this text may not meet the criteria for hatespeech or offensive content according to the provided guidelines, it could still be perceived as aggressive or divisive by some. Encouraging understanding and respectful dialogue among all individuals is crucial in maintaining a harmonious society.\n",
      "Sample 67 Results:  The provided text \"i am presuming he means the standard left wing idiots lots of hypocritical women amongst them think maria ladenburger obviously you are against these fucking muhammadans\" can be classified as '1 - Offensive'.\n",
      "\n",
      "Reasoning: This text uses derogatory language towards a political group (left-wing idiots) and gender (hypocritical women), but it does not specifically target any protected groups based on race, sexuality, religion, or disability. However, the use of \"fucking muhammadans\" can be considered offensive as it stereotypes and devalues a religious group. The overall tone of the text is disrespectful and toxic.\n",
      "Sample 68 Results:  The provided text is: \"rajini with indian muslims from <number> coimbatore blasts till now thalaivar has always been supportive to muslim brother\"\n",
      "\n",
      "Reasoning: This text does not involve any devaluation or direct attack on a protected group. It mentions the support of a person (Thalaivar) towards Muslims, which is not inherently offensive. However, if the context suggests that the support is unwarranted or problematic, it could be interpreted as controversial or questionable, but not necessarily hate speech or offensive.\n",
      "\n",
      "Output: 0 (Normal)\n",
      "Sample 69 Results:  The provided text \"negerball has went full ghetto apefreaka looking forward to the before after photos like 1 9 2 0 dietriot to today\" contains multiple derogatory and offensive terms, including racial slurs (\"neger,\" \"ape\") and dehumanizing language (\"ghetto\"). This text is intended to devalue and attack a specific group (black people) based on their race. Therefore, the output for this text would be '2' as it qualifies as Hatespeech.\n",
      "Sample 70 Results:  The provided text, \"if money was grown on trees women would be dating monkeys oh wait never mind,\" does not specifically mention or devalue any protected groups based on gender, race, sexuality, religion, or disability. It is a joke that uses an absurd comparison and does not seem to be intended as hate speech or offensive.\n",
      "\n",
      "Output: 0 (Normal)\n",
      "Sample 71 Results:  2\n",
      "\n",
      "Reasoning: The text directly targets a specific race (Sand Nigger) and involves devaluation, which is a form of hate speech. Additionally, it suggests violence against an individual based on their race, which is extremely offensive and dangerous.\n",
      "Sample 72 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The text expresses positive emotions towards another user, using emojis to convey affection. There is no devaluation or attack on any protected group in this context.\n",
      "Sample 73 Results:  The provided text \"a bitch needs a hair cut tattoo and vacation\" can be interpreted as offensive, but it does not specifically target a protected group such as gender or race. It is used as an insult towards women in general. However, the term \"bitch\" is often used derogatorily to demean women, which can be considered disrespectful or offensive.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 74 Results:  The provided text is: \"this hoe needs to get beat down omg\"\n",
      "\n",
      "Reasoning: This text can be interpreted as a direct attack and devaluation of women, using the derogatory term \"hoe\". It also implies violence against them. Therefore, it falls under the category of 'Hatespeech'.\n",
      "\n",
      "Output: 2\n",
      "Sample 75 Results:  The provided text \"<user> honey i aint u r just into dykes ðŸ¥º\" can be interpreted as offensive, but it does not specifically involve devaluation of a protected group. The term \"dyke\" is often used as a derogatory term towards lesbians, but in this context, it seems to be used in a conversation between individuals who may identify as LGBTQ+ themselves. However, the use of the term can still be considered disrespectful and offensive.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 76 Results:  The provided text seems to discuss personal relationships and marriages between individuals of different ethnicities, without any clear intention to devalue or attack protected groups. However, the term \"Paki\" could be perceived as offensive towards people from Pakistan. To classify this text, let's consider its main intent:\n",
      "\n",
      "1. The text does not explicitly devalue or attack a specific group based on race, gender, sexuality, religion, or disability.\n",
      "2. It discusses personal relationships and marriages between individuals of different ethnicities, which might be seen as neutral information.\n",
      "3. However, the use of \"Paki\" could be perceived as offensive towards people from Pakistan.\n",
      "\n",
      "Taking these points into account, I would classify this text as:\n",
      "\n",
      "Output (number only): 1 - Offensive\n",
      "Sample 77 Results:  The provided text contains multiple racial slurs, including \"nigger,\" \"monkey,\" and \"negra.\" These terms are historically used to devalue and discriminate against people of African descent. Therefore, the text can be classified as 'Hatespeech' with an output of '2'. It is important to note that such language is harmful and offensive, and should not be tolerated in any context.\n",
      "Sample 78 Results:  The provided text does not directly mention or devalue any protected groups based on gender, race, sexuality, religion, or disability. However, it does reference Nazis, a group known for their hate speech and genocide against Jews during World War II. While the intent of the text might be to express disapproval or threat, it could potentially be interpreted as promoting violence towards a specific group (Nazis).\n",
      "\n",
      "However, it's important to note that the text does not explicitly call for violence or hate speech against any protected groups. Therefore, I would classify this text as '1 - Offensive'. The reasoning is that while the text might not be directly hatespeech, it could still be considered offensive due to its potential association with a historically violent and hateful group (Nazis).\n",
      "Sample 79 Results:  Output: 0\n",
      "\n",
      "Reasoning: The text does not mention or involve devaluation of any protected groups, nor is it used as an attack or insult. Instead, it promotes a positive message about women supporting each other and spreading love. It encourages sisterhood and positivity, which are generally considered normal and positive sentiments.\n",
      "Sample 80 Results:  The provided text, \"<user> <user> siss why you posting retard b did she sure you,\" can be interpreted as using the term \"retard\" in a derogatory manner towards people with intellectual disabilities. However, it does not specifically target a protected group based on gender, race, sexuality, religion, or disability. Therefore, according to the provided classification system, the output would be 1 (Offensive).\n",
      "Sample 81 Results:  The provided text does not mention any protected groups, gender, race, sexuality, religion, or disability. It is a reference to Bill Cosby's legal case and a band named REO Speedwagon. Therefore, the output would be 0, indicating that it can't be interpreted as hatespeech.\n",
      "Sample 82 Results:  The provided text contains racial slurs (\"niggers\") and a derogatory term (\"gold\"). It is used in a way that devalues and attacks a specific group, in this case, black people. Therefore, the output should be '2' as it qualifies as 'Hatespeech'.\n",
      "Sample 83 Results:  The provided text \"it all hehe haha until we show up at your local favorite hang out spot and wait for you to come out in the van they go one little heeb at a time whatever it takes\" can be classified as 'Hatespeech' (2). This is because the term \"heeb\" is often used as a derogatory slur against Jewish people, and the context suggests a violent intent towards them. The use of this word in such a threatening manner is clearly intended to devalue and attack a protected group based on their religion.\n",
      "Sample 84 Results:  The provided text contains derogatory language towards racial and ethnic groups, as well as a stereotype about sexuality. It implies that minority populations are producing \"fatherless niglet boys\" for the benefit of gay men, which is a harmful and dehumanizing stereotype. This text can be classified as 'Hatespeech' (2).\n",
      "Sample 85 Results:  The provided text seems to express a critical opinion about certain media, specifically targeting those perceived as promoting an unconventional view of beauty for women. However, it does not directly devalue or attack any specific protected group based on gender, race, sexuality, religion, or disability. Therefore, the output should be '0' (Normal).\n",
      "\n",
      "However, it's important to note that the text could still be considered offensive due to its tone and potential for misinterpretation. The use of terms like \"homosexual\" and \"jewish media\" might be perceived as stereotypical or disrespectful by some individuals. To avoid misunderstandings, it would be more appropriate to use specific terms such as \"LGBTQ+ media\" instead of \"homosexual,\" and to avoid generalizing an entire group based on their profession or affiliation.\n",
      "\n",
      "In summary, the text can be classified as '0' (Normal) in terms of hatespeech, but it could still be considered offensive due to its tone and potential for misinterpretation. To make the text more inclusive and respectful, consider revising it to avoid stereotypes and generalizations.\n",
      "Sample 86 Results:  The provided text seems to express a critical viewpoint towards feminism, suggesting that it prioritizes the interests of some women over men, particularly those of higher status. However, it does not directly devalue or attack any specific protected group based on gender, race, sexuality, religion, or disability.\n",
      "\n",
      "Therefore, according to the provided classification system:\n",
      "Output (number only): 1 (Offensive)\n",
      "Sample 87 Results:  The provided text is: \"these niggas be so weird out young and old do not know how to approach a female\"\n",
      "\n",
      "Reasoning:\n",
      "The term \"nigga\" can be considered offensive towards black people, but in this context, it seems to be used as a generalization about a group of men (not specifically targeting black men). The phrase \"out young and old\" suggests the group includes individuals across different age ranges. However, the statement implies that these men lack social skills or etiquette when approaching women, which could be perceived as disrespectful or offensive towards women.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 88 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The text does not mention or devalue any protected groups, nor is it used as an attack. Instead, it seems to be a neutral statement about the historical process of immigration.\n",
      "Sample 89 Results:  Output: 1 (Offensive)\n",
      "\n",
      "Reasoning: The term \"retarded\" is often used as an insult and can be seen as devaluing people with intellectual disabilities. However, in this context, it seems to be used to express strong disagreement with an idea rather than directly targeting a specific group of individuals. Therefore, while offensive, it may not strictly fall under the category of hatespeech.\n",
      "Sample 90 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The text discusses political concepts and ideas, specifically the critique of representation as a form of oppression. It does not involve any direct devaluation or attack on protected groups based on gender, race, sexuality, religion, or disability.\n",
      "Sample 91 Results:  The provided text \"when i was young my goal was to be like jane curtin on snl an ignorant slut finally realized my goals\" does not specifically target any protected group or involve devaluation. Instead, it seems to refer to a specific character from Saturday Night Live, \"an ignorant slut,\" which was the name of a sketch performed by Jane Curtin. Therefore, based on the given classification system, this text would be classified as '0' - Normal.\n",
      "Sample 92 Results:  The provided text \"paul i like you and appreciate what you are doing but you are being a retard right now\" can be interpreted as offensive due to the use of the term \"retard\" which is considered derogatory towards people with intellectual disabilities. However, it does not specifically target or devalue a protected group in a systematic way, so it's not hatespeech.\n",
      "\n",
      "Output: 1\n",
      "Sample 93 Results:  The provided text mentions a group, which in this case is \"conservative Arabs.\" However, it does not devalue or attack them directly. Instead, it seems to be expressing frustration with a specific characteristic of an individual from that group (being nosy). Therefore, the text can be classified as '1 - Offensive.' The use of the term \"isp aint shit\" might be considered disrespectful, but it does not specifically target or devalue the Arab community.\n",
      "Sample 94 Results:  Output: 0\n",
      "\n",
      "Reasoning: The text discusses a concept related to immigration policy, specifically chain migration. It does not contain any derogatory or offensive language towards protected groups such as race, gender, sexuality, religion, or disability. Therefore, it cannot be classified as hatespeech or offensive.\n",
      "Sample 95 Results:  1 (Offensive)\n",
      "\n",
      "Reasoning: The text expresses criticism towards the UK police, using derogatory terms like \"useless joke\" and \"retarded\". While it doesn't directly target a specific protected group, the use of \"pansy men\" can be considered offensive to men. Additionally, the phrase \"unarmed women\" might be interpreted as belittling or mocking the capabilities of women, although this is not explicit hatespeech.\n",
      "Sample 96 Results:  The provided text \"<user> parties with leo room full of bad bitch and fine niggas\" can be interpreted as using derogatory terms for women (\"bad bitch\") and people of color (\"niggas\"). However, it does not seem to devalue or attack any specific protected group. It is more about describing the people at a party in a stereotypical manner.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 97 Results:  This text appears to be a news headline or a statement about a tragic event. It does not contain any derogatory language or slurs that are commonly associated with hatespeech. The text mentions the nationality of the victims and the location of the incident, but it does not devalue or attack any protected groups. Therefore, based on the provided criteria, this text can be classified as 'Normal'.\n",
      "\n",
      "However, it's important to note that discussing sensitive topics like this should always be done with respect and sensitivity towards the victims and their families. The number in the text seems irrelevant to the classification, so I've left it out of my analysis.\n",
      "Sample 98 Results:  2\n",
      "\n",
      "Reasoning: The text directly targets women, devaluing them by suggesting that they should be violent towards their abusers. It also uses derogatory language (\"savages\") to describe the victims of rape, which is a form of violence and abuse. This text encourages violence against women and dehumanizes them, making it a clear example of hate speech.\n",
      "Sample 99 Results:  The provided text \"Europe is being stolen blind by the muzrat hordes\" can be classified as 'Hatespeech'. This statement involves devaluation of a protected group, in this case, people of Middle Eastern or Muslim descent. The term \"muzrat\" is often used as a derogatory slur against these groups, and the phrase \"stolen blind\" implies that they are taking something that doesn't belong to them, which can be seen as dehumanizing and promoting prejudice.\n",
      "Sample 100 Results:  The provided text \"lmao a lot of you all new bitches be my old ho\" can be interpreted as disrespectful or offensive towards women, but it does not specifically target a protected group based on gender, race, sexuality, religion, or disability. It is used in a casual, flirtatious manner and does not involve devaluation of the group.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 101 Results:  The provided text directly targets multiple protected groups (blacks, Jews, Muslims, Mexicans or Latinos, and Asians) with a derogatory tone. It implies that these groups are trying to harm others or are proud of being harmful. This text fits the definition of 'Hatespeech' as it involves devaluation and direct attacks on multiple protected groups based on their race, religion, and ethnicity.\n",
      "\n",
      "Output: 2\n",
      "Sample 102 Results:  The provided text is: \"trump needs to fire that kike rod rosenstein he should have known you can not trust a jew\"\n",
      "\n",
      "Reasoning: This text directly targets and devalues a specific religious group, Jews. It implies that all Jews are untrustworthy, which is a stereotype and a form of hate speech. Therefore, the output is 2 (Hatespeech).\n",
      "Sample 103 Results:  The provided text \"im really a pretty bitch\" does not mention or involve devaluation of any protected groups such as gender, race, sexuality, religion, or disability. It is used to describe oneself in a self-deprecating manner and can be considered a colloquial expression.\n",
      "\n",
      "Output: 0 (Normal)\n",
      "Sample 104 Results:  2\n",
      "\n",
      "Reasoning: The text directly links to devaluation of a protected group (women) and religion (Muslims). It also implies a derogatory term (\"white slut\") towards women, which is often used as an insult. This text can be interpreted as hatespeech.\n",
      "Sample 105 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The text is making an observation about the similarity between two cultural outfits, without any intent to devalue or attack a specific group. It does not involve devaluation of protected groups linking to race or ethnicity.\n",
      "Sample 106 Results:  The provided text directly links race and ignorance, which can be interpreted as devaluing a specific racial group. However, it does not explicitly call for violence or discrimination against the group. Therefore, this text can be classified as '1 - Offensive'.\n",
      "\n",
      "Reasoning: While the text suggests a correlation between being ignored by a white man and being a \"nigger\", it does not directly attack or devalue all white people. Instead, it is used to express frustration or anger towards an individual's behavior. However, the use of the term \"nigger\" is offensive and disrespectful towards black people.\n",
      "Sample 107 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The text does not mention or devalue any protected groups, and it is a common expression of frustration or annoyance between individuals. It does not involve hatespeech or offensive language towards any group.\n",
      "Sample 108 Results:  2\n",
      "\n",
      "Reasoning: The text directly targets Kamala Harris, a woman of color who is the Vice President of the United States. It devalues her by suggesting that she is easy to be raped and killed, which is a form of dehumanization. Additionally, it links this devaluation to her gender and race. Furthermore, the text also involves an attack on her political beliefs by implying that she jokes about killing someone (Trump). This text can be considered as hate speech towards Kamala Harris due to its devaluing nature and direct attack on her based on her gender, race, and political beliefs.\n",
      "Sample 109 Results:  The provided text, \"milton is a kike lover who pretends to be against communism when he promotes degeneracy,\" can be classified as 'Hatespeech' (Text that not only mentions but also involves devaluation of protected groups linking to religion). The term \"kike\" is historically and currently used as an anti-Semitic slur, and in this context, it is used to devalue Milton based on his perceived religious beliefs. Additionally, the phrase \"promotes degeneracy\" could be interpreted as a derogatory comment towards certain cultural or moral values, further reinforcing the hateful nature of the text.\n",
      "Sample 110 Results:  Output: 1\n",
      "\n",
      "Reasoning: The text \"too bad you are retarded and can not read\" is offensive as it uses the term \"retarded\" in a derogatory manner towards people with intellectual disabilities. However, it does not specifically target a protected group or involve devaluation of them. It's more about insulting someone's intelligence rather than hating on a specific group.\n",
      "Sample 111 Results:  0 (Normal)\n",
      "Reasoning: The text promotes acceptance and equality among different groups, including gender, race, sexuality, religion, and disability. It does not involve devaluation or direct attacks on any of these groups.\n",
      "Sample 112 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The text does not involve devaluation of any protected group, nor does it link to gender, race, sexuality, religion, or disability. It's a question about the contradiction between being a nationalist and being a Muslim, which is a topic of discussion rather than hate speech or offense.\n",
      "Sample 113 Results:  The provided text contains multiple statements about Mahatma Gandhi, some of which are controversial and could be interpreted as devaluing or attacking certain groups based on religion (Jews), gender (women), and race (black people). However, it's important to note that the text is not directly addressing these groups but rather making statements about Gandhi's actions.\n",
      "\n",
      "In this context, the text can be seen as a critique or criticism of Gandhi's actions, which could be considered offensive due to the controversial nature of the statements. However, it does not seem to be intended as hatespeech towards specific groups.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 114 Results:  The provided text \"my friends highkey got that bitch personality i fucking hate them\" can be interpreted as offensive due to the use of derogatory language (\"bitch\") and expressing dislike towards others. However, it does not specifically target a protected group based on gender. Therefore, the output is 1 (Offensive).\n",
      "\n",
      "Reasoning: While \"bitch\" is often used as an insult against women, in this context, it seems to be directed at friends of the speaker, regardless of their gender. The use of the term does not appear to involve devaluation or direct an attack on a specific group of women. Instead, it is used as an insult towards individuals. However, the text still contains offensive language and expresses negative feelings.\n",
      "Sample 115 Results:  The provided text appears to contain derogatory language and stereotypes towards various racial and ethnic groups, which can be considered as hate speech. Specifically, it refers to whites being ethnically cleansed, uses the term \"shitskin,\" and encourages whites to trust in their whiteness. Therefore, the output for this text would be '2'.\n",
      "Sample 116 Results:  The provided text is: \"it true i am fairly retarded at bird identification i have no egrets about it pic giant bird eats man after he sprays paint on it\"\n",
      "\n",
      "Reasoning:\n",
      "The term \"retarded\" is historically used as a derogatory term for people with intellectual disabilities. However, in this context, the author seems to be using it humorously and self-deprecatingly to express their difficulty identifying birds. The phrase \"have no egrets\" is a play on words, referring to the bird species 'egret' while also meaning 'regrets'.\n",
      "\n",
      "The text does not involve devaluation or direct an attack towards any protected group based on gender, race, sexuality, religion, or disability. Instead, it seems to be a light-hearted joke about the author's inability to identify birds.\n",
      "\n",
      "Output: 0 (Normal)\n",
      "Sample 117 Results:  The provided text is discussing a hypothetical situation, but it does not directly involve devaluation or an attack on any protected group. It's more about speculating someone's reaction in a certain scenario. However, the term \"nigger\" is offensive and derogatory towards black people when used as an insult. In this context, the text seems to be using it in that manner, but it's not directly targeting or devaluing any specific individual or group.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 118 Results:  The provided text \"<user> <user> this is what feminazi consider being born again\" does not specifically mention or devalue any protected groups based on gender, race, sexuality, religion, or disability. It seems to be a generalized statement about a group of people (feminazis) and their beliefs. However, it could potentially be perceived as offensive due to the use of the term \"feminazi,\" which some may find derogatory towards feminists.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 119 Results:  The provided text contains multiple elements that can be considered offensive or hateful towards different protected groups. Here's a breakdown:\n",
      "\n",
      "1. \"fake americans\" could potentially target immigrants, asylum seekers, or people of certain ethnicities who are perceived as not being 'authentic' Americans.\n",
      "2. \"killing each other on us soil\" might be interpreted as promoting violence against specific groups, although it is vague and open-ended.\n",
      "3. \"msm response how can we make this some white dude fault right now\" suggests a bias against white people, implying that they are being unfairly exonerated or not held accountable for certain actions.\n",
      "4. \"they are trying to bleach out the pigment of the illegal alien face\" is clearly racist and dehumanizing towards immigrants, particularly those of color.\n",
      "5. \"make sure the muslim american girl looks suitably cute in every photo\" objectifies a specific group (Muslim American women) and reinforces harmful stereotypes about them.\n",
      "6. \"goback\" is a common racist trope used to tell people, often immigrants or people of color, to return to their 'home' country.\n",
      "\n",
      "Given the\n",
      "Sample 120 Results:  The provided text seems to express a critical viewpoint about American laziness in comparison to African countries, and it also distinguishes between Africans and \"white supremacy.\" However, it does contain a generalization about Americans being lazy. While this might be perceived as offensive or disrespectful by some, it doesn't specifically target protected groups based on race, gender, sexuality, religion, or disability.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 121 Results:  The provided text does not mention or involve devaluation of protected groups linking to gender, race, sexuality, religion, or disability. It seems to be referring to a specific type of fan fiction and using derogatory language towards those who write it. However, the term \"a b o bitches\" could be considered offensive due to its derogatory nature.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 122 Results:  The provided text contains multiple derogatory and offensive terms towards different protected groups, including racial slurs (\"niggers\"), dehumanizing language (\"apes\"), and religious stereotypes (\"owned by Jews\"). It also demonstrates a disregard for the intelligence of certain individuals (\"<number> iq\").\n",
      "\n",
      "Given the context, it is clear that the text is intended to devalue and attack these groups. Therefore, according to the provided classification system, this text would be classified as 'Hatespeech' (Text that not only mentions but also involves devaluation of protected groups linking to race, religion, and disability).\n",
      "\n",
      "Output: 2\n",
      "Sample 123 Results:  The provided text \"<user> <user> so it not okay to be white\" does not specifically mention or devalue a protected group based on race. It seems more like a statement or question open for discussion, rather than an expression of hate or offense. Therefore, the output would be 0 (Normal).\n",
      "\n",
      "However, it's important to note that this text could potentially be interpreted as offensive or problematic in certain contexts, especially given the current political and social climate. It's always crucial to consider the broader conversation and the intentions behind the words used.\n",
      "Sample 124 Results:  The provided text does not directly mention or devalue a specific protected group, nor is it used as an attack against them. It suggests that the users should go to a Muslim country if they speak in a certain way, which could be interpreted as a general statement about respecting cultural norms rather than hatespeech or offensive language towards Muslims.\n",
      "\n",
      "Output: 0 (Normal)\n",
      "Sample 125 Results:  Output: 2\n",
      "\n",
      "Reasoning: The text explicitly devalues and targets a protected group (men) by denying their ability to be victims of rape and abuse. It also reinforces harmful stereotypes about men being perpetrators and women and children being the primary victims, which can contribute to violence against these groups.\n",
      "Sample 126 Results:  The provided text contains derogatory language towards multiple protected groups, including Jews (\"goy\"), Black people (\"nigger\"), and Muslims (\"muzzie\"). It also implies a negative association between these groups, which can be seen as devaluing them. Therefore, the output should be '2' as it meets the criteria for Hatespeech.\n",
      "Sample 127 Results:  The provided text \"hating beaners is so easy\" can be interpreted as targeting a specific ethnic group, in this case, people of Mexican or Hispanic descent, as \"beaner\" is a derogatory term often used towards them. Therefore, the output would be: 2 (Hatespeech)\n",
      "Sample 128 Results:  Output (number only): 0\n",
      "\n",
      "Reasoning: The text does not mention or devalue any protected groups, nor is it used as an attack on them. It's a common financial saying and doesn't contain any offensive language or slurs.\n",
      "Sample 129 Results:  The provided text \"this communist bitch has to go she should not be teaching middle school or any school for that matter she a danger to freedom and to society outantifa\" can be classified as '1 - Offensive'.\n",
      "\n",
      "Reasoning: This text is offensive due to the use of derogatory language (\"bitch\") towards a specific individual, and it also contains political slurs (\"communist\", \"outantifa\"). However, it does not specifically target protected groups based on gender, race, sexuality, religion, or disability. The text implies that the person is a danger to society and freedom, but this is a political opinion rather than hatespeech.\n",
      "Sample 130 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The text does not mention or devalue any protected groups based on gender, race, sexuality, religion, or disability. It is a personal comment about interacting with progressives on Facebook and writing for publication. While the use of \"f***book\" and the censored word might be considered informal or inappropriate by some, it does not qualify as hatespeech or offensive towards any specific group.\n",
      "Sample 131 Results:  The provided text does not specifically mention or devalue any protected groups based on gender, race, sexuality, religion, or disability. However, it seems to express disapproval towards a specific ideology (communism) and religion (Muslim). But the tone is more critical of their political beliefs rather than an attack on the individuals themselves or their identity.\n",
      "\n",
      "Therefore, based on the given classification system, this text can be classified as '1 - Offensive'. It's important to note that while it may not meet the criteria for 'Hatespeech', it still contains language that could be considered disrespectful and harmful.\n",
      "Sample 132 Results:  The provided text contains derogatory language and expressions towards Jewish people, which is a protected group based on religion. It also promotes conspiracy theories about Jews posing as neo-Nazis to control others. This text can be classified as 'Hatespeech' (Text that not only mentions but also involves devaluation of a protected group).\n",
      "\n",
      "Output: 2\n",
      "Sample 133 Results:  1 - Offensive. The text implies a generalization about Islamists, left loonies, and Muslims as a whole, which could be perceived as offensive. However, it does not specifically involve devaluation or direct attacks on protected groups based on race, gender, sexuality, religion, or disability. The text is toxic due to the derogatory tone towards certain political ideologies and potential religious groups.\n",
      "Sample 134 Results:  The provided text \"<user> <user> lmao shut up bitch report that\" is not directly targeting or devaluing a protected group based on gender, race, sexuality, religion, or disability. It can be interpreted as rude or disrespectful, but it does not meet the criteria for hatespeech or offensive speech as defined in the provided context.\n",
      "\n",
      "Output: 0 (Normal)\n",
      "Sample 135 Results:  The provided text seems to be targeting a specific political group (\"the tolerant left\") and making accusations that they are responsible for harm to children, tax evasion, and promoting violence. However, it does not specifically mention or devalue any protected groups based on gender, race, sexuality, religion, or disability. Therefore, according to the provided classification system, this text would be classified as '1' - Offensive.\n",
      "\n",
      "However, it's important to note that the tone and language used in the text can still be considered inflammatory and divisive, potentially causing harm or offense to those who read it. It's always important to promote respectful and inclusive communication in all interactions.\n",
      "Sample 136 Results:  The provided text, \"this pic shows success and the ghetto all in one area,\" does not specifically target or devalue any protected group. It seems to be a statement about a picture's content, discussing the coexistence of two contrasting conditions. Therefore, based on the given classification system, this text can be classified as '0 - Normal'.\n",
      "\n",
      "However, it's important to note that the term \"ghetto\" has historically been used in a derogatory manner to refer to impoverished urban neighborhoods with high concentrations of racial or ethnic minorities. While it might not be intended as such in this specific context, its use can potentially be perceived as offensive or stereotypical by some individuals.\n",
      "\n",
      "In order to avoid potential misunderstandings, it's always a good practice to choose words carefully and consider their historical connotations when communicating with others.\n",
      "Sample 137 Results:  The provided text appears to contain derogatory language towards certain racial, ethnic, and socio-economic groups. Specifically, it uses the terms \"redneck\" and \"white trash\" in a negative and degrading manner. While these terms may not be directly linked to protected groups such as race or disability, they are often used to stereotype and devalue white, working-class individuals.\n",
      "\n",
      "Additionally, the use of the term \"skanks\" is derogatory towards women, particularly those from lower socio-economic backgrounds. The text also includes a reference to \"hillbilly\" which can be seen as offensive due to its historical and current connotations of rural, uneducated, and unsophisticated individuals.\n",
      "\n",
      "Overall, the text appears to contain hate speech and offensive language towards multiple groups based on race, ethnicity, and gender.\n",
      "\n",
      "Output: 2\n",
      "Sample 138 Results:  0 (Normal)\n",
      "Reasoning: The provided text does not mention or devalue any protected groups, nor is it used as an attack. It's simply a statement of dislike towards the user in question.\n",
      "Sample 139 Results:  Based on the provided context, the text seems to be discussing a change in ownership of liquor stores from Blacks to Arabs in certain areas. It does not explicitly devalue or attack any protected group, and its main intent appears to be describing a societal shift. Therefore, according to the classification system provided:\n",
      "\n",
      "Output: 0 (Normal)\n",
      "Sample 140 Results:  1 (Offensive)\n",
      "\n",
      "Reasoning: The text contains a derogatory term (\"crowd\") that could be perceived as offensive, but it does not specifically target any protected group based on race, gender, sexuality, religion, or disability. The user expresses feeling offended if they are not part of the crowd, which could imply exclusion or bias, but it's not clear who the \"crowd\" refers to in this context.\n",
      "Sample 141 Results:  The provided text seems to be critical of a group of people, specifically \"white het boys.\" However, the criticism is directed towards their behavior (recycling old jokes and hiding insecurities) rather than devaluing them based on their race, gender, or sexuality. The text also appears to be critical of specific actions (holocaust, racist, sexist, homophobic jokes), which could be seen as offensive but not necessarily hatespeech.\n",
      "\n",
      "Output: 1 - Offensive\n",
      "Sample 142 Results:  The provided text contains multiple instances of offensive language and devaluation, particularly towards black people (using the term \"niggers\" in a derogatory manner) and towards individuals who may not conform to certain beauty standards or aesthetics (referring to them as \"faux niggers\" and implying they should be exiled).\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 143 Results:  Output: 2\n",
      "\n",
      "Reasoning: The text directly targets and devalues a protected group (black people) by using racial slurs, making derogatory statements about their country, and implying violence against them. It also expresses a desire for the reinstatement of apartheid, which was a system of institutionalized racial segregation that discriminated against black South Africans. This text is clearly hate speech.\n",
      "Sample 144 Results:  The provided text does not mention any protected groups, gender, race, sexuality, religion, or disability explicitly. However, it seems to imply a derogatory or disrespectful attitude towards women based on their race (white). This could be considered offensive but not necessarily hatespeech as it doesn't involve devaluation or direct attack on a specific group.\n",
      "\n",
      "Output: 1\n",
      "Sample 145 Results:  The provided text \"agh waters world dem negresses remarks god dayum\" does not explicitly mention or devalue any protected groups based on gender, race, sexuality, religion, or disability. It seems to be a fragment of speech or writing that might express frustration or surprise, but it doesn't contain hateful or offensive language towards any specific group.\n",
      "\n",
      "Output: 0 (Normal)\n",
      "Sample 146 Results:  The provided text is \"hunger games with little niglet babies\".\n",
      "\n",
      "Reasoning: In this context, the term \"niglet\" is a derogatory and racist slur towards black people. Using it in relation to babies implies that black children are associated with violence or negative connotations, which can be seen as devaluing a protected group (race). Therefore, the text can be classified as 'Hatespeech'.\n",
      "\n",
      "Output: 2\n",
      "Sample 147 Results:  The provided text does not mention or involve devaluation of any protected groups, nor is it used as an attack. It seems to be a statement expressing a political opinion about immigration. Therefore, based on the given classification system, the output would be 0 - Normal.\n",
      "Sample 148 Results:  Output: 2\n",
      "\n",
      "Reasoning: The text explicitly uses racial slurs (\"nigger\") to devalue and attack a specific race (black people), and also includes another racial slur (\"wetbacks\") that is offensive towards Hispanic or Latino people. This text can be classified as hatespeech.\n",
      "Sample 149 Results:  This text appears to be offensive due to the derogatory language used towards a specific racial group, which can be interpreted as an insult. However, it does not specifically involve devaluation or direct attacks on protected groups based on gender, race, sexuality, religion, or disability in a way that would classify it as hate speech.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 150 Results:  The provided text is \"those are quotes directly from anti white semites so shove your fucking anti semitism up your faggot ass\". This text directly targets and devalues a protected group, in this case, Jews (anti-semites) and the LGBTQ+ community (faggot). It also involves a violent and aggressive tone. Therefore, the output is 2. This text can be classified as Hatespeech.\n",
      "Sample 151 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The text does not mention or devalue any protected groups, nor is it used as an attack. It's a request to look at and support refugees from Iraq who are currently in Turkey. The intent of the text seems to be humanitarian rather than offensive or hateful.\n",
      "Sample 152 Results:  0 (Normal)\n",
      "Reasoning: The text does not involve devaluation of any protected group, nor is it used as an insult or attack. It's a question about personal preferences, which can be considered normal conversation.\n",
      "Sample 153 Results:  The provided text uses a derogatory term (\"faggot\") which is often used to devalue or attack members of the LGBTQ+ community. However, in this context, it seems to be directed towards an individual rather than a broader group. Therefore, while offensive, it might not strictly fall under the category of 'Hatespeech'.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 154 Results:  The provided text, \"homosexual and Hollywood communities redundant,\" does not specifically target or devalue a protected group based on gender, race, sexuality, religion, or disability. It seems to be expressing an opinion about the relationship between two entities (the homosexual community and Hollywood). Therefore, according to the given classification system, this text would be classified as '0' - Normal. However, it's important to note that the term \"redundant\" could potentially be interpreted as implying a lack of importance or value, which might not sit well with some individuals or groups. But in this specific context, it doesn't appear to be hate speech or offensive towards any particular group.\n",
      "Sample 155 Results:  This text contains several potentially offensive terms, including \"bitch\" and \"piffy,\" which can be disrespectful or derogatory towards women. However, it does not specifically target a protected group based on gender, race, sexuality, religion, or disability. Therefore, according to the provided classification system, this text would be classified as '1 - Offensive.'\n",
      "\n",
      "However, if we consider the number in the text as part of the analysis (as per your request), it doesn't change the offensive nature of the text but it does make the text more explicit and potentially more harmful. In this case, I would suggest adding a separate category for 'Explicit Offensive' to account for such instances where the text contains explicit or graphic language that intensifies its offensiveness.\n",
      "\n",
      "Output (including number): 1 - Explicit Offensive\n",
      "Sample 156 Results:  The provided text suggests a comparison between racial groups, specifically white and black people, in relation to their offspring. However, it does not directly devalue or attack any specific group. Instead, it seems to be making an observation or statement about genetic traits. Therefore, based on the given criteria, this text can be classified as '0' - Normal.\n",
      "\n",
      "However, it's important to note that this interpretation assumes good faith and that the user is not intentionally trying to provoke or offend. If the context suggests otherwise, the classification might change. For example, if the user frequently posts divisive content or uses similar language in a derogatory manner, it could be considered offensive or even hatespeech.\n",
      "\n",
      "In this case, without additional context, it's difficult to definitively classify the text as anything other than '0' - Normal.\n",
      "Sample 157 Results:  The provided text seems to involve a personal argument between two individuals, where one person is labeled as an SJW (Social Justice Warrior) and the other uses the term \"nazi\" in response. However, the context suggests that the use of \"nazi\" is not aimed at devaluing or attacking any specific protected group based on race, religion, gender, sexuality, or disability. Instead, it appears to be used as a pejorative label in an ongoing argument.\n",
      "\n",
      "Therefore, according to the provided classification system:\n",
      "Output: 1 (Offensive)\n",
      "Sample 158 Results:  The provided text suggests a question about the credibility of Vox Media, implying they made false claims about Jews being globalists. However, it does not directly devalue or attack Jews as a group. Instead, it questions the veracity of a statement made by Vox. Therefore, based on the given classification system, this text would be classified as '0' - Normal.\n",
      "\n",
      "However, it is essential to note that using the term \"Jews\" in this context could potentially be perceived as offensive or sensitive due to historical associations with antisemitism. To avoid misunderstandings and potential harm, it might be more appropriate to rephrase the question to focus on Vox's credibility rather than mentioning Jews explicitly. For example:\n",
      "\n",
      "\"Is Vox Media truthful in their claims that no globalists are Jews?\"\n",
      "\n",
      "This revised version maintains the intent of the original question while avoiding potential offense or misinterpretation.\n",
      "Sample 159 Results:  To classify the provided text, we need to consider if it involves devaluation of a protected group and whether it is used as an attack or insult.\n",
      "\n",
      "Text: \"man <number> of these nibbas really retarded\"\n",
      "Reasoning: The term \"nibbas\" can be considered offensive towards black people, but in this context, it seems to be used casually without any intent to devalue or attack a specific group. However, the use of \"retarded\" can be seen as derogatory towards individuals with intellectual disabilities.\n",
      "\n",
      "Output: 1 (Offensive) - The text contains an offensive term towards black people and another term that could potentially be considered offensive towards individuals with intellectual disabilities.\n",
      "Sample 160 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The text is a prayer, expressing hope for an improvement in someone's health. It does not involve devaluation or direct attacks on any protected groups based on race, gender, sexuality, religion, or disability.\n",
      "Sample 161 Results:  The provided text, \"so five beaners will not be collecting welfare,\" can be interpreted as offensive due to the use of the term \"beaner.\" Historically, this term has been used in a derogatory manner towards Hispanic people, particularly Mexican immigrants. However, it does not specifically target a protected group or involve devaluation in the same way that direct slurs do. Therefore, the output would be 1 (Offensive).\n",
      "Sample 162 Results:  This text contains multiple elements that could be considered offensive or hate speech. Here's a breakdown of some of the problematic elements:\n",
      "\n",
      "1. \"beat as worst president by trump\": This statement could be interpreted as devaluing President Andrew Johnson, who is not a protected group member but a historical figure. However, it's not directly linked to race, gender, sexuality, religion, or disability.\n",
      "\n",
      "2. \"go back places from which they came\": This phrase has historically been used as a racist dog whistle, particularly against African Americans. In this context, it seems to be directed towards black people in general, making it a form of hate speech.\n",
      "\n",
      "3. \"read jesus turned serapis sermon on the black christ lulu thomas\": This part is unclear and could potentially be interpreted as religious or racial insensitivity, but it's not directly devaluing any specific protected group.\n",
      "\n",
      "4. \"jefferson pimped skydog\": This statement seems to imply that Thomas Jefferson was involved in immoral activities, which could be considered offensive. However, it's not specifically targeting a protected group.\n",
      "\n",
      "5. \"and the aunt jamama bomb\n",
      "Sample 163 Results:  The provided text does not mention or involve devaluation of any protected groups, nor is it used as an insult against individuals. It appears to be a personal statement expressing anger towards an individual. Therefore, the output would be 0, indicating that it's considered 'Normal'. However, it's important to note that repeated use of aggressive language can still be harmful and unproductive in communication.\n",
      "Sample 164 Results:  The provided text seems to be stereotyping and devaluing people of Japanese descent by implying they have certain physical features, which could be considered offensive. However, it does not directly attack or target a specific individual or group based on their race, gender, sexuality, religion, or disability.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 165 Results:  The provided text does not specify any protected group, gender, race, sexuality, religion, or disability. Therefore, it cannot be classified as 'Hatespeech'. However, using derogatory terms like \"nigger\" is highly offensive and disrespectful. So, the classification for this text would be '1 - Offensive'.\n",
      "Sample 166 Results:  The provided text \"bungo scrungo gay dogs\" does not specifically mention or devalue any protected groups such as gender, race, sexuality, religion, or disability. It seems to be a playful or derogatory term for someone or something, but it's not clear enough to definitively classify it as hatespeech or offensive. Therefore, based on the given criteria, this text can be classified as '0 - Normal'. However, it's important to note that context and tone can greatly influence the interpretation of such texts, and in some cases, they might be considered offensive due to their potential to harm or disrespect individuals or groups.\n",
      "Sample 167 Results:  The provided text is: \"beat odds never beat women lil wayne\".\n",
      "\n",
      "Reasoning: This text does not directly mention or devalue any protected groups such as gender, race, sexuality, religion, or disability. It's a lyric from a song by Lil Wayne, and while it could be interpreted as promoting violence against women, it is not used in a way that suggests a general disdain or devaluation of women as a group. Therefore, the output would be:\n",
      "\n",
      "Output (number only): 0\n",
      "Sample 168 Results:  The provided text seems to be expressing a criticism or observation about a perceived double standard in the way certain groups, particularly white people versus non-white people, are described in media or public discourse. However, it does not explicitly devalue or attack any specific protected group, nor does it directly use hate speech language.\n",
      "\n",
      "Therefore, based on the provided classification system, this text would be classified as '1' - Offensive. It is important to note that while this text may not meet the criteria for 'Hatespeech', it still contains potentially inflammatory or divisive language and could be interpreted as expressing frustration or anger towards societal biases.\n",
      "Sample 169 Results:  The provided text \"real women really do seem to hate those soyboys\" does not specifically target a protected group based on gender, race, sexuality, religion, or disability. Instead, it seems to be referring to a stereotype or joke about certain groups of men (\"soyboys\"). However, the tone and intent can still be perceived as offensive or disrespectful towards these groups.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 170 Results:  The provided text seems to be implying a question or statement about the relationship between Islam and Jews, specifically mentioning Kolkata. However, it does not directly devalue or attack any protected group based on religion. Therefore, according to the given classification system, this text would be classified as '0' - Normal.\n",
      "\n",
      "However, it's important to note that this text could potentially be interpreted as offensive or insensitive due to its reference to a historical event where many Jews were persecuted and killed in various parts of the world, including Kolkata during the Partition of India and Pakistan in 1947. It might be beneficial to provide more context to fully understand the intent behind this statement.\n",
      "\n",
      "In this case, I would recommend adding a category for 'Potentially Offensive' to account for such situations where the text may not meet the criteria for hatespeech or offensive but could still be perceived as insensitive or inappropriate by some people.\n",
      "Sample 171 Results:  Based on the provided criteria, the text seems to be targeting a specific group (women) and making derogatory statements about them. It implies that women lack certain instincts and are weak, which could be seen as devaluing or attacking a protected group. Therefore, the output would be '2' for Hatespeech.\n",
      "Sample 172 Results:  2\n",
      "\n",
      "Reasoning: The text directly links to devaluation of a protected group (women) and religion (Islam), implying that converting to Islam gives permission to abuse women and children. This is clearly hate speech.\n",
      "Sample 173 Results:  The provided text, \"time to have the music industry join us on the not retarded side,\" can be interpreted as offensive due to the use of the term \"retarded\" in a derogatory manner towards people with intellectual disabilities. However, it does not specifically target or devalue a protected group, so it falls under category 1: Offensive.\n",
      "\n",
      "Reasoning: The text uses the term \"retarded\" as an insult, which can be seen as offensive towards individuals with intellectual disabilities. While it doesn't directly attack or devalue a specific group, it does use a term that is generally considered derogatory and hurtful in this context.\n",
      "Sample 174 Results:  The provided text is: \"that faggot is begging for a helicopter ride\"\n",
      "\n",
      "Reasoning: In this context, the term \"faggot\" is used as an offensive slur against the LGBTQ+ community. However, without additional information, it's not clear if the text is specifically targeting an individual or a group. The phrase \"begging for a helicopter ride\" could be interpreted in various ways, but it doesn't necessarily involve devaluation of any protected groups.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 175 Results:  The provided text contains several elements that can be considered offensive and hateful. It makes generalized, derogatory statements about specific racial and ethnic groups (whites, Jews), and it also promotes a conspiracy theory that is often used to demean and stereotype these groups. Furthermore, the text implies that whites are cowards for not embracing racism, which further reinforces negative stereotypes.\n",
      "\n",
      "Output: 2 (Hatespeech)\n",
      "Sample 176 Results:  The provided text seems to be critical of four Islamic halal markets, suggesting they were involved in illegal activities such as foodstamp fraud and selling stolen goods. It also mentions health code violations including human fecal e coli in kebabs. While the text is critical of these specific businesses, it does not directly devalue or attack a protected group (Muslim immigrants) based on their race, religion, gender, sexuality, or disability.\n",
      "\n",
      "However, the tone and choice of words could be perceived as offensive due to the strong criticism and the mention of health code violations involving human fecal e coli.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 177 Results:  2\n",
      "\n",
      "Reasoning: The text directly targets and devalues a protected group, Jewish people, by using the derogatory term \"kike\" and associating them with negative characteristics such as \"bitchy\", \"ugly\", and \"deplorable\". It also uses offensive terms like \"dyke\" and \"faggot\" to target other protected groups, LGBTQ+ individuals. The text also implies that it is acceptable for men to respond to women in a disrespectful manner, which can be seen as promoting misogyny. Therefore, the text fits the definition of hatespeech.\n",
      "Sample 178 Results:  The provided text appears to contain multiple offensive terms, including \"currynigger\" and \"racetraitor\". These terms are derogatory and racist, targeting individuals based on their race. However, it's important to note that the context of the text is not entirely clear. For instance, it seems to be discussing a platform called \"gab\", but without more information, it's hard to determine if these terms are being used in a broader discussion about the platform or its community, or if they are directed at specific individuals.\n",
      "\n",
      "Given the presence of racist slurs, I would classify this text as '1 - Offensive'. However, if the context were to reveal that these terms are being used in a non-discriminatory manner (for example, if they are part of a discussion about historical or cultural issues), the classification might change. But without additional context, it's hard to make a definitive judgment.\n",
      "Sample 179 Results:  1 (Offensive)\n",
      "\n",
      "Reasoning: The text suggests a mocking and potentially harmful stereotype about Jews, Blacks, and Whites. While it doesn't explicitly devalue any specific group, it can be interpreted as promoting divisive and offensive ideas. However, the text does not directly involve devaluation or an attack on protected groups, so it is classified as 'Offensive'.\n",
      "Sample 180 Results:  1 - Offensive\n",
      "\n",
      "Reasoning: The text expresses a derogatory and disrespectful view towards homosexuality, which is a protected group based on sexuality. However, it does not directly involve devaluation or an attack on the entire LGBTQ+ community. Instead, it seems to be a personal opinion against homosexuality itself, rather than targeting individuals within the community. The use of derogatory language and the suggestion that sexual orientation is influenced by \"Satan\" also contributes to the offensive nature of the text.\n",
      "Sample 181 Results:  The provided text \"what is this red shoes meme i am hearing about did anglin really suggest wearing nigger shoes or am I wrong\" can be classified as '1 - Offensive'.\n",
      "\n",
      "Reasoning: While the term \"nigger\" is highly offensive towards black people, in this context it seems to be used in a question about a controversial meme or statement made by someone named Anglin. However, the use of such a derogatory term is still offensive and disrespectful.\n",
      "Sample 182 Results:  The provided text \"<user> <user> why do muzzys hate so much\" does not directly mention or devalue a specific protected group, but it seems to be stereotyping and potentially disrespectful towards individuals of Muslim faith. However, without further context, it's hard to definitively classify this as hatespeech.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 183 Results:  1 - Offensive\n",
      "\n",
      "Reasoning: The text uses the term \"niggers\" in a derogatory manner, but it is not specifically directed towards any particular race or ethnicity. Instead, it seems to be used as an example in a broader discussion about historical context. However, the use of such a derogatory term is still offensive and disrespectful.\n",
      "Sample 184 Results:  The provided text contains derogatory language and stereotypes, specifically targeting Jewish people (referred to as \"kikes\"). This is a form of hate speech that devalues and attacks a protected group based on religion. Therefore, the output for this text would be '2'.\n",
      "Sample 185 Results:  The provided text clearly targets protected groups based on race and political beliefs, and it involves devaluation and direct attacks. It is used to incite violence and hatred towards these groups, which aligns with the definition of hatespeech. Therefore, the output for this text would be '2'.\n",
      "Sample 186 Results:  The provided text seems to contain offensive language and derogatory comments, particularly towards individuals who may identify as feminists or allies. However, it does not specifically target a protected group based on gender, race, sexuality, religion, or disability. Therefore, according to the given classification system, the output would be 1 (Offensive).\n",
      "\n",
      "However, it's important to note that this text still contains harmful and disrespectful language that can contribute to a toxic environment. It's always crucial to promote respectful and inclusive communication in all interactions.\n",
      "Sample 187 Results:  The provided text contains multiple offensive and derogatory terms, including \"faggot,\" \"bitch,\" and \"nigger.\" These terms are used as insults and can be considered offensive towards the LGBTQ+ community, women, and racial minorities respectively. However, to classify this statement as hatespeech, we need to determine if it specifically targets a protected group with the intent to devalue or attack them.\n",
      "\n",
      "In this case, while the terms are derogatory and offensive, they are used in the context of an individual's actions (not punching someone back) rather than targeting a specific group based on their race, gender, sexuality, religion, or disability. Therefore, it can be classified as 'Offensive' with a score of 1.\n",
      "\n",
      "However, it's important to note that this text still contains harmful and disrespectful language that should not be tolerated in any form of communication.\n",
      "Sample 188 Results:  Output: 2\n",
      "\n",
      "Reasoning: The text directly targets multiple protected groups (race, religion) and devalues them. It also suggests that white women who have abortions are racists, which further reinforces the devaluation of people of color. This text is clearly hate speech.\n",
      "Sample 189 Results:  The provided text is: \"<user> if you are reading this you are a faggot i am just memeing and a bit bored\"\n",
      "\n",
      "Reasoning:\n",
      "The term \"faggot\" is historically used as a derogatory slur against the LGBTQ+ community, specifically towards gay men. However, in this context, it seems to be used as a form of internet trolling or joking (memeing). The user explicitly states that they are just joking and are bored.\n",
      "\n",
      "However, it's important to note that even if used as a joke, such language can still be offensive and hurtful to those in the LGBTQ+ community. It's crucial to remember that words have power and can cause harm, regardless of intent.\n",
      "\n",
      "Output (number only): 1 (Offensive)\n",
      "Sample 190 Results:  2\n",
      "\n",
      "Reasoning: The text uses the term \"black nationalist\" and \"nigger\" in a derogatory manner, which can be seen as devaluing a protected group based on race. It also implies that the person being referred to is uncooperative and acting in a negative way due to their race, which further reinforces the hate speech.\n",
      "Sample 191 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The text discusses a political issue, DACA, and suggests legal action against certain parties. It does not involve any devaluation or direct attack towards protected groups such as race, gender, sexuality, religion, or disability.\n",
      "Sample 192 Results:  The provided text contains multiple offensive elements. It uses derogatory language towards Jewish people (\"shoot a kike in the face\"), which is clearly hatespeech targeting a protected group based on religion. Additionally, the use of \"gabfam\" and the general tone of the text indicate a toxic and hostile environment.\n",
      "\n",
      "Output: 2 (Hatespeech)\n",
      "Sample 193 Results:  1 (Offensive)\n",
      "\n",
      "Reasoning: While the text mentions a specific individual, David Hogg, and discusses his actions on Twitter, it does not specifically involve devaluation or direct attacks towards any protected groups. However, the tone of the text suggests criticism and potential bias against Hogg's political views, which could be perceived as offensive by some readers. The use of the term \"obvious political initiative\" also implies a judgment without providing clear evidence to support it.\n",
      "Sample 194 Results:  The provided text does not directly mention or devalue any protected groups based on gender, race, sexuality, religion, or disability. It expresses concern about the potential impact of certain actions on legal immigrants waiting to enter a country. Therefore, the output would be 0, indicating that it is 'Normal'.\n",
      "\n",
      "However, it's important to note that this text could still be interpreted as offensive if one perceives the implied criticism towards those who might not consider the issue a \"big deal\" as disrespectful or insensitive towards legal immigrants. But in terms of hatespeech, it does not meet the criteria defined in the provided classification system.\n",
      "Sample 195 Results:  0 (Normal)\n",
      "Reasoning: The text does not involve devaluation of protected groups linking to gender, race, sexuality or religion. It is expressing admiration for hot lesbian energy and asking for a fan club, which can be considered as a common expression of interest in pop culture.\n",
      "Sample 196 Results:  The provided text contains multiple derogatory and offensive terms towards various protected groups, including but not limited to Catholics, homosexuals, women (implied by \"skank\"), and people of different ethnicities (implicitly referred to as \"shitskin\"). This text can be classified as 'Hatespeech' (2) because it involves devaluation of multiple protected groups and directs an attack on them.\n",
      "Sample 197 Results:  The provided text \"bitch wanna keep bugging mute button it is ðŸ¤· ðŸ½ â€ â™€ï¸\" does not specifically target a protected group or involve devaluation based on gender, race, sexuality, religion, or disability. It seems to be more of a casual insult towards an individual, possibly a woman, in a conversation context. Therefore, the output would be:\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 198 Results:  The provided text \"terrifying ly retarded\" can be interpreted as devaluing people with intellectual disabilities, specifically those diagnosed with Retardation. However, it does not directly target a specific individual or group, but rather uses the term as an insult. Therefore, the output would be 1 (Offensive).\n",
      "Sample 199 Results:  The provided text \"this little kike is a good little donkey american\" can be classified as 'Hatespeech'. This statement uses the term \"kike\", which is historically and currently used as an anti-Semitic slur against Jewish people. Additionally, the phrase \"good little donkey\" could be interpreted as degrading or devaluing towards Jewish individuals. Therefore, the output for this text would be '2'.\n",
      "Sample 200 Results:  The provided text seems to express a prejudiced view towards certain racial groups, suggesting that once white people are \"all but extinct,\" Asians would be targeted. This implies a hierarchy of civilizations and a devaluation of non-white groups, which aligns with the definition of hatespeech.\n",
      "\n",
      "Output: 2\n",
      "Sample 201 Results:  The provided text does not mention or involve devaluation of protected groups linking to gender, race, sexuality, religion, or disability. It appears to be a personal expression of anger or frustration towards an individual, rather than a broader attack on a group. Therefore, the output would be 0 (Normal).\n",
      "Sample 202 Results:  The provided text \"lmao i am not one of the dykes who you would catch with any bitch who has a baby simple its a deal breaker for me\" can be interpreted as offensive towards lesbian women, specifically those who have children. However, it does not directly devalue or attack them based on their sexuality or gender identity. It is more about personal preference expressed in a derogatory manner.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 203 Results:  The provided text does not specifically mention or devalue any protected groups based on gender, race, sexuality, religion, or disability. It refers to a \"nazi\" which is often associated with a political ideology rather than a racial group. However, the term \"nazi\" can be considered offensive due to its historical connotations and association with genocide. Therefore, the text can be classified as '1 - Offensive'.\n",
      "\n",
      "Reasoning: While the term \"nazi\" is used in a derogatory manner, it does not specifically target any protected group based on race, gender, sexuality, religion, or disability. However, the use of such a term can be considered offensive due to its historical connotations and association with genocide.\n",
      "Sample 204 Results:  This text seems to be critical of the spending on \"illegal aliens\" by Los Angeles County and calls out Democrats for their stance on sanctuary spaces. However, it does not specifically devalue or attack a protected group based on race, gender, sexuality, religion, or disability. Therefore, according to the provided classification system, this text would be classified as 'Normal' (0).\n",
      "\n",
      "However, it's important to note that the term \"illegal aliens\" can be considered offensive by some, as it is often used pejoratively and dehumanizes immigrants who are in the country without legal documentation. Some prefer to use terms like \"undocumented immigrants\" instead.\n",
      "\n",
      "Also, the repeated use of <user> could be interpreted as a form of trolling or spamming, which is generally considered inappropriate in most online discussions. So while it may not meet the strict definition of hatespeech or offensive language, it still falls short of being respectful and constructive discourse.\n",
      "Sample 205 Results:  The provided text seems to be targeting a specific political ideology, \"Maga Trump,\" which is associated with a particular group of people who support Donald Trump and his policies. However, it's not directly attacking or devaluing individuals based on their race, gender, sexuality, religion, or disability.\n",
      "\n",
      "The text does contain derogatory language (\"retardedness\") that can be offensive to some, but it doesn't specifically target a protected group. Therefore, according to the provided classification system, the output would be:\n",
      "\n",
      "Output (number only): 1 - Offensive\n",
      "Sample 206 Results:  The provided text \"plenty of faggots to talk to\" can be interpreted as devaluing and directing an attack towards the LGBTQ+ community, specifically targeting gay men. Therefore, according to the given classification system, the output would be '2' for Hatespeech.\n",
      "Sample 207 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The text does not mention or devalue any protected groups, it is expressing a negative emotion towards an abstract concept (the invention of mosh pits). It does not involve any form of hate speech or offensive language directed at individuals or groups.\n",
      "Sample 208 Results:  The provided text is: \"niggas will rep any gang niggas will bust any head niggas will risk everything point him out and then he dead\"\n",
      "\n",
      "Reasoning: This text repeatedly uses the racial slur \"nigga,\" which is highly offensive towards black people. It also promotes violence, aggression, and discrimination against a specific race (black people). Therefore, it can be classified as 'Hatespeech'.\n",
      "\n",
      "Output: 2\n",
      "Sample 209 Results:  Output: 0\n",
      "\n",
      "Reasoning: The term \"hoe\" is often considered disrespectful or derogatory, but it does not specifically target any protected group based on gender. It's a general insult and not linked to devaluation of a particular group. Therefore, it can be classified as 'Normal'. However, it's important to note that the use of such language can still be disrespectful or offensive in certain contexts.\n",
      "Sample 210 Results:  The provided text appears to be using derogatory language towards the LGBTQ+ community, specifically lesbians. The term \"dyke\" is often used as a pejorative against lesbian women. Therefore, based on the given classification system, this text would fall under 'Hatespeech' (Text that not only mentions but also involves devaluation of protected groups linking to gender and sexuality).\n",
      "\n",
      "Output: 2\n",
      "Sample 211 Results:  1 - Offensive. While the text discusses religious groups, it does not involve direct devaluation or an attack on any specific group. However, the tone of the text implies a negative bias towards certain countries (Bangladesh and Pakistan) due to their religious majority, which can be perceived as offensive. The intent seems to question the treatment of non-Muslims in these countries, but it does not specifically target Muslims or devalue them.\n",
      "Sample 212 Results:  The provided text does not directly mention or devalue any protected groups based on gender, race, sexuality, religion, or disability. However, it does contain a reference to a Filipina and Islam. If the context suggests that these references are used in a neutral or informative manner, then the text can be classified as 'Normal'.\n",
      "\n",
      "However, if the text is found to imply or suggest negative stereotypes or prejudices towards Filipinas or Muslims, it could potentially be considered 'Offensive' due to its potential to cause discomfort or harm. To make a definitive classification, one would need more context about the conversation or article this text is part of.\n",
      "\n",
      "Output: 0 (Normal) or 1 (Offensive), depending on the context.\n",
      "Sample 213 Results:  The provided text, \"queers in olympics are the same in the military a huge fucking mistake,\" can be interpreted as offensive due to the derogatory term \"queers.\" However, it does not specifically target a protected group based on sexuality. Instead, it seems to express a negative opinion about individuals who identify as LGBTQ+ participating in the Olympics and the military.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 214 Results:  The provided text uses derogatory and offensive language towards various groups, including lesbians (\"dykes\"), Jews (\"kikes\"), Hispanics (\"spics\"), African Americans (\"niggas\"), white people (\"whit trash\"), and rural or working-class individuals (\"redneck,\" \"trailer trash,\" \"honky\"). However, it seems to be more of a rant about societal issues rather than directly devaluing these groups.\n",
      "\n",
      "The text does encourage self-reflection and questioning one's own role in situations, which could be seen as an attempt to understand and address problems collectively. However, the use of derogatory language undermines this message and makes it offensive.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 215 Results:  This text appears to be making a generalization about specific racial groups, which could potentially be perceived as offensive or derogatory. However, it does not explicitly devalue or attack these groups in the way that hatespeech would. The text seems to be discussing a sensitive topic (rape) and making a controversial statement about certain demographics being responsible for it.\n",
      "\n",
      "However, it's important to note that this text still carries negative connotations and could potentially cause harm or distress. It reinforces harmful stereotypes and contributes to divisive narratives.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 216 Results:  2\n",
      "\n",
      "Reasoning: The text suggests a violent action against a specific racial group (\"native Swedish neighbourhoods\") and refers to them as \"the other,\" which is devaluing and discriminatory towards foreign refugees. It also implies that the police chiefs are taking this action to teach empathy, which can be interpreted as a derogatory stereotype about the targeted group's lack of empathy. The text directly involves devaluation of a protected group (race) and promotes violence against them, making it hatespeech.\n",
      "Sample 217 Results:  The provided text does not specifically target or devalue any protected group based on gender, race, sexuality, religion, or disability. It seems to be discussing a perceived bias in discourse, and while it mentions Jews, it does not do so in a derogatory or hateful manner. Therefore, the output should be 0 (Normal).\n",
      "Sample 218 Results:  The provided text \"americans are dreamers too i give trump a <number> out of <number> pandered a bit too much to nonwhites but really stuck it to immigrants\" does not specifically target any protected group or involve devaluation. It seems to be expressing an opinion about a political figure's policies towards different groups. However, the phrase \"really stuck it to immigrants\" could potentially be interpreted as negative towards immigrants, but without specific derogatory language, it doesn't meet the criteria for hatespeech or offensive speech.\n",
      "\n",
      "Output: 0 (Normal)\n",
      "Sample 219 Results:  The provided text seems to be criticizing someone's abilities, particularly related to naval duties. However, it does not specifically target a protected group based on gender, race, sexuality, religion, or disability. Therefore, according to the given classification system, this text would be classified as '1 - Offensive'.\n",
      "\n",
      "Reasoning: While the text could potentially be interpreted as devaluing someone's abilities, it does not directly link these criticisms to a protected group. The criticism is more about the individual's performance rather than their identity. However, the language used is harsh and disrespectful, which contributes to the 'Offensive' classification.\n",
      "Sample 220 Results:  The provided text, \"it ok if a moslem does it\", doesn't explicitly devalue or attack any protected group based on religion. However, the phrase could potentially be interpreted as implying that certain actions by Muslims are acceptable, which might reinforce negative stereotypes. But without additional context, it's hard to definitively classify this text as 'Hatespeech'.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 221 Results:  The provided text is: \"hi niggers add me on discord chanel <number> especially you <user>\"\n",
      "\n",
      "Reasoning: The term \"niggers\" is a racial slur and is used to devalue and attack black people. In this context, it is being used as hatespeech towards black people. Therefore, the output should be '2' (Hatespeech). However, since the number is included in the text, I will provide two outputs:\n",
      "\n",
      "1. Without the number: \"hi niggers add me on discord chanel especially you <user>\" - Output: 2 (Hatespeech)\n",
      "2. With the number: \"hi niggers add me on discord chanel <number> especially you <user>\" - Output: 2 (Hatespeech, but including a number does not change the classification)\n",
      "Sample 222 Results:  The provided text seems to be using the term \"ghetto\" as a derogatory comment towards someone. While it doesn't explicitly target a specific protected group, it can be perceived as offensive or disrespectful towards certain cultures or communities associated with urban areas. However, without more context, it's hard to definitively classify this text as 'Hatespeech' or 'Offensive'.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 223 Results:  The provided text does not specifically target any protected group or individuals, and it seems to be a statement about refugees receiving essential items like food, clothes, and water. Therefore, based on the given classification system, this text can be classified as '0' - Normal.\n",
      "\n",
      "However, it is important to note that the term \"refugees\" might carry negative connotations in some contexts, but in this case, it seems to be used in a neutral manner to describe a group of people seeking assistance. If there were additional context or derogatory language used, the classification could change.\n",
      "Sample 224 Results:  The provided text seems to discuss a controversial topic related to race and abortion, but it does not directly devalue or attack any specific protected group. Instead, it appears to be a statement about a political viewpoint or argument (\"sjwlogic\"). However, the term \"black lives are <number> times as likely to abort their unborn baby than white women\" could be interpreted as implying that black women are more irresponsible or careless with their pregnancies, which might be seen as offensive.\n",
      "\n",
      "To classify this text, let's consider the main intent of the statement: it is not primarily about devaluing a protected group but rather about presenting an argument or viewpoint on abortion and race. Therefore, I would classify this text as '1 - Offensive'. The number part of the text does not provide enough context to determine if it should be classified as 'Hatespeech' or 'Normal'.\n",
      "Sample 225 Results:  The provided text, \"getting ass raped by sandniggers,\" clearly involves devaluation of a protected group (race) and includes explicit violence. This text can be classified as 'Hatespeech' (Text that not only mentions but also involves devaluation of protected groups linking to race).\n",
      "\n",
      "Output: 2\n",
      "Sample 226 Results:  Output: 1\n",
      "\n",
      "Reasoning: The text \"thanks for coming to my ted talk p.s. calling me ching chong won't make me laugh\" is using the term \"ching chong\" as an ethnic slur against Asian people, but it is not used in a way that devalues or attacks Asians as a group. Instead, it is used in a context of expressing personal discomfort with being called this name. Therefore, while offensive, it does not qualify as hatespeech.\n",
      "Sample 227 Results:  The provided text expresses a strong opinion, but it does not directly devalue or attack any specific protected group. It discusses potential policies that could impact various groups, such as the homeless, immigrants, LGBTQ+ individuals, and women, but it is presented in the context of a disagreement about autocracy. Therefore, based on the provided classification system, this text would be classified as '0' - Normal.\n",
      "\n",
      "However, it's important to note that while the text itself may not be considered hatespeech or offensive according to the given criteria, the sentiments expressed could still be controversial or harmful if taken out of context or misinterpreted. It's always crucial to promote respectful and inclusive discussions in any setting.\n",
      "Sample 228 Results:  The provided text seems to be discussing a historical stereotype or prejudice, but it doesn't directly devalue or attack any specific protected group. Instead, it refers to the stereotypes that have been used against certain groups in the past. Therefore, based on the given classification system, this text would fall under '0 - Normal'.\n",
      "\n",
      "However, it's important to note that while the text itself might not be considered hate speech or offensive, the topic of discussion (stereotypes and prejudice) can still be sensitive and potentially triggering for some individuals. It's always crucial to approach such topics with care and respect.\n",
      "Sample 229 Results:  The provided text contains multiple problematic elements. Let's break it down:\n",
      "\n",
      "1. \"she is not good looking enough to rape presidency\" - This statement devalues and objectifies women, linking to gender and sexuality. It also implies a violent and inappropriate act, which can be considered as hatespeech. Output: 2\n",
      "\n",
      "2. \"everyone lying but me he started it\" - While not directly related to protected groups, this statement is argumentative and potentially offensive due to the accusation of dishonesty towards others. Output: 1 (Offensive)\n",
      "\n",
      "Overall, the text contains both hatespeech and offensive language, so the final output would be a combination of 2 and 1. However, for simplicity's sake, you could consider it as primarily 'Hatespeech' due to the more severe and inappropriate nature of the statement.\n",
      "Sample 230 Results:  The provided text is about a specific person, Milo, and discusses certain relationships within the \"homosexual world.\" However, it does not directly devalue or attack any protected groups based on gender, race, sexuality, religion, or disability. Therefore, the output should be '0' as this text can't be interpreted as hatespeech.\n",
      "\n",
      "However, it is important to note that the phrase \"coming of age relationships\" between younger boys and older men has been associated with pedophilia in some contexts, which could be considered offensive or inappropriate due to its potential association with child exploitation. But, without additional context, it's hard to definitively classify this text as 'Offensive.'\n",
      "\n",
      "In a broader sense, it is essential to promote respectful and inclusive language when discussing sensitive topics like sexuality and age differences in relationships.\n",
      "Sample 231 Results:  Based on the provided criteria, this text appears to involve devaluation of a protected group (in this case, Muslims) by making generalized negative statements about them. The text also links these statements to gender, race, sexuality, and religion. Therefore, according to the classification system provided:\n",
      "\n",
      "Output: 2 (Hatespeech)\n",
      "Sample 232 Results:  0\n",
      "\n",
      "Reasoning: The text does not mention or devalue any protected groups, nor is it used as an attack. It's a question about the focus of a conversation, and while it might imply frustration, it doesn't meet the criteria for hatespeech or offensive language.\n",
      "Sample 233 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The text does not mention, devalue, or directly attack any protected groups based on gender, race, sexuality, religion, or disability. It is discussing a social network and its characteristics, without any hateful or offensive language towards specific individuals or groups.\n",
      "Sample 234 Results:  The provided text is: \"<user> i was raped <date> april ain't shit lol cancelapril\"\n",
      "\n",
      "Reasoning: This text involves discussing a sensitive topic, rape, which can be considered offensive. However, it does not directly devalue or attack any specific protected group (gender, race, sexuality, religion, or disability). The phrase \"cancelapril\" might refer to the April Sexual Assault Awareness Month campaign, but it doesn't necessarily imply hating or devaluing victims of rape.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 235 Results:  The provided text clearly targets and devalues a protected group based on race, which is African Americans. It uses derogatory language (\"negros\", \"retards\") and makes generalizations about the entire group. This text can be classified as 'Hatespeech' with an output of 2.\n",
      "Sample 236 Results:  The provided text seems to be targeting a specific group, \"illegal aliens,\" which can be linked to race or ethnicity. It implies that these individuals are responsible for deaths in Texas and suggests that the victims and their families have been wronged. This could potentially be interpreted as devaluing or directing an attack on a protected group (immigrants).\n",
      "\n",
      "Output: 2 (Hatespeech)\n",
      "Sample 237 Results:  The provided text \"bears last lmaoo niggas team tho\" does not specifically target or devalue a protected group. It seems to be using the term \"nigga\" casually, possibly in a sports context. However, it's important to note that the term can still be considered offensive due to its historical and cultural connotations.\n",
      "\n",
      "To classify this text, we should consider the main intent of the statement. In this case, the text appears to be expressing amusement or commentary about a sports team, not intending to devalue or attack any protected group. Therefore, based on the provided classification system:\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 238 Results:  The provided text \"davos is merely whitewashed economic gangsterism\" does not specifically target any protected group based on gender, race, sexuality, religion, or disability. It seems to be criticizing an event (Davos) or a group of people (economic gangsters) for being whitewashed, which means they are pretending to be more inclusive or progressive than they actually are. However, without additional context, it's hard to definitively classify this text as 'Normal' or 'Offensive'.\n",
      "\n",
      "Output: 0 (This is a borderline case and could potentially be classified as 'Offensive' if the intent is perceived as attacking a specific group, but without more information, it's best to classify it as 'Normal' for now.)\n",
      "Sample 239 Results:  The provided text contains several elements that might be considered offensive or inflammatory. Here's a breakdown of the reasoning:\n",
      "\n",
      "1. \"retarded\": This term is often used as an insult and can be seen as devaluing people with intellectual disabilities, making it potentially hate speech towards this group.\n",
      "\n",
      "2. \"fake actors\": While not directly targeting a protected group, the use of the term \"fake\" could be interpreted as implying dishonesty or insincerity, which might be offensive to some individuals in the entertainment industry.\n",
      "\n",
      "3. \"migrant caravan invasion\": The use of the term \"invasion\" in this context can be seen as inflammatory and potentially offensive towards migrants, especially given the historical connotations of the word.\n",
      "\n",
      "4. \"gab looks just like twitter right now\": This statement might not be considered hate speech or offensive, but it could be interpreted as a negative comparison between two platforms, which is not necessarily harmful but does not fit the definition of 'normal' either.\n",
      "\n",
      "Given these points, it seems that the text contains elements of both 'Offensive' and 'Hatespeech'. However, to classify it definitively\n",
      "Sample 240 Results:  The provided text seems to be discussing historical events involving Jews, specifically mentioning the Nazi era. However, it does not appear to directly devalue or attack Jews as a group. Instead, it seems to be critically analyzing certain historical actions and propaganda. Therefore, based on the given classification system, this text would fall under '0' - Normal.\n",
      "\n",
      "However, it's important to note that discussing sensitive historical events should always be done with care and respect, especially when involving groups that have been persecuted in the past. This text might still be considered offensive or insensitive by some due to its subject matter, even though it doesn't meet the criteria for hatespeech as defined in this classification system.\n",
      "Sample 241 Results:  The provided text, \"dig a ditch for a bitch if she gone throw dirt talking all that shit like you wonâ€™t get hurt,\" can be interpreted as devaluing women and using violent language. However, it does not specifically target a protected group based on gender, race, sexuality, religion, or disability. Therefore, the output should be 1 (Offensive).\n",
      "\n",
      "Reasoning: The phrase \"bitch\" is often used as a derogatory term for women, and the text suggests violence against this hypothetical woman if she speaks negatively. While it does not explicitly mention any other protected group, the use of violent language and degrading terms towards women makes it offensive.\n",
      "Sample 242 Results:  Output: 1 (Offensive)\n",
      "\n",
      "Reasoning: The term \"retard\" is often used as a derogatory slur towards individuals with intellectual disabilities. While it may not specifically target a protected group, it is still offensive and demeaning language that should be avoided. In this context, it is being used as an insult against the person being addressed by the user.\n",
      "Sample 243 Results:  The provided text discusses a controversial topic related to transgender rights and gender equality. It doesn't directly devalue or attack any specific protected group, but it might be perceived as offensive or insensitive by some due to the sensitive nature of the subject matter. However, the intent behind the question seems more about inquiry rather than hate or devaluation.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 244 Results:  The provided text, \"<user> makes no sense to rent homie it â€™ actually retarded,\" can be interpreted as offensive due to the use of the term \"retarded\" in a derogatory manner. However, it does not specifically target a protected group based on disability. Therefore, the output would be 1 (Offensive).\n",
      "Sample 245 Results:  The provided text \"dykes are tougher than lightskin niggas\" can be interpreted as devaluing or directing an attack on protected groups based on sexuality and race. Therefore, the output would be '2'. This statement is considered as hatespeech because it stereotypes and devalues both lesbian women (dykes) and black people (niggas).\n",
      "Sample 246 Results:  Output: 0\n",
      "\n",
      "Reasoning: The text discusses the actions or statements of BJP supporters and ministers, but it doesn't directly devalue or attack Muslims as a group. Instead, it presents an argument about the relationship between those individuals and their potential anti-Muslim sentiments. Therefore, it can be classified as 'Normal'.\n",
      "Sample 247 Results:  The provided text contains derogatory language and stereotypes, which can be considered offensive. However, it does not specifically target a protected group based on race or ethnicity. Instead, it seems to be criticizing individuals (the \"Pakis\" and those in positions of power) for alleged actions related to child rape and cover-ups.\n",
      "\n",
      "While the language used is offensive, it might not fall under the category of hatespeech as defined earlier because it does not devalue or attack a specific racial or ethnic group as a whole.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 248 Results:  The provided text, \"giving the Asians a bad name,\" does not directly mention or devalue a specific individual or group. However, it implies that someone is acting in a way that negatively represents all Asians. This could potentially be seen as offensive or harmful to the Asian community.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 249 Results:  Output: 0\n",
      "\n",
      "Reasoning: The statement does not mention or devalue any protected groups based on gender, race, sexuality, religion, or disability. It is expressing an opinion about a person, Donald Trump, who is a public figure. While some people might find the language offensive, it doesn't specifically target or devalue a group of people.\n",
      "Sample 250 Results:  The provided text is: \"im only playing tabletops with niggers from now on\"\n",
      "\n",
      "Reasoning: This text specifically targets a racial group, black people, and it's used in a derogatory manner. It involves devaluation of the protected group, linking to race. Therefore, the output is 2 (Hatespeech).\n",
      "Sample 251 Results:  The provided text contains multiple instances of derogatory and offensive language towards various protected groups, including people with disabilities, Jews (anti-Semitic slur \"kikes\"), and racial slurs against both whites (\"white genocide\") and people of Middle Eastern descent (\"shitskins\"). It also involves devaluation of these groups. Therefore, the output should be '2' as it qualifies as Hatespeech.\n",
      "Sample 252 Results:  1 (Offensive)\n",
      "\n",
      "Reasoning: While the text mentions different racial and ethnic groups, it does not devalue them directly. However, it can be interpreted as objectifying people based on their physical characteristics (tall, nerdy, white, lanky, geeky, Caucasian, towering European) which can be seen as offensive or disrespectful towards individuals. It is important to note that this text does not specifically target a protected group and it's main intent seems to be describing the individual's dating preferences rather than devaluing them.\n",
      "Sample 253 Results:  The provided text is: \"your posts show otherwise nigger lover\".\n",
      "\n",
      "Reasoning: This text uses the racial slur \"nigger\" which is highly offensive towards black people. Additionally, it implies that the person being addressed is supportive of black people, which could be interpreted as an attack on them for their perceived support of a protected group. Therefore, this text can be classified as 'Hatespeech'.\n",
      "\n",
      "Output: 2\n",
      "Sample 254 Results:  The provided text \"dykes has joined og for the first time <user>\" does not mention any protected groups, nor is it used in a derogatory or devaluing manner. It simply states that someone identifying as a lesbian (often referred to as dyke) has joined a group. Therefore, the output would be 0, indicating that this text is 'Normal'.\n",
      "Sample 255 Results:  The provided text contains racial slurs (\"niggers\") which can be considered offensive towards black people. However, in this context, it seems to be used in a derogatory manner towards the game developers (2k) rather than directly targeting black people as a group. Therefore, the output should be 1 - Offensive.\n",
      "\n",
      "However, it's important to note that using racial slurs is generally considered inappropriate and disrespectful, regardless of the intended target. It's always best to avoid such language in communication.\n",
      "Sample 256 Results:  The provided text \"my ex has a weird infatuation w dykes\" can be interpreted as offensive towards lesbian women. While it doesn't directly devalue or attack them, the term \"dyke\" is often considered derogatory and disrespectful towards lesbians. Therefore, the output would be 1 (Offensive).\n",
      "Sample 257 Results:  Output: 0\n",
      "\n",
      "Reasoning: The text does not mention or involve devaluation of any protected groups, nor does it link to gender, race, sexuality, religion, or disability. Instead, it expresses a positive sentiment about women in WWE receiving respect.\n",
      "Sample 258 Results:  The provided text is \"omg the jews added me to their hate list what shall i ever do i will count it as an honor\".\n",
      "\n",
      "Reasoning: This text implies that being added to a 'hate list' by Jews is considered an honor, which could be interpreted as devaluing or targeting a specific religious group. Therefore, the output would be '2'. However, it's important to note that the intent of the text might not necessarily be to promote hate speech but rather to express a sense of irony or sarcasm, which can sometimes be difficult to discern from written text alone. In such cases, additional context could help clarify the true intention behind the text.\n",
      "Sample 259 Results:  The provided text does not specifically target any protected group or involve devaluation of them, it is just an insult towards the user's pet. So, the output would be 0 (Normal). However, it's important to note that even though this text is considered normal in this context, using derogatory language towards animals can still be disrespectful and insensitive.\n",
      "Sample 260 Results:  The provided text does not specifically target or devalue any protected group. It seems to express confusion about a name and suggests a possible misunderstanding. Therefore, the output would be '0' - Normal.\n",
      "Sample 261 Results:  The provided text directly targets a specific race (white) and implies a derogatory stereotype about them being associated with violence, which is a form of hate speech. It also uses a racial slur (\"porch monkey\") towards another race (black). Therefore, the output should be '2'.\n",
      "Sample 262 Results:  The provided text is: \"asshole ghetto trash bastard I will have a party when someone puts his in the ground\"\n",
      "\n",
      "Reasoning: This text contains multiple derogatory terms (\"asshole\", \"ghetto trash\", \"bastard\") that are generally considered offensive. However, it does not specifically target any protected group based on race, gender, sexuality, religion, or disability. Instead, it seems to be a general insult towards an individual. The phrase \"I will have a party when someone puts his in the ground\" can be interpreted as wishing harm upon the person being addressed, which is inappropriate and disrespectful but does not necessarily qualify as hatespeech.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 263 Results:  The provided text seems to express a critical viewpoint towards Mexican immigrants, suggesting they are entitled and demanding too much from others. However, it does not directly devalue or attack them as a group based on their race or nationality. Instead, it criticizes their perceived behavior. Therefore, the output should be 1 (Offensive).\n",
      "\n",
      "However, it's important to note that this text could still be considered problematic due to its potential to reinforce negative stereotypes about Mexican immigrants. It would be beneficial to encourage open and respectful dialogue about immigration issues, focusing on understanding and empathy rather than criticism or generalizations.\n",
      "Sample 264 Results:  The provided text does not specifically target any protected groups based on gender, race, sexuality, religion, or disability. Instead, it seems to be discussing political ideologies and the use of violence for political ends. Therefore, according to the given classification system, this text would be classified as '0' - Normal.\n",
      "\n",
      "However, it's important to note that the term \"terrorist\" is often used in a derogatory and biased manner towards certain groups, particularly in the context of geopolitics. While the text itself does not directly use hate speech, the underlying connotation could potentially be offensive or inflammatory depending on the reader's perspective.\n",
      "\n",
      "In this case, I would recommend adding an additional category to account for texts that may contain implicit biases or offensive undertones, even if they do not meet the strict criteria for hatespeech or offensive speech. This could help provide a more nuanced understanding of the text's impact and intent.\n",
      "\n",
      "For example:\n",
      "\n",
      "Text: \"millions of soldiers are terrorists by your definition every state in existence is a terrorist state by your definition calling someone our for using violence to achieve a political end is just being dishonest and beta\"\n",
      "Sample 265 Results:  The provided text seems to contain explicit and disturbing content that devalues and targets a protected group, specifically daughters. It also involves sexual assault implications which is a serious offense. Therefore, the output should be '2' as it qualifies as Hatespeech.\n",
      "Sample 266 Results:  2\n",
      "\n",
      "Reasoning: The text explicitly targets and devalues protected groups based on race (white) and political affiliation (republican), suggesting that they are subject to unfair treatment, which can be interpreted as hatespeech.\n",
      "Sample 267 Results:  The provided text \"twitter would have flooded with islamophobic topic if it was other way around but anyways ohm namah shivaya\" does not directly involve devaluation or an attack on a protected group, specifically religion. However, the mention of \"Islamophobic topic\" suggests a negative sentiment towards Islam, which could be considered offensive.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 268 Results:  The provided text is: \"from time you see a ghetto yute in formal wear just know they bouta go to court or funeral\"\n",
      "\n",
      "Reasoning: This text seems to stereotype individuals from a specific socio-economic background (ghetto) and associates them with legal issues (court or funeral). While it doesn't directly devalue or attack any protected group, it could be perceived as reinforcing negative stereotypes. However, the intent might not necessarily be to devalue or attack a specific group, but rather to make a general observation or joke.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 269 Results:  The provided text is \"musacchio suspended for being a retard blame giampaolo\".\n",
      "\n",
      "Reasoning: In this context, the term \"retard\" is often considered offensive and derogatory towards people with intellectual disabilities. However, without additional information about the specific context or the individuals involved, it's not clear if the text is intended to devalue or attack a protected group (people with intellectual disabilities). The text also mentions \"musacchio\" and \"giampaolo\", which could suggest a discussion about specific people in a sports or professional setting.\n",
      "\n",
      "Since the text can be interpreted as potentially offensive but it's not clear if it specifically targets a protected group, I would classify it as '1 - Offensive'. However, it's important to note that the interpretation of such texts can vary greatly depending on cultural and personal contexts, and this classification should be used with caution.\n",
      "Sample 270 Results:  The provided text, \"is it too late to hire sonny dykes to be the next tech head coach\", does not involve devaluation of any protected groups based on gender, race, sexuality, religion, or disability. It seems to be discussing a potential job opportunity for a person named Sonny Dykes in a sports context. Therefore, the output would be 0, indicating that it is 'Normal'.\n",
      "Sample 271 Results:  The provided text, \"i need a kid thats gon wash them dishes ðŸ˜­ bitch is retarded,\" can be interpreted as offensive due to the use of derogatory language towards women (\"bitch\") and the ableist slur (\"retarded\"). However, it does not specifically target a protected group based on race, gender, sexuality, religion, or disability in a way that devalues them.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 272 Results:  The provided text contains derogatory and offensive language towards Kate Brown, who is a woman, and uses anti-Semitic slurs (\"kike\"). It also includes a violent threat against her. Therefore, this text can be classified as 'Hatespeech' (2).\n",
      "Sample 273 Results:  The provided text, \"frank dicpario and the misogenous potatoes a blackened math metal band\", does not contain any derogatory or offensive language towards protected groups such as gender, race, sexuality, religion, or disability. It is simply describing a band with a unique name. Therefore, the output should be 0, indicating that it's Normal.\n",
      "\n",
      "However, it's important to note that \"misogenous\" implies a dislike of, contempt for, or ingrained prejudice against women. While it might not be directly targeting women in this context, it does contain a negative connotation towards females. This could potentially be considered offensive if used in an inappropriate or derogatory manner. But in the given context, it seems to be referring to the band's name and style of music, so it's not intended as hate speech or offensive in this case.\n",
      "Sample 274 Results:  The provided text uses derogatory language towards both race (\"negress\") and weight (\"obese\"). However, the context does not seem to involve a direct attack or devaluation of a specific protected group. Instead, it appears to be a commentary on societal reactions to different expressions of identity.\n",
      "\n",
      "However, it's important to note that using derogatory language is still offensive and disrespectful. In this case, I would classify the text as '1 - Offensive'. The text could potentially be interpreted as hatespeech due to the use of derogatory terms, but it does not specifically target a protected group with the intent to devalue or attack them.\n",
      "Sample 275 Results:  The provided text, \"<user> get off my twitter feed you towel head go milk a goat or something\" can be interpreted as offensive due to the use of \"towel head\" which is derogatory towards people of Middle Eastern descent. However, it does not specifically target a protected group and its main intent seems to express annoyance rather than devaluation.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 276 Results:  The provided text is in French and translates to \"the vocals of Junee in Just Go ðŸ˜”\". This text does not contain any derogatory or offensive language towards protected groups such as gender, race, sexuality, religion, or disability. It seems to be a comment about a specific song or artist. Therefore, the output should be '0' for Normal.\n",
      "Sample 277 Results:  Output: 2\n",
      "\n",
      "Reasoning: The text explicitly mentions a racial group (\"blacks\") and proposes a reciprocal devaluation by using derogatory terms (\"vinallas\" for whites, \"chocolates\" or \"niggers\"). This can be considered as hate speech.\n",
      "Sample 278 Results:  The provided text \"<user> woah eyes are like ghetto blaster speakers my two cents ðŸ˜Š ðŸ ðŸ‘ ðŸ» ðŸ’œ\" does not specifically target any protected group, nor is it used as an insult. It seems to be a casual comment about the user's eyes being compared to something else. Therefore, based on the provided classification system, this text would be classified as '0 - Normal'. However, it's important to note that context can sometimes influence the interpretation of such statements, and in some cases, seemingly innocuous comments may still be perceived as offensive or insensitive by certain individuals or groups.\n",
      "Sample 279 Results:  The provided text is highly offensive and can be interpreted as hatespeech. It devalues a specific group of people, in this case, individuals from the third world, by using derogatory terms such as \"retards,\" implying they have low intelligence, and \"perpetual victims,\" suggesting they are prone to violence. The use of these terms is disrespectful and discriminatory towards the targeted group.\n",
      "\n",
      "Output: 2\n",
      "Sample 280 Results:  The provided text suggests that the speaker is confident about writing a paper debunking the concept of \"reverse racism\" in a class full of white people. However, it does not explicitly devalue or attack any protected group. Instead, it seems to be more about the speaker's confidence in their academic ability.\n",
      "\n",
      "Output: 0 (Normal)\n",
      "Sample 281 Results:  Output: 0\n",
      "\n",
      "Reasoning: The text does not mention or devalue any protected groups, nor is it used to attack anyone. It's a simple statement about a movie and an actor's performance.\n",
      "Sample 282 Results:  The provided text is \"bts as Muslims thread a thread\". In this context, BTS is a popular South Korean boy band and the term \"Muslims\" refers to followers of Islam. There's no indication in the text that either group is being devalued or attacked. Instead, it seems like a statement about the members of BTS and their religious beliefs, if any.\n",
      "\n",
      "Therefore, based on the provided classification system, this text would be classified as '0 - Normal'. It doesn't contain hate speech or offensive language towards any protected group.\n",
      "Sample 283 Results:  Output: 0\n",
      "\n",
      "Reasoning: The text does not mention any protected groups, nor is it used to devalue or attack them. It's a general statement about personal freedom and the potential reactions from others.\n",
      "Sample 284 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The text is referring to a specific album (\"Unknown Pleasures\" by Joy Division) and the person's personal experience of listening to it and crying. It does not involve devaluation or direct attacks on any protected groups based on gender, race, sexuality, religion, or disability.\n",
      "Sample 285 Results:  The provided text contains multiple derogatory and offensive terms directed towards different protected groups, including women (using the term \"bitch\"), racial slurs (\"nigger\"), and homophobic slurs (\"faggot\"). It also includes degrading language about physical appearance. Therefore, based on the given criteria, this text can be classified as 'Hatespeech' with an output of '2'.\n",
      "Sample 286 Results:  The provided text contains multiple offensive and derogatory terms, including \"nigger,\" \"snow,\" \"alt-right,\" and \"cucks.\" These terms are used as insults and can be considered racist or discriminatory. However, it's important to note that the text does not specifically target a protected group based on race, gender, sexuality, religion, or disability. Instead, it seems to be a generalized and toxic commentary on various groups.\n",
      "\n",
      "In this context, I would classify the text as \"1 - Offensive.\" While it contains hate speech-like language, its main intent does not appear to involve devaluing or directly attacking any specific protected group. However, it is important to acknowledge that such language can still be harmful and divisive.\n",
      "Sample 287 Results:  The provided text seems to be expressing frustration about being suspended from an account due to using an \"unsavory name\" towards Don Jr., who is a white male. However, it does not explicitly devalue or attack any protected group based on gender, race, sexuality, religion, or disability.\n",
      "\n",
      "The text does mention \"white male billionaire fail sons,\" but this seems more like a sarcastic comment about the perceived privileged status of Don Jr., rather than an attempt to devalue or attack all white male billionaires or their sons.\n",
      "\n",
      "Therefore, based on the provided classification system, I would classify this text as '0' - Normal. It expresses frustration but does not seem to be hate speech or offensive in a way that directly targets protected groups.\n",
      "Sample 288 Results:  The provided text is: \"i wonder when it ll finally come out that tony has niglet grandkids or gay sons\"\n",
      "\n",
      "Reasoning:\n",
      "The term \"niglet\" is a derogatory and racist slur towards black people. Using this term implies devaluation of a racial group, making it a form of hatespeech. The phrase \"gay sons\" does not necessarily imply any form of devaluation or attack, but the context suggests that it might be used in a negative or derogatory manner due to societal biases and prejudices towards homosexuality. However, without additional context, it's difficult to definitively classify this text as hatespeech against the LGBTQ+ community.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 289 Results:  0 (Normal)\n",
      "Reasoning: The statement does not involve devaluation of any protected group, nor is it used as an attack or insult. It's simply a personal declaration about the user's sexual orientation.\n",
      "Sample 290 Results:  This text contains explicit and violent language that can be considered highly offensive, disturbing, and inappropriate. It involves devaluing and expressing a desire for harm towards another individual, which is not protected under any group category but still crosses the line of acceptable discourse. The reference to political figures or policies (Tory austerity) does not change the nature of the text as it is primarily focused on the violent and offensive content.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 291 Results:  The provided text \"it the big gay wedding\" does not specifically devalue or attack a protected group based on sexuality. It is referring to a wedding, which is a common event, and using the term \"gay\" in this context is often used to describe something as extravagant or festive, rather than as an insult. Therefore, the output would be 0 (Normal).\n",
      "Sample 292 Results:  The provided text is: \"i seriously doubt any white man would willingly lie with a sheboon let alone rape one, hell black men do not even want them mawa\"\n",
      "\n",
      "Reasoning: This text involves devaluation of a protected group (black women) by using the derogatory term \"sheboon\". It also implies that white men are superior and black men do not desire black women. Therefore, it can be classified as 'Hatespeech' with an output of 2.\n",
      "Sample 293 Results:  The provided text does not mention or involve devaluation of protected groups linking to gender, race, sexuality, religion, or disability. It is a statement about the author's political views and personal characteristics. Therefore, the output for this text would be 0, indicating that it is 'Normal'.\n",
      "Sample 294 Results:  The provided text \"ha good i am tired of that beaner clown\" can be interpreted as offensive due to the use of the term \"beaner,\" which is a derogatory slur often used against Hispanic people, particularly Mexicans. However, it does not specifically target a protected group based on race or ethnicity and is used as an insult against an individual or group.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 295 Results:  The provided text is: \"get this nigga zion some lugz those soles strong as shit\"\n",
      "\n",
      "Reasoning: In this context, the term \"nigga\" is used casually and not in a derogatory or hateful manner. It's being used as a nickname for someone named Zion. The rest of the text seems to be about buying shoes for that person. Therefore, it doesn't involve devaluation or direct an attack on any protected group.\n",
      "\n",
      "Output: 0 (Normal)\n",
      "Sample 296 Results:  0 (Normal)\n",
      "Reasoning: The term \"clowns\" is a common slang for people acting foolishly or irrationally, and it does not specifically target any protected group. It can be used to describe anyone regardless of race, gender, sexuality, religion, or disability. Therefore, it cannot be interpreted as hatespeech or offensive in this context.\n",
      "Sample 297 Results:  The provided text \"i guess col <user> was wrong about just pounding the table if the law facts are against your case the smart thing to do is pack the jury with wetback child rapists\" can be classified as 'Hatespeech'. This statement not only mentions but also involves devaluation of a protected group (Hispanic people, often referred to as \"wetbacks\") and links it to a serious crime (child rape). The intent here is to demean and attack the Hispanic community.\n",
      "Sample 298 Results:  The provided text, \"and fish smell sweaty in the raghead and body bags\", can be interpreted as devaluing a specific religious group (Muslims). The term \"raghead\" is derogatory towards Muslims. Additionally, the phrase \"body bags\" could be seen as suggesting violence or death towards this group. Therefore, based on the given criteria, the output would be: 2 (Hatespeech)\n",
      "Sample 299 Results:  The provided text is: \"greatest hope for mankind is to reach out to muslims who have not yet been enlisted to violence\"\n",
      "\n",
      "Reasoning: This text does not involve devaluation of a protected group, it suggests reaching out to Muslims who have not yet been involved in violence. It can be seen as promoting peace and understanding rather than hatespeech or offensive language.\n",
      "\n",
      "Output (number only): 0\n",
      "Sample 300 Results:  The provided text is: \"the mudslime needs to be deported back in a coffin\"\n",
      "\n",
      "Reasoning: This text directly targets a specific religious group (Muslims) and devalues them, using derogatory language (\"mudslime\"). It also implies violence and death. Therefore, the output is: 2 (Hatespeech)\n",
      "Sample 301 Results:  The provided text is \"abusive in your bio, you're getting blocked since you love being ghetto ðŸ¤¢ ðŸ¤¢ ðŸ¤¢ ðŸ¤¢ ðŸ¤¢\".\n",
      "\n",
      "Reasoning:\n",
      "The term \"ghetto\" can be perceived as offensive or derogatory towards certain communities, particularly African American and other urban communities. However, in this context, it seems to be used as a pejorative against the user's behavior (abusive bio) rather than directly targeting a specific racial or ethnic group.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 302 Results:  The provided text does not directly devalue or attack any specific protected group. It seems to be discussing the identity of individuals and expressing gratitude. However, it might be perceived as offensive due to the use of the term \"Muslim immigrant man\" which could potentially stereotype or generalize a certain group. But it doesn't involve devaluation or direct attack on that group.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 303 Results:  The provided text seems to be making a statement about a change in demographics of a certain area, but it doesn't directly devalue or attack any specific protected group. However, the use of the term \"once white ghetto\" could potentially be interpreted as offensive due to its association with racial stereotypes.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 304 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The text does not mention any protected groups, nor does it involve devaluation or direct an attack towards them. It is a humorous and nonsensical statement about animals, with no malicious intent.\n",
      "Sample 305 Results:  The provided text \"so my iphone still thinks fuck is duck but it auto corrects hufflepuff with no issue <number> is gay af\" does not mention or involve devaluation of any protected groups such as gender, race, sexuality, religion, or disability. It's a humorous comment about the iPhone's autocorrect feature and does not intend to offend or attack anyone. Therefore, the output should be 0 (Normal).\n",
      "Sample 306 Results:  The provided text is: \"how the fuck did that nigger secured this my head is so hot\"\n",
      "\n",
      "Reasoning:\n",
      "The term \"nigger\" is highly offensive and devaluing towards black people. In this context, it is used as a racial slur to demean an individual or group of people based on their race. Therefore, the text can be classified as 'Hatespeech'.\n",
      "\n",
      "Output (number only): 2\n",
      "Sample 307 Results:  The provided text does not mention or involve devaluation of any protected groups, nor is it used as an attack. It's a statement about a celebrity and an emotional reaction, which can be considered normal fan behavior. Therefore, the output would be 0.\n",
      "Sample 308 Results:  The provided text seems to contain stereotypes and potentially offensive language towards Asian people. However, it doesn't explicitly devalue or attack them based on their race, gender, sexuality, religion, or disability. Instead, it makes a generalized statement about Asians living in huts and their financial worth compared to Western users.\n",
      "\n",
      "While the text might be considered culturally insensitive or offensive due to its stereotypical portrayal of Asian people, it doesn't meet the criteria for hate speech as defined in this context (directly devaluing a protected group).\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 309 Results:  The provided text \"you're jealous like all leftist queers\" can be interpreted as offensive, but it does not specifically involve devaluation of protected groups such as sexuality or political affiliation. However, the use of the term \"queers\" might be considered derogatory and disrespectful towards LGBTQ+ individuals.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 310 Results:  The provided text seems to be implying a negative stereotype towards non-white individuals, which could potentially be interpreted as devaluation of a protected group. However, it does not directly attack or insult an individual, but rather suggests a generalization about countries and ghettos. Therefore, the output would be: 1 (Offensive)\n",
      "Sample 311 Results:  The provided text seems to express criticism towards certain individuals and a political situation, but it also contains derogatory language towards Muslims (\"anti-Muslims\" and \"greedy western Muslim countries\"). However, the text does not explicitly devalue or attack Muslims as a protected group. Instead, it appears to be criticizing specific actions of some individuals who are Muslim or from Muslim-majority countries.\n",
      "\n",
      "Therefore, based on the provided definition, this text can be classified as '1 - Offensive'. It contains language that may be considered derogatory towards Muslims, but its main intent does not seem to involve devaluing or attacking Muslims as a group.\n",
      "Sample 312 Results:  The provided text \"<user> bring your chess boards out, China. No more ghetto checkers\" does not specifically target any protected group based on gender, race, sexuality, religion, or disability. It seems to be a comment about the quality of games being played, comparing chess (a traditional Western game) to \"checkers\" (often associated with African-American culture in the U.S.). However, it does not devalue or attack any specific group.\n",
      "\n",
      "Output: 0 (Normal)\n",
      "Sample 313 Results:  The provided text \"sorry i havenâ€™t tweeted in a while iâ€™m too busy having gay sex\" does not specifically target or devalue any protected group based on gender, race, sexuality, religion, or disability. It is a light-hearted joke about being busy and does not contain any derogatory language or intent to harm. Therefore, the output would be 0 (Normal).\n",
      "Sample 314 Results:  The provided text seems to contain derogatory language and stereotypes, particularly towards homosexual individuals and heterosexual rugby players. It also appears to use the term \"cultural Marxist\" in a pejorative manner, which can be seen as offensive or divisive. However, it does not explicitly devalue or attack a specific protected group based on race, gender, sexuality, religion, or disability.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 315 Results:  The provided text, \"yeah just a bunch of triggered retarded nazis anyway i am off to sleep good nights,\" can be interpreted as offensive due to the use of derogatory terms (\"retarded\" and \"nazis\"). However, it does not specifically target protected groups such as race, gender, sexuality, religion, or disability in a devaluing manner. Therefore, the output would be 1 (Offensive).\n",
      "Sample 316 Results:  The provided text, \"guilty until proven innocent unless you are a jew a nigger or a lover of both,\" clearly involves devaluation and direct attacks on protected groups based on religion (Jew) and race (nigger). This text is not used as an insult against an individual but rather as a general statement that targets these specific groups.\n",
      "\n",
      "Output: 2 (Hatespeech)\n",
      "Sample 317 Results:  This text contains a racial slur (\"shitskin\"), which is highly offensive and can be considered as devaluation of a protected group (race). However, the context suggests that it's being used in response to an insult or provocation. To classify this text, we should consider the intent behind using the slur. If the intent was to devalue or attack the racial group, then it would be classified as 'Hatespeech'. But if the intent was to retaliate against a personal insult, it might be considered more as 'Offensive' rather than 'Hatespeech'.\n",
      "\n",
      "However, without knowing the specific context in which this text was used, it is difficult to make a definitive classification. In general, using racial slurs should be avoided due to their potential for causing harm and offense.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 318 Results:  The provided text does not specify any protected group, gender, race, sexuality, religion, or disability. It simply mentions a person's name, Don Lemon, followed by a racial slur. However, the intent of the text seems to be an insult rather than devaluing or attacking a specific group. Therefore, according to the provided classification system, this text would fall under '1 - Offensive'.\n",
      "Sample 319 Results:  The provided text does not directly mention or devalue any specific protected group based on gender, race, sexuality, religion, or disability. However, it does seem to express a negative sentiment towards Arabs, suggesting they have been scheming to destroy Israel for decades. This could potentially be seen as offensive or biased, but it doesn't meet the criteria for hatespeech as defined in the provided guidelines because it doesn't devalue or attack a specific group of people based on their protected characteristics.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 320 Results:  This text contains multiple instances of offensive language and devaluation of protected groups, specifically targeting white women, black people, and potentially disabled individuals. The use of derogatory slurs such as \"white whores,\" \"nigger,\" and potentially \"autistic\" can be seen as hatespeech. Additionally, the text includes statements that devalue and stereotype these groups, such as calling white women \"trashy\" and black businessmen \"ghetto.\" Therefore, the output number for this text would be '2' indicating Hatespeech.\n",
      "Sample 321 Results:  The provided text \"<user> not shocking that the ones yelling hate and intolerance are all white lol\" can be interpreted as implying that a specific racial group (white people) is associated with hate and intolerance. While it doesn't directly devalue or attack individuals, it does generalize a negative trait to an entire race, which could potentially be perceived as offensive or stereotyping.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 322 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The text does not contain any derogatory or offensive language towards protected groups such as gender, race, sexuality, religion, or disability. It is a statement condemning violence and expressing sympathy for victims, which is generally considered acceptable and non-offensive.\n",
      "Sample 323 Results:  The provided text, \"clueless boomer Jews don't want refugees because Muslims hate them,\" seems to be making generalizations about specific groups of people. However, it does not explicitly devalue or attack these groups in a way that would be considered hatespeech. Instead, it appears to be discussing and stereotyping the attitudes of certain groups towards each other.\n",
      "\n",
      "However, it's important to note that this text could still be considered offensive due to its generalizations and potential perpetuation of harmful stereotypes. Therefore, I would classify this text as '1 - Offensive.'\n",
      "\n",
      "Reasoning: While the text mentions specific groups (Boomer Jews and Muslims), it does not directly devalue or attack these groups in a way that would be considered hatespeech. However, the generalizations made about their attitudes towards each other could be perceived as offensive due to potential stereotyping.\n",
      "Sample 324 Results:  The provided text is: \"i swear if i ever die someday and some sorry son of a bitch votes democrat on my behalf i will comeback and slash that motherfucker\"\n",
      "\n",
      "Reasoning: This text contains threats, which can be considered offensive or aggressive. However, it does not specifically target any protected group based on gender, race, sexuality, religion, or disability. Therefore, the output is 1 (Offensive).\n",
      "Sample 325 Results:  The provided text is: \"slap the bitch in the fave with them hoes\"\n",
      "\n",
      "Reasoning: This text uses derogatory language towards women, specifically referring to a woman as a \"bitch\" and using sexual objectification (\"fave\" and \"hoes\"). It can be interpreted as devaluing or directing an attack on a protected group (women). Therefore, the output is 2. This text would be considered Hatespeech.\n",
      "Sample 326 Results:  2\n",
      "\n",
      "Reasoning: The text specifically targets white women, devaluing them by referring to them as \"corrupted\" and suggesting they need to be \"un whored\" and \"rebuild patriarchy.\" This implies a belief in the superiority of one gender over another, which is a form of hate speech.\n",
      "Sample 327 Results:  Based on the provided context, this text seems to express frustration about receiving sexualized harassment. However, it does not specifically target or devalue any protected group based on gender, race, sexuality, religion, or disability. Therefore, the output should be '1' - Offensive. The text is toxic due to the expression of sexualized harassment, but it doesn't meet the criteria for hatespeech as defined in the given context.\n",
      "Sample 328 Results:  The provided text is \"merkel next governmental position should be refugee camp whore\". This statement can be interpreted as devaluing and directing an attack towards Angela Merkel, the former Chancellor of Germany, due to her strong stance on accepting refugees. It also involves a derogatory term \"whore\". Therefore, according to the given classification system, this text would fall under 'Hatespeech' (Text that not only mention but also involves devaluation of protected groups linking to gender and political affiliation).\n",
      "\n",
      "Output: 2\n",
      "Sample 329 Results:  The provided text seems to be targeting a specific group, which is lesbian women (dykes), and it devalues them by calling them \"frigid\" and implying that they are con artists. It also devalues childless women and those who don't prioritize traditional gender roles (taking care of the home). The text also makes a generalization about all lesbians, which could be seen as a form of hate speech.\n",
      "\n",
      "Output: 2\n",
      "Sample 330 Results:  The provided text seems to express frustration with diversity hires, specifically mentioning Chinese women. However, it does not directly devalue or attack any protected group based on race, gender, sexuality, religion, or disability. Instead, the text appears to be critical of the hiring process and the perceived lack of qualifications among some diversity hires.\n",
      "\n",
      "However, the phrase \"comical English served no purpose other than to take a job from an American\" could be interpreted as offensive due to its potential stereotyping of non-native English speakers. Therefore, I would classify this text as '1 - Offensive'.\n",
      "\n",
      "It's important to note that context is crucial in determining whether a statement is hate speech or offensive. This classification is based on the provided text alone and may change if additional context were available.\n",
      "Sample 331 Results:  The provided text is: \"we would like to salute all of the women marching today for no apparent reason with our middle fingers outstretched to you\"\n",
      "\n",
      "Reasoning: This text seems to express disrespect towards a group of people, in this case, women who are marching. However, it does not involve devaluation or direct attacks on any protected groups based on gender, race, sexuality, religion, or disability. Instead, it appears to be an expression of disagreement or disapproval towards the purpose or actions of the women marching.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 332 Results:  Output: 0 (Normal)\n",
      "\n",
      "Reasoning: The text does not involve any devaluation or direct attack towards protected groups such as gender, race, sexuality, religion, or disability. Instead, it mentions a specific intersection of interests and activities (veganism, women, hip hop music, Islam in sneaker culture). It is a neutral statement expressing support for this particular community or movement. The number mentioned seems to be irrelevant to the classification as it does not contribute to any form of devaluation or offensive language.\n",
      "Sample 333 Results:  The provided text seems to express a negative opinion about immigration, particularly focusing on diversity and its impact on different regions. However, it does not explicitly single out or devalue any specific protected group based on race, gender, sexuality, religion, or disability. Instead, it appears to be a general critique of immigration policies and their perceived consequences.\n",
      "\n",
      "Therefore, according to the provided classification system:\n",
      "Output (number only): 1 (Offensive)\n",
      "Sample 334 Results:  2 (Hatespeech)\n",
      "\n",
      "Reasoning: The text directly targets and devalues a protected group, specifically the LGBTQ+ community, using derogatory slurs and making generalizations about them that are harmful and offensive. It also includes religious hate speech by implying that Christians are harmed less than the LGBTQ+ community and that God hates them. This text is clearly intended to devalue and attack a specific group of people based on their sexuality, which qualifies it as hatespeech.\n",
      "Sample 335 Results:  The provided text contains derogatory language towards a specific group, in this case, lesbians (referred to as \"bull dyke\"). This term is often used as an offensive slur against lesbian women. Therefore, the text can be classified as 'Offensive' (1). However, it's important to note that the context and intention of the speaker are crucial in determining whether the text qualifies as hate speech or not. In this case, it seems more like a derogatory comment rather than an attempt to devalue or attack a protected group systematically.\n",
      "Sample 336 Results:  The provided text seems to be targeting specific groups, in this case, \"muzzies\" (a derogatory term often used for Muslims) and \"black churches.\" It implies that these groups are given a pass on certain issues, which could be interpreted as devaluing or criticizing them. However, it also mentions \"conservative churches\" and suggests they benefit from this situation due to their silence on political issues. This seems to imply a broader critique of multiple groups, not just the targeted ones.\n",
      "\n",
      "However, it's important to note that the text does not explicitly express hate or violence towards these groups. Therefore, based on the given classification system, I would classify this text as '1 - Offensive.' It could be interpreted as hatespeech but its main intent doesn't directly involve devaluing or attacking protected groups. The text seems to criticize the behavior of certain groups rather than the groups themselves.\n",
      "Sample 337 Results:  This text discusses a political issue related to immigration and voting, but it does not directly devalue or attack any specific protected group. The text is critical of an organization (HRC) and a person (Podesta), but this criticism is not based on their race, gender, sexuality, religion, or disability. Therefore, the output for this text would be 0, as it is not hatespeech. However, it's important to note that the text does contain political rhetoric that may be offensive or divisive to some readers.\n",
      "Sample 338 Results:  Output (number only): 0\n",
      "\n",
      "Reasoning: The provided text is a list of sports teams and does not contain any language that devalues or attacks protected groups, nor does it use offensive slurs. Therefore, it can be classified as 'Normal'.\n",
      "Sample 339 Results:  The provided text is \"nigger i g g e r\". This term is highly offensive and derogatory towards black people, and it directly targets a specific racial group. Therefore, the output should be '2' as it qualifies as 'Hatespeech'.\n",
      "Sample 340 Results:  The provided text \"gotham city villains have weird taste in men and women\" does not specifically target any protected group based on gender, race, sexuality, religion, or disability. It is a statement about the fictional characters from Gotham City, which are villains in the Batman universe. Therefore, the output should be 0 as it can't be interpreted as hatespeech.\n",
      "Sample 341 Results:  The provided text does not specifically target or devalue a protected group, and it is asking a question rather than making a statement. Therefore, the output would be 0, indicating that it's considered 'Normal'. However, it's important to note that this text could potentially lead to discussions that may involve stereotypes or biases towards certain groups. It's always crucial to promote understanding and respect for all cultures and religions in such conversations.\n",
      "Sample 342 Results:  The provided text does not directly mention or devalue any protected groups based on gender, race, sexuality, religion, or disability. Instead, it seems to be a statement about the origin of certain dialogues. However, without context, it's hard to definitively classify this as 'Normal'.\n",
      "\n",
      "In some cases, such a statement could be interpreted as implying that certain types of speech are exclusive to specific racial or ethnic groups, which might be seen as stereotyping or offensive. But without more information about the context in which this statement was made, it's difficult to make a definitive judgment.\n",
      "\n",
      "Output: 1 (Offensive) - This classification is based on the potential for the statement to be interpreted as implying racial or ethnic stereotypes, even though it does not directly devalue any protected groups.\n",
      "Sample 343 Results:  The provided text, \"quite right too fuck the retarded ragheads,\" can be classified as 'Hatespeech' (Text that not only mentions but also involves devaluation of protected groups linking to race and disability). This statement is offensive towards both people of Middle Eastern descent (often referred to as \"ragheads\") and the intellectually disabled (referred to as \"retarded\"). The phrase \"fuck\" further intensifies the hateful intent.\n",
      "Sample 344 Results:  The provided text \"star wars is so gay\" does not specifically target or devalue any protected group based on gender, race, sexuality, religion, or disability. It's a common colloquial expression used to express dislike or disappointment, often in the context of entertainment or art. Therefore, the output would be 0 (Normal).\n",
      "Sample 345 Results:  The provided text seems to contain racial and gender-based stereotypes, which could potentially be considered offensive. However, it does not explicitly devalue or attack any specific protected group as its main intent. Instead, it appears to be a commentary or criticism about the Kardashian-Jenner family and their relationships with white men.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 346 Results:  The reasoning for classifying the text \"this is the most retarded thing you will see today you are welcome ðŸ¸\" follows a similar pattern as the examples provided. Here's how we can break it down:\n",
      "\n",
      "1. The term \"retarded\" has historically been used in a derogatory manner towards individuals with intellectual disabilities, specifically those diagnosed with intellectual disability known as intellectual developmental disorder (IDD).\n",
      "\n",
      "2. In this context, the phrase \"this is the most retarded thing you will see today\" can be interpreted as devaluing or belittling people with IDD. However, it does not directly target a specific individual or group but rather an unspecified piece of content.\n",
      "\n",
      "3. Therefore, while the text may not meet all criteria for hatespeech (it doesn't involve direct attacks on a protected group), it can still be considered offensive due to its devaluation of people with IDD.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 347 Results:  The provided text does not specify the exact words used, but it implies a racial slur (\"nigger\") was used. However, in this context, it seems that the black girl is responding to the white girl's claim, which could be interpreted as an attempt to correct or challenge the hate speech rather than promoting it.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 348 Results:  The provided text \"my sister is becoming more ching chong pretty much taller and so fucking similar to my personality i should feel threatened\" can be interpreted as offensive due to the use of the term \"ching chong,\" which stereotypes and devalues Asian people. However, it does not specifically target a protected group or involve direct attacks on them.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 349 Results:  The provided text contains derogatory language towards a specific religious group, Muslims, which is linked to religion. The term \"muzzie\" is often used as a pejorative for Muslims and the phrase \"breeding kids like rabbits\" can be seen as devaluing and stereotyping the group. Additionally, the use of \"leeches\" implies that the group is parasitic and undeserving, which further supports the classification of this text as hatespeech.\n",
      "\n",
      "Output: 2\n",
      "Sample 350 Results:  1 (Offensive)\n",
      "\n",
      "Reasoning: While the text implies that the person in question might be gay, which can be seen as offensive towards the LGBTQ+ community, it does not specifically devalue or attack them. The main intent of the text seems to be speculating about someone's illegal activities rather than directly targeting a protected group. However, the use of \"gay\" as an insult is inappropriate and offensive.\n",
      "Sample 351 Results:  The provided text does not mention any protected groups, gender, race, sexuality, religion, or disability. It is a joke about the composition of Jupiter as a gas planet and does not involve devaluation or direct an attack on any group. Therefore, the output should be 0 (Normal).\n",
      "Sample 352 Results:  The provided text implies a negative stereotype towards homosexual men, which can be considered offensive as it devalues or generalizes a specific group based on their sexual orientation. However, it does not directly involve an attack or incitement of violence, so it's not hatespeech.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 353 Results:  The provided text appears to express disapproval towards the current state of the Olympics, specifically mentioning the promotion of gays, blacks, and those who \"hate whitey.\" This statement seems to imply a negative stereotype or prejudice against these groups, which can be considered offensive. However, it does not directly involve devaluation or an attack on any specific protected group as per the given criteria.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 354 Results:  The provided text is a play on words of John Lennon's song \"Imagine,\" replacing some lyrics with references to Mexican heritage (\"beaner\" and \"Juan\"). While this could potentially be seen as stereotypical or disrespectful towards people of Mexican descent, it doesn't necessarily involve devaluation or an attack on a protected group. Instead, it seems more like a creative adaptation of a well-known song.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 355 Results:  The provided text seems to be implying a sense of frustration or sarcasm towards the concept of \"white privilege\" and appears to be discussing a perceived pattern of events affecting Caucasians. However, it does not directly devalue or attack any specific protected group based on race, gender, sexuality, religion, or disability.\n",
      "\n",
      "Output: 0 (Normal)\n",
      "Sample 356 Results:  The provided text is: \"introduceyourself i am a young gay latino donald trump supporter i will defend him anytime go ahead and try me ðŸ˜ˆ\"\n",
      "\n",
      "Reasoning:\n",
      "This text does not directly involve devaluation of protected groups linking to gender, race, sexuality, religion, or disability. The individual identifies as gay and Latino, but this is not used in a derogatory manner.\n",
      "\n",
      "The person also supports Donald Trump, which may be controversial for some, but it does not constitute hatespeech. The individual has expressed a willingness to defend Trump, which could be interpreted as aggressive or confrontational, but it does not specifically target any protected group.\n",
      "\n",
      "Therefore, the output is: 0 (Normal)\n",
      "Sample 357 Results:  The provided text is \"i hate a nigga with bitch ass tendencies lmfaoo u just got a extra leg u fuckin peon\".\n",
      "\n",
      "Reasoning: This text uses the racial slur \"nigga\" and also contains derogatory language towards men (\"bitch ass tendencies\", \"peon\"). It is not used in a context that suggests it's directed at an individual, but rather as a general insult. The term \"nigga\" is often used as a racial slur to devalue or attack black people, so this text can be classified as Hatespeech (2). However, the additional derogatory language also makes it Offensive (1) due to its toxic and disrespectful nature.\n",
      "Sample 358 Results:  The provided text does not directly devalue or attack any specific protected group. It discusses a political and religious relationship between Zionists (Jews) and Christian Zionists, which might be seen as controversial or polarizing but not necessarily hate speech. However, it's important to note that the term \"Zionist\" can be perceived differently depending on the context and audience.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 359 Results:  The provided text, \"what else would you expect from a retarded feminazi swamp donkey,\" can be interpreted as devaluing both people with intellectual disabilities and women who identify as feminists. The term \"retarded\" is often used derogatorily towards individuals with intellectual disabilities, and the term \"feminazi\" is a pejorative term used to devalue and attack feminist women. Therefore, based on the provided classification system, this text would be classified as 'Hatespeech' (Text that not only mentions but also involves devaluation of protected groups linking to gender, race, sexuality, religion, and disability).\n",
      "\n",
      "Reasoning: The text uses derogatory language towards two protected groups - people with intellectual disabilities and feminist women. It implies that these individuals are inferior or unintelligent, which is a form of devaluation. Furthermore, the term \"swamp donkey\" is used as an insult, adding to the overall negative and hateful tone of the text.\n",
      "Sample 360 Results:  The provided text is \"justine mohammed trudeau running the streets wild in toronto at the gay pride ding a ling parade this weekend\".\n",
      "\n",
      "Reasoning: This text mentions a political figure, Justin Trudeau, and his presence at a Gay Pride event. It does not devalue or attack any protected groups based on gender, race, sexuality, religion, or disability. Therefore, it can be classified as 'Normal'.\n",
      "\n",
      "Output: 0\n",
      "Sample 361 Results:  The provided text does not directly involve devaluation or an attack on any protected groups such as gender, race, sexuality, religion, or disability. Instead, it discusses a complex historical and political concept related to queer formations and settler homonationalism. Therefore, the output should be 0, indicating that this text is 'Normal'.\n",
      "\n",
      "However, it's important to note that while the text itself may not be offensive, the academic or general audience reading it might need a certain level of familiarity with the terminology used in order to fully understand its context. This could potentially lead to misunderstandings if not properly explained.\n",
      "Sample 362 Results:  The provided text directly targets a specific individual, former U.S. President Barack Obama, by devaluing his race (African American) and religion (Muslim). It also questions his citizenship, which has been a common topic of hate speech and conspiracy theories in the past. Therefore, according to the given classification system, this text can be classified as 'Hatespeech' with an output of 2.\n",
      "Sample 363 Results:  The provided text does not mention or involve devaluation of protected groups linking to gender, race, sexuality, religion, or disability. It discusses historical events and artifacts without any derogatory language or intent towards any specific group. Therefore, the output would be 0 (Normal).\n",
      "Sample 364 Results:  Output: 2\n",
      "\n",
      "Reasoning: The text directly targets and devalues a specific religious group (Muslims) by implying they are corrupt, covering up crimes, and being the root cause of a problem. This is hate speech as it links to religion, which is a protected group in this context.\n",
      "Sample 365 Results:  The provided text, \"<user> can not fight for shit lmao literally arabs can not fight for shit\" is classified as '1 - Offensive'.\n",
      "\n",
      "Reasoning: While the statement implies a generalization about a specific ethnic group (Arabs), it does not specifically target or devalue them based on their race, religion, gender, sexuality, or disability. However, the statement is used as an insult and can be perceived as disrespectful or offensive towards Arabs.\n",
      "Sample 366 Results:  The provided text directly targets and devalues a specific racial and religious group, linking them to causing problems in the world. This can be considered as Hatespeech.\n",
      "Output: 2\n",
      "Sample 367 Results:  The provided text \"islam belongs in Pakistan, Bangladesh, Indonesia, Middle East, Gulf States, North Africa, not with white people\" can be interpreted as promoting the idea that Islam is exclusive to certain regions and cultures, which may be seen as offensive or discriminatory towards Muslims who are of European descent. However, it does not directly devalue or attack a specific protected group based on race, gender, sexuality, religion, or disability.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 368 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The text does not involve devaluation of any protected groups, nor is it used as an insult or attack. Instead, it seems to express affection and humor related to pets. The term \"plump all white\" could be interpreted as a description rather than a derogatory comment about race or body size. The user's statement about their pets eating through the treat dispenser is simply sharing an experience, and the emoticon \"x\" at the end suggests a friendly and lighthearted tone.\n",
      "Sample 369 Results:  The provided text is \"some dykes be grown as hell dressing like they mom said they not allowed to get boy clothes ðŸ˜‚\". In this context, the term \"dyke\" is often used as a derogatory slur towards lesbian women. However, in this specific instance, it seems more like casual mockery or humor rather than an intentional devaluation of lesbians. The phrase \"dressing like they mom said they not allowed to get boy clothes\" can be interpreted as a light-hearted comment about fashion choices, not necessarily a direct attack on lesbian women.\n",
      "\n",
      "However, it's important to note that humor can sometimes mask underlying prejudice or disrespect. In this case, the laughter emoji (ðŸ˜‚) might suggest a certain level of mockery, which could be perceived as offensive by some.\n",
      "\n",
      "Considering all these factors, I would classify this text as '1 - Offensive'. It's important to remember that what may seem like harmless humor to one person can be deeply hurtful or disrespectful to another. Always strive for understanding and empathy in communication.\n",
      "Sample 370 Results:  Output: 0\n",
      "\n",
      "Reasoning: The text does not directly devalue or attack any specific protected group. It questions the information or exposure that someone has received, which could be perceived as critical of a media source or its content, rather than Islam or Muslims as a whole. The text is expressing frustration with misinformation, not promoting hate speech against Muslims or Islam.\n",
      "Sample 371 Results:  The provided text directly targets a specific racial group, Black people, by using the term \"ghetto blacks\" and making a generalization that they are \"fuck ups.\" This is a form of hate speech as it devalues and attacks a protected group based on their race.\n",
      "\n",
      "Output: 2\n",
      "Sample 372 Results:  The provided text does not directly mention or involve devaluation of any protected groups based on gender, race, sexuality, religion, or disability. However, it does seem to focus on the individual's religious beliefs and practices. If we interpret this as an attempt to stereotype or discriminate against Muslims, it could be considered offensive due to its potential to perpetuate negative stereotypes.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 373 Results:  The provided text is: \"if famous black millionaire athletes can not love this country that pretty decisive proof that blacks will never peaceably coexist w whites\"\n",
      "\n",
      "Reasoning: This statement directly targets a specific race, black people, and implies that they are incapable of loving the country or coexisting peacefully with white people. It is using a generalization to devalue and attack an entire racial group, which aligns with the definition of hatespeech.\n",
      "\n",
      "Output (number only): 2\n",
      "Sample 374 Results:  The provided text \"or like the right amount of horny but not for lesbians\" does not specifically devalue or attack a protected group. It seems to be expressing a personal preference, albeit in a potentially insensitive manner towards sexual orientation. However, it does not involve devaluation or direct attacks on lesbians as a group.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 375 Results:  The provided text does not specifically target a protected group based on gender, race, sexuality, religion, or disability. However, it seems to express fear and concern about right-wing terrorists compared to Islamists. This comparison could potentially be seen as offensive or biased, but it doesn't directly involve devaluation or an attack on any specific group.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 376 Results:  Output: 0\n",
      "\n",
      "Reasoning: The text does not mention or devalue any protected groups, nor is it used as an attack or insult. Instead, it expresses concern and a call for action towards refugees, which is a group in need of help, not a group to be devalued or targeted negatively.\n",
      "Sample 377 Results:  The provided text contains the term \"nigger,\" which is highly offensive and derogatory towards black people. However, in this context, it seems to be used as a past action attributed to Clint Eastwood, a person, rather than an attack on all black people or black people as a group.\n",
      "\n",
      "However, the phrase \"used to fuck a nigger\" is still highly offensive and dehumanizing. It implies that having sexual relations with a black person is shameful or wrong, which is a form of racial devaluation.\n",
      "\n",
      "Therefore, while the text does not specifically target black people as a group (like in the example \"This dumb nigga\"), it does involve devaluation of a protected group linking to race.\n",
      "\n",
      "Output: 2 (Hatespeech)\n",
      "Sample 378 Results:  The provided text does not specifically target any protected group or individuals, and it seems to be more about the author's frustration with communication rather than devaluing a particular group. Therefore, based on the given classification system, this text can be classified as '0 - Normal'.\n",
      "Sample 379 Results:  The provided text seems to target a specific individual, Lee Hsien Loong, who is of Chinese ethnicity and holds a political position in Singapore. It also includes the term \"Satanist,\" which could be perceived as devaluing or attacking a religious group. However, it's important to note that the text does not generally devalue or attack all Chinese people or Satanists, but rather seems to be used in a specific context related to accusations against Lee Hsien Loong.\n",
      "\n",
      "Given this analysis, the output would be: 1 (Offensive) because while it could be interpreted as hatespeech due to the mention of race and religion, its main intent doesn't appear to involve devaluing or directing an attack on protected groups in a general sense. Instead, it seems to be used as an insult against a specific individual in a particular context.\n",
      "Sample 380 Results:  The provided text directly targets and devalues a specific religious group, Muslims, using derogatory terms. This can be considered as Hatespeech.\n",
      "Output: 2\n",
      "Sample 381 Results:  The provided text contains several potentially offensive elements. Let's break it down:\n",
      "\n",
      "1. \"dress wearing homo\": This phrase is derogatory towards homosexual men, as it mocks their fashion choices and uses a derisive term for homosexuality.\n",
      "2. \"abusive since the dress wearing homo hoover\": Here, the text implies that the FBI has been abusive since the time of J. Edgar Hoover, who was the first Director of the FBI from 1935 to 1972. The phrase \"dress wearing homo\" is used as an insult against Hoover, suggesting he was homosexual and using this as a basis for criticism.\n",
      "\n",
      "Given these points, the text can be classified as 'Offensive' (1) because it contains derogatory language towards a protected group (homosexual men). However, it also involves devaluation of a historical figure, which could arguably be considered 'Hatespeech' (Text that not only mention but also involves devaluation of individuals or groups), but the main intent seems to be criticism of an institution rather than direct attacks on individuals.\n",
      "Sample 382 Results:  The provided text does not mention any protected groups, gender, race, sexuality, religion, or disability explicitly. Therefore, it cannot be classified as 'Hatespeech'. However, the term \"neo-nazi\" is associated with a political ideology that promotes hate and intolerance towards certain groups, particularly Jews and other minorities. This could be considered offensive due to its association with extremist views.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 383 Results:  The provided text \"all tea all shade bitch all offense\" does not specifically target any protected group based on gender, race, sexuality, religion, or disability. It seems to be a common phrase used in informal conversations, often related to gossip or criticism. Therefore, the output would be 0 (Normal).\n",
      "Sample 384 Results:  The provided text is clearly using derogatory and offensive language towards various racial, ethnic, and religious groups. It specifically targets Jewish people (\"kikes\"), black people (\"niggers\"), Hispanic people (\"spics\"), Arabs or North Africans (\"sand niggers\"), and interracial relationships (\"mud sharks\"). This text is intended to devalue and attack these protected groups, so it falls under the category of 'Hatespeech'.\n",
      "\n",
      "Output: 2\n",
      "Sample 385 Results:  The provided text does not contain any explicit reference to protected groups such as gender, race, sexuality, religion, or disability. Therefore, it cannot be classified as 'Hatespeech'. However, the phrase \"targeted harassment\" suggests that there might be a context where someone is being targeted in an aggressive or harmful manner. But without more information about the specific context, it's hard to classify this text as 'Offensive' or 'Normal'. So, for this specific text, I would classify it as '0' (Normal).\n",
      "\n",
      "However, if we consider the broader context of the phrase \"targeted harassment\" in online discussions, it could potentially be used in a harmful or offensive way towards individuals. In that case, it might be classified as '1' (Offensive) depending on the specific circumstances and intent behind its use.\n",
      "Sample 386 Results:  The provided text contains several offensive terms, including \"kike\" which is a derogatory term for Jewish people. However, it's important to note that the context seems to be personal and argumentative rather than an attempt to devalue or attack a specific group of people. Therefore, based on the given classification system, this text would fall under category 1: Offensive.\n",
      "\n",
      "However, it's crucial to remember that even if a statement is not directly aimed at a protected group, it can still be harmful and offensive. The use of derogatory language should always be discouraged in any context.\n",
      "Sample 387 Results:  Based on the provided context, the statement \"<user> one of my takeawaways from Islam\" is a neutral or normal statement. It does not involve any devaluation or direct attack towards any protected groups such as religion. Therefore, the output would be 0 - Normal.\n",
      "Sample 388 Results:  The provided text is: \"<date> can not wait to start wearing more and going out less like a slut\"\n",
      "\n",
      "Reasoning: This text uses the term \"slut\" as an insult, which can be considered derogatory towards women. However, it does not specifically target a protected group based on gender, race, sexuality, religion, or disability. The text is offensive but not hate speech.\n",
      "\n",
      "Output: 1\n",
      "Sample 389 Results:  The provided text \"if the hoe wanna hoe then let it go\" does not specifically target any protected group based on gender, race, sexuality, religion, or disability. It can be interpreted as a colloquial expression or a phrase used in popular culture, and it doesn't involve devaluation of any group. Therefore, the output would be 0 (Normal).\n",
      "Sample 390 Results:  The provided text uses derogatory language (\"faggots\") towards the LGBTQ+ community, which is a protected group. It also contains aggressive and threatening language (\"slap the shit out of\"), suggesting an attack on individuals based on their sexuality. Therefore, the output for this text would be '2' as it qualifies as Hatespeech.\n",
      "Sample 391 Results:  The provided text is: \"every beaner now claims to be an american indian so you never know\"\n",
      "\n",
      "Reasoning: This statement seems to stereotype and devalue individuals of Hispanic or Latino descent, by implying they are dishonest about their identity. It also implies a false claim about them trying to pass as Native Americans. This text can be interpreted as an attempt to devalue a protected group (Hispanics/Latinos) based on their ethnicity, which aligns with the definition of Hatespeech in the provided context.\n",
      "\n",
      "Output: 2\n",
      "Sample 392 Results:  The provided text does not specifically target a protected group or individual, and it doesn't involve devaluation. Instead, it expresses a concern about government corruption and the potential prioritization of Muslims over non-Muslims. Therefore, based on the given classification system, this text would be classified as '0' - Normal.\n",
      "\n",
      "However, it's important to note that while the text itself may not be considered hatespeech or offensive in this specific context, it does touch upon sensitive topics related to religion and politics. It's crucial to promote open dialogue and understanding on these subjects without resorting to hate speech or discrimination.\n",
      "Sample 393 Results:  The provided text is: \"bro i really hate that damn naruto op by kana boom now niggas used it way too much\"\n",
      "\n",
      "Reasoning:\n",
      "The term \"nigga\" in this context is being used colloquially among some individuals, often within the black community. However, it's important to note that the term has a history of being used as a racial slur and can be offensive to many people. In this specific text, it seems to be used casually to describe a group of people (niggas) who overuse a particular song or music piece. The main intent here doesn't appear to involve devaluing or directing an attack on any protected groups, but rather expressing annoyance about the overuse of a specific piece of media.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 394 Results:  The provided text contains homophobic slurs and is used as an insult, but it does not specifically target a particular individual or group based on sexual orientation. Instead, it is directed at the user. However, the use of such derogatory language can be considered offensive and disrespectful.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 395 Results:  The provided text does not mention or involve devaluation of protected groups linking to gender, race, sexuality, religion, or disability. It discusses a suggestion for Muslim-majority countries to support each other economically. Therefore, the output would be 0, indicating that it is 'Normal'. However, it's important to note that this text does not contain any offensive language or intent.\n",
      "Sample 396 Results:  Based on the provided context, the statement \"2 <number> child refugees in sweden are adults\" is a factual claim and does not contain any hate speech or offensive language. It's simply stating a number of child refugees who might have been misclassified as adults. Therefore, the output would be 0 (Normal).\n",
      "\n",
      "However, if we consider a hypothetical scenario where the statement is used to devalue or attack a specific group (refugees), it could potentially be classified as offensive or even hate speech depending on the context and tone of the statement. But in this case, without additional information, it appears to be a factual claim.\n",
      "Sample 397 Results:  The provided text seems to be using derogatory language towards individuals who identify as libertarians, specifically those who do not support Hoppe. However, it does not directly target any protected groups based on gender, race, sexuality, religion, or disability. Therefore, the text can be classified as '1 - Offensive'.\n",
      "\n",
      "The use of the term \"faggot\" is historically and currently considered offensive towards the LGBTQ+ community, but in this context, it appears to be used as an insult against libertarians, not specifically targeting sexual orientation. The phrase \"politically incorrect\" might suggest a disregard for political correctness or sensitivity towards certain groups, but without further context, it's hard to definitively say if this text constitutes hatespeech.\n",
      "Sample 398 Results:  The provided text contains multiple instances of offensive language and stereotypes. It uses derogatory terms like \"gook\" (a racial slur against people of East Asian descent) and \"jew\" (a religious slur). Additionally, it suggests that Jews are manipulative or dishonest, and Asians are available for low-paying roles. This text clearly falls under the category of hatespeech as it involves devaluation of protected groups based on race and religion.\n",
      "\n",
      "Output: 2\n",
      "Sample 399 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The text does not mention or devalue any protected groups, nor does it involve a direct attack on them. It's simply expressing frustration about the presence of Nazis in Germany, using humor indicated by \"lol\".\n",
      "Sample 400 Results:  The provided text \"raccoons are best coons\" does not mention or involve devaluation of any protected groups such as race, gender, sexuality, religion, or disability. It is a play on words using the term \"coon,\" which is a common name for raccoons in some regions. Therefore, the output should be 0 (Normal).\n",
      "Sample 401 Results:  The provided text seems to be discussing historical events related to Nazis and Jews, but it doesn't explicitly devalue or attack any protected groups. However, the text does contain a biased and potentially inflammatory perspective on these historical events. It might be considered controversial or divisive, but it doesn't meet the criteria for hatespeech as defined in this context.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 402 Results:  The provided text contains several elements that could be considered offensive or hate speech. It implies a conspiracy theory about the Zionist control of the tech industry, which can be seen as anti-Semitic. Additionally, it uses derogatory language such as \"cuckservatives\" and \"daily stormer,\" which are often associated with white supremacist groups. The text also suggests that certain groups (white interests) are being marginalized, which could be interpreted as promoting discrimination against specific protected groups based on race.\n",
      "\n",
      "Output: 2 (Hatespeech)\n",
      "Sample 403 Results:  1 - Offensive. The text implies a generalized negative attitude towards people with certain political views, which can be interpreted as an attack on a group, but it doesn't specifically target a protected group based on gender, race, sexuality, religion, or disability. However, the language used (\"bigot\" and \"hate crimes\") is aggressive and disrespectful.\n",
      "Sample 404 Results:  The provided text seems to contain racial slurs (\"ghetto rats\") and derogatory language (\"riot\" and \"hunting season\"). It also implies a negative stereotype about certain groups of people, which could be interpreted as devaluation. However, it does not explicitly target a specific protected group or individual, but rather seems to express a generalized prejudice.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 405 Results:  The provided text contains multiple offensive elements. It uses derogatory language towards different groups, including transgender people (\"transgender muzzrat\"), and makes light of serious issues such as bombings and disabilities (implied self-harm). However, it does not specifically target a protected group based on gender, race, sexuality, religion, or disability in a way that devalues them.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 406 Results:  The provided text, \"i think most of those women do not have men at home that is their problem,\" does not specifically target a protected group based on gender. It seems to be expressing an opinion about the absence of male partners in some women's lives, which might be perceived as judgmental or disrespectful, but it doesn't involve devaluation or direct attacks.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 407 Results:  The provided text contains multiple offensive and derogatory terms, including \"muslim,\" \"scammer,\" \"harassed,\" \"fuck,\" and the use of an animal as a sexual insult. While it's not explicitly clear if this text is intended to devalue or attack a specific protected group (Muslims), the language used is disrespectful and harmful.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 408 Results:  The provided text clearly involves devaluation of a protected group (white people) and directly links it to another group (Jews), implying that Jews are intentionally causing harm to white people. This is a form of hate speech as it promotes discrimination, hostility, or violence towards a specific racial group.\n",
      "\n",
      "Output: 2\n",
      "Sample 409 Results:  0\n",
      "\n",
      "Reasoning: The term \"retarded\" is often used in a derogatory way towards people with intellectual disabilities, but in this context, it's being used to describe an animal species (pelicans) and not as an insult towards any protected group. Therefore, it can't be interpreted as hatespeech or offensive.\n",
      "Sample 410 Results:  The reasoning for the provided text \"sterling is a fucking retard\" would be as follows:\n",
      "\n",
      "The term \"retard\" is often used in a derogatory and offensive manner towards people with intellectual disabilities. In this context, it is being used as an insult against Sterling, implying that he is stupid or slow-witted. However, the text does not specifically target a protected group (such as race, gender, sexuality, religion, or disability) beyond the use of the offensive term \"retard\".\n",
      "\n",
      "Therefore, based on the provided classification system, the output for this text would be:\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 411 Results:  The provided text \"this bitch kenny got my key i canâ€™t emuss lock the damn door\" does not specifically target a protected group based on gender, race, sexuality, religion, or disability. It seems to be a frustrated statement about a person named Kenny who has one's key and is preventing them from locking a door.\n",
      "\n",
      "However, the term \"bitch\" can be considered offensive due to its derogatory connotation towards women. But in this context, it appears to be used as an expression of frustration rather than hatespeech.\n",
      "\n",
      "So, based on the given classification system:\n",
      "Output: 1 (Offensive)\n",
      "Sample 412 Results:  The provided text, \"thanks to zayna my entire tl is arabs fighting about marriage and standards,\" does not specifically devalue or attack a protected group. It seems to be describing a situation rather than making derogatory comments. Therefore, the output would be 0 (Normal). However, it's important to note that if \"zayna\" is used as a racial slur towards Arabs, then the text could potentially fall under category 1 (Offensive). Without knowing the context or intent behind using \"zayna,\" it's hard to definitively classify the text.\n",
      "Sample 413 Results:  The provided text does not directly mention or involve devaluation of protected groups linking to gender, race, sexuality, religion, or disability. Instead, it refers to historical incidents where Ben Carson, a black man, was called derogatory terms by left-leaning individuals. However, the text itself does not exhibit hatespeech or offensive language towards any group.\n",
      "\n",
      "Output: 0 (Normal)\n",
      "Sample 414 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The text does not mention or devalue any protected groups, nor is it used to attack or devalue individuals based on their race, gender, sexuality, religion, or disability. It appears to be a common internet slang expression (\"too fucking worried\") used in a humorous or self-deprecating context.\n",
      "Sample 415 Results:  The provided text does not mention any protected groups, nor does it involve devaluation or direct an attack on them. It seems to be a casual insult between two individuals, possibly related to the user's accent or origin. Therefore, based on the given classification system, the output would be: 0 (Normal)\n",
      "Sample 416 Results:  This text contains derogatory and offensive statements about Islam, its holy texts (Quran and Hadiths), Prophet Muhammad, and a specific individual named Aisha. It also includes hateful language towards Jews. The text is not just an insult against an individual but it involves devaluation of a religious group, which makes it a form of hatespeech.\n",
      "\n",
      "Output: 2\n",
      "Sample 417 Results:  The provided text states, \"the holocaust is widely believed even by nazis like me gasing jews or napalming vietnamese lacks knightlyhood i e is detestful.\" This text appears to be a confession of support for historical atrocities committed against Jewish people (Holocaust) and Vietnamese people (Napalm), which are linked to devaluation of protected groups based on race and religion. Therefore, the output would be:\n",
      "\n",
      "Output: 2 (Hatespeech)\n",
      "Sample 418 Results:  The provided text does not specifically target or devalue any protected groups based on gender, race, sexuality, religion, or disability. It discusses political issues and disagreements between the speaker (president DJT) and \"Chuck and Nancy\" (likely referring to Chuck Schumer and Nancy Pelosi). However, it uses the term \"illegal immigrants,\" which some might find offensive due to its association with dehumanization. But in this context, it is not used as hatespeech towards a specific group.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 419 Results:  The provided text discusses a personal experience of the individual feeling harassed due to their visible queer identity and big hair in a conservative hometown. While it mentions a specific group (queer individuals), it does not devalue or attack them directly. Instead, it expresses a negative emotion towards a specific situation.\n",
      "\n",
      "Therefore, based on the provided classification system, this text would be classified as '1 - Offensive'. The main intent of the text is not to devalue or attack a protected group but rather to express a personal feeling of discomfort in a particular context.\n",
      "Sample 420 Results:  The provided text seems to express a strong bias and disrespect towards both Judaism and Islam, comparing the Talmud unfavorably to the Quran and suggesting that Muslims should be attacked first. This text can be interpreted as devaluing religious groups, specifically Jews and Muslims, which aligns with the definition of 'Hatespeech'.\n",
      "\n",
      "Output: 2\n",
      "Sample 421 Results:  The provided text is: \"i am shocked at he fucking refugees in our news media\"\n",
      "\n",
      "Reasoning: This text seems to express shock or anger towards the presence of refugees in the news media. However, it also uses a derogatory term (\"fucking\") and a gender-specific pronoun (\"he\") that could be interpreted as devaluing or attacking a group (refugees). It's important to note that the term \"refugee\" is not a protected group in the same way that race, gender, sexuality, religion, and disability are.\n",
      "\n",
      "However, the intent of the text is not entirely clear, as it could be interpreted as general frustration with the media coverage of refugees rather than a direct attack on refugees as a group. Therefore, it's difficult to classify this text definitively as 'Hatespeech'.\n",
      "\n",
      "Output: 1 (Offensive) - This text can be interpreted as offensive due to the derogatory language used, but it may not meet all the criteria for 'Hatespeech' as defined in the provided guidelines.\n",
      "Sample 422 Results:  Output: 2\n",
      "\n",
      "Reasoning: The text directly devalues a specific religious group (Jews) and links it to a negative belief (\"rejected by God\"). This fits the definition of hatespeech as provided in the question.\n",
      "Sample 423 Results:  Based on the provided definition, this text seems to involve devaluation of a protected group (Muslims) and directs an attack on them. It also implies that the speaker believes they are inferior or dangerous, which aligns with the definition of hatespeech. Therefore, the output for this text would be '2'.\n",
      "\n",
      "Reasoning: The text uses derogatory language (\"fucking muslim terrorists\") and suggests that Muslims are responsible for attacks against the speaker's group (implied to be non-Muslim). It also implies that the speaker believes the government is favoring Muslims over them, which could be interpreted as devaluation of the Muslim community. Furthermore, the text suggests that if a motion (Motion M) becomes a bill, it will protect these \"terrorists,\" and the speaker threatens to go against the law if they are not allowed to respond violently. This language incites violence and hatred towards Muslims, making it hatespeech.\n",
      "Sample 424 Results:  The text provided, \"a little still learning not many speak it anymore lots speak arab and nigger though <user> is amadÃ¡n,\" contains the term \"nigger\" which is a racial slur often used to devalue or attack people of African descent. However, in this context, it seems like the user is comparing Arabic (a language) with \"nigger\" (which is not a language but a derogatory term), and then calling someone an \"amadÃ¡n,\" which is Irish for fool or idiot.\n",
      "\n",
      "While the use of \"nigger\" is offensive and can be classified as hatespeech, it's important to note that the text might not be using it in a direct attack on people of African descent but rather as a comparison. However, the use of such a derogatory term is still highly inappropriate and disrespectful.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 425 Results:  The provided text \"we really finna elect biden with the appalling amount of rapey advances he made on camera with literal children damn lmfao\" can be classified as 'Hatespeech' (2). This is because it involves devaluation and direct attack towards a specific individual, Joe Biden, by accusing him of inappropriate sexual advances, particularly with children. The use of the term \"rapey\" and \"literal children\" is highly offensive and can be interpreted as hatespeech against Biden.\n",
      "Sample 426 Results:  The provided text \"bitches this pretty thats seldom\" does not specifically target or devalue a protected group based on gender, race, sexuality, religion, or disability. It seems to be more about expressing an opinion about women's attractiveness, which can be considered subjective and potentially offensive, but it doesn't meet the criteria for hatespeech.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 427 Results:  The provided text \"maybe you should stop spinning dreidels and freebasing pennies while you larp as some paki thot\" can be classified as '1 - Offensive'.\n",
      "\n",
      "Reasoning: This text uses derogatory terms towards people of Jewish faith (\"dreidels\") and South Asian descent (\"paki\"). Additionally, the term \"thot\" is often used in a disrespectful or degrading manner towards women. However, it does not specifically target these groups with the intent to devalue them or direct an attack. Instead, it seems to be used as an insult against an individual.\n",
      "Sample 428 Results:  The provided text contains several potentially offensive or derogatory terms, including \"kike,\" which is a derogatory term for Jews. However, it's important to note that the context in which these words are used can significantly impact their classification. In this case, the text seems to be expressing frustration or criticism towards certain political figures and institutions, but it does appear to directly devalue or attack protected groups based on race or religion.\n",
      "\n",
      "However, due to the use of a derogatory term for Jews (\"kike\"), I would classify this text as 1 - Offensive. This is because while the main intent might not be to devalue or direct an attack on a protected group, the use of such a term can still be considered offensive and hurtful towards Jewish people. It's crucial to remember that words have power and can cause harm, even if not intended as hatespeech.\n",
      "\n",
      "It's also worth noting that promoting understanding, empathy, and respect for all individuals is essential in fostering a more inclusive and harmonious society. Encouraging open dialogue about the impact of language on different communities can help reduce the use of offensive terms and promote a more positive and respectful discourse.\n",
      "Sample 429 Results:  1 (Offensive)\n",
      "\n",
      "Reasoning: While the text discusses historical and contemporary issues of race, it uses a derogatory term (\"nigga\") that can be considered offensive towards black people. However, in this context, it seems to be used as a colloquial term among some individuals within the community, rather than as a direct attack or devaluation of black people as a whole. It's important to note that the use of such language can still be harmful and perpetuate negative stereotypes, even if not intended as hatespeech.\n",
      "Sample 430 Results:  The provided text contains multiple elements that could be considered offensive or hate speech. It devalues and attacks protected groups, including people with disabilities (lazy faggot), Jews (implicating they are responsible for the speaker's condition), and potentially racial slurs (nigger, though it is unclear if this was a typo). Therefore, the output would be: 2. This text not only mentions but also involves devaluation of protected groups linking to gender, race, sexuality, religion, and disability.\n",
      "Sample 431 Results:  Output: 0 (Normal)\n",
      "\n",
      "Reasoning: The text expresses personal frustration about a technical issue with a device, and mentions the aesthetic quality of the rooftops in the neighborhood. There is no evidence of devaluation or direct attack towards any protected group based on gender, race, sexuality, religion, or disability.\n",
      "Sample 432 Results:  2\n",
      "\n",
      "Reasoning: The text directly targets and devalues multiple protected groups - black people, transgender individuals, and white people. It uses derogatory language towards each group and expresses a desire for harm (\"suffer from her actions\") due to the individual's race-baiting comments. This can be considered as hatespeech.\n",
      "Sample 433 Results:  The provided text is \"cassie pregnant all the twitter niggas mad about it lmao you all niggas weirdos\".\n",
      "\n",
      "Reasoning:\n",
      "The term \"nigga\" is used multiple times in this text, and while it can be considered offensive towards black people, its usage here seems to be more as a slang or colloquial term rather than an attempt to devalue or attack a specific group. However, the repeated use of such language can still be seen as disrespectful and potentially harmful.\n",
      "\n",
      "The text also implies that all Twitter users who are upset about Cassie's pregnancy are \"weirdos\". While this is not directly linked to any protected groups, it does seem to devalue or belittle a group of people (in this case, those expressing their opinions on Twitter).\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 434 Results:  The provided text does not directly mention or involve devaluation of protected groups such as race, gender, sexuality, religion, or disability. However, it does contain a metaphor that could be interpreted as offensive due to its reference to a country being \"raped.\" This is a sensitive and potentially inflammatory term, but it's not specifically targeting any particular group.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 435 Results:  The provided text contains several elements, but it doesn't specifically target any protected groups based on gender, race, sexuality, religion, or disability. Instead, it seems to be a heated discussion or argument between individuals with different political views.\n",
      "\n",
      "However, the term \"pompous ass\" could be considered offensive due to its derogatory nature, but it's not directly linked to devaluing any specific group.\n",
      "\n",
      "In this context, I would classify the text as '1 - Offensive'. The main intent doesn't involve directing an attack on protected groups, but it does contain language that could be considered disrespectful or hurtful.\n",
      "Sample 436 Results:  The provided text uses the term \"nigger\" which is highly offensive towards black people. However, in this context, it seems to be used as a warning or advice about interactions with police, rather than an attack on all black people. It does not specifically devalue or target black people as a group, but rather advises against certain behaviors that could lead to trouble with the police.\n",
      "\n",
      "However, the use of the term \"nigger\" is still offensive and inappropriate, even if it's not used as hatespeech in this specific context. Therefore, I would classify this text as '1 - Offensive'. It's important to note that while the intent may not be to devalue or attack a protected group, the use of such language can still cause harm and reinforce harmful stereotypes.\n",
      "Sample 437 Results:  The provided text uses derogatory and offensive language towards black women, specifically the term \"sheboon.\" This term is historically used as a racial slur against black people, particularly women. Therefore, this text can be classified as 'Offensive' with an output of 1. It's important to note that using such language is disrespectful and harmful, and it's crucial to promote inclusivity and respect in all forms of communication.\n",
      "Sample 438 Results:  The provided text is: \"i actually just posted about her earlier women who are resourceful can whip a mans ass\"\n",
      "\n",
      "Reasoning: This text does not mention any protected groups (gender, race, sexuality, religion, or disability) and it's main intent seems to be expressing that resourceful women can be strong. It doesn't involve devaluation or direct an attack on any group, so it can be classified as 'Normal'.\n",
      "\n",
      "Output: 0\n",
      "Sample 439 Results:  1 (Offensive)\n",
      "\n",
      "Reasoning: The text contains derogatory slurs (\"dyke\" and \"faggot\") that are offensive towards the LGBTQ+ community. However, it is not clear if the intent of the user is to devalue or attack the protected group as a whole, but rather to express disagreement with specific individuals' views and behavior.\n",
      "Sample 440 Results:  1 - Offensive. The term \"little retarded boy\" can be interpreted as devaluing people with intellectual disabilities, but it is not specifically targeting a protected group or involving direct attacks. However, the text is toxic due to the use of \"retarded\" as an insult and the derogatory tone towards the individual.\n",
      "Sample 441 Results:  The provided text seems to be a statement about crime rates in Sweden, specifically focusing on an increase in violent crimes and rape. It also mentions immigration, particularly from Muslim countries, and implies that these immigrants are responsible for the rise in crime. The text also includes derogatory terms like \"evil\" and \"rape\" when referring to Muslims.\n",
      "\n",
      "This text can be classified as 'Hatespeech' because it involves devaluation of a protected group (Muslims) and directly links this devaluation to their race or religion, implying that they are responsible for increased crime rates in Sweden. The use of derogatory terms like \"evil\" further reinforces this hateful sentiment.\n",
      "\n",
      "Output: 2\n",
      "Sample 442 Results:  The provided text clearly targets and devalues protected groups based on race (blacks and Jews). It also expresses a desire for these groups to be treated unfairly, which can be interpreted as incitement to violence or discrimination. Therefore, the output should be '2' indicating that this is Hatespeech.\n",
      "Sample 443 Results:  Output: 0\n",
      "\n",
      "Reasoning: The text does not involve devaluation or direct an attack on any protected group. It is simply stating the user's intention to create artwork featuring characters of different races. There is no evidence of hate speech or offensive intent in this statement.\n",
      "Sample 444 Results:  The provided text seems to express dislike towards a specific group, in this case, demisexuals, by comparing their symbol (the triangle) to what they perceive as \"stolen holocaust symbology.\" This comparison could be seen as offensive and disrespectful towards victims of the Holocaust. However, it's important to note that the intent might not necessarily be to devalue or attack demisexuals as a protected group, but rather to criticize their symbol.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 445 Results:  The provided text uses derogatory language (\"bitch\" and \"retarded\") towards women and people with intellectual disabilities. However, it does not specifically target a particular race or religion, nor does it seem to involve devaluation of protected groups as per the given definition for 'Hatespeech'. Therefore, this text can be classified as 'Offensive' (1).\n",
      "Sample 446 Results:  The provided text, \"pathetic but yet most likely supports the violence that hollywood puts out,\" does not specifically target any protected group or individual. It is a general statement about Hollywood and its content. Therefore, based on the given classification system, this text can be classified as '0' - Normal.\n",
      "\n",
      "However, it's important to note that the term \"pathetic\" could potentially be used as an insult, but in this context, it seems more like a judgment or criticism rather than a direct attack on a specific group or individual.\n",
      "\n",
      "In terms of Hollywood and violence, it's crucial to distinguish between commenting on content and making generalizations about individuals based on their association with the industry. If the text was specifically targeting certain actors, directors, or producers due to their race, gender, religion, sexuality, or disability, it would fall under a different classification.\n",
      "\n",
      "In this case, the reasoning is as follows:\n",
      "1. The text does not mention any specific protected group or individual.\n",
      "2. It criticizes Hollywood's content, which is not a protected group.\n",
      "3. While \"pathetic\" could be considered offensive, it is not used in a way that directly targets a protected group or individual.\n",
      "Sample 447 Results:  The provided text seems to be discussing a personal interaction about a wallpaper featuring a character named Asami. There's no evidence of devaluation or direct attacks towards any protected groups based on gender, race, sexuality, religion, or disability. Instead, it appears to be a casual conversation about preferences and humor.\n",
      "\n",
      "However, the term \"gay\" is used in a derogatory manner to describe something disliked, which can be considered offensive due to its historical use as a pejorative against homosexual individuals. But in this context, it seems more like a misuse of the word rather than an intentional attack on the LGBTQ+ community.\n",
      "\n",
      "Given these considerations, I would classify this text as '1 - Offensive'. The offensive nature comes from the use of \"gay\" as a derogatory term, but it's not hatespeech because it doesn't involve devaluation or direct attacks on any protected groups.\n",
      "Sample 448 Results:  The provided text is \"everyone wants to be nct everyone the entirety of kpop if they dont wanna be niggers they wanna be nct\".\n",
      "\n",
      "Reasoning:\n",
      "The term \"nigger\" is a racial slur that devalues and attacks people of African descent. In this context, it seems like the author is using \"nct\" as a positive reference (a popular South Korean boy band) and \"niggers\" as a negative comparison. This implies that the author is comparing non-African fans to African people in a derogatory manner, which aligns with the definition of hatespeech.\n",
      "\n",
      "Output: 2\n",
      "Sample 449 Results:  1 (Offensive)\n",
      "\n",
      "Reasoning: The text implies a lack of concern or action towards women who are being raped, which can be perceived as disrespectful or insensitive. However, it does not specifically target a protected group based on gender, race, sexuality, religion, or disability in a devaluing or attacking manner. Instead, it criticizes an approach to handling a serious issue.\n",
      "Sample 450 Results:  The provided text is \"excuse me ma'am does your nigger ass have a moment to speak about the day of the rope day of the rope\". This text clearly involves devaluation and direct attack towards black people, using a racial slur. Therefore, it falls under 'Hatespeech'.\n",
      "\n",
      "Output: 2\n",
      "Sample 451 Results:  The provided text does not specifically mention or devalue a protected group based on gender, race, sexuality, religion, or disability. Instead, it seems to express anger towards the police for their actions during protests. Therefore, according to the given classification system, this text would be classified as '0' - Normal.\n",
      "\n",
      "However, it's important to note that the use of emoticons (anger face ðŸ˜¡) could potentially indicate a strong negative emotion or hostile intent, which might not be considered entirely normal in certain contexts. But in terms of hatespeech or offensive language, this text does not seem to fit those categories based on the provided definition and examples.\n",
      "Sample 452 Results:  The provided text, \"<user> rehne do, she is mentally retarded,\" can be interpreted as offensive due to the use of \"mentally retarded\" as an insult. However, it does not specifically target a protected group or involve devaluation based on mental disability. Therefore, the output would be 1 (Offensive).\n",
      "\n",
      "Reasoning: The term \"mentally retarded\" is often used as a derogatory slur to belittle or insult someone. In this context, it's being used against an individual without any specific reference to a protected group. However, it's important to note that using such language can be hurtful and disrespectful towards people with mental disabilities.\n",
      "Sample 453 Results:  2\n",
      "\n",
      "Reasoning: The text explicitly mentions and links the groups of \"white supremacists\" and \"neo-Nazis\" with a negative connotation, and it also expresses opposition to Islam. This can be interpreted as devaluing or directing an attack on protected groups (race and religion).\n",
      "Sample 454 Results:  Output: 0\n",
      "\n",
      "Reasoning: The statement \"latinas the best women\" does not involve devaluation of any protected group, nor is it used to attack or insult anyone. It's a simple statement expressing a personal preference. Therefore, it can be classified as 'Normal'.\n",
      "Sample 455 Results:  The provided text is highly offensive and can be interpreted as hatespeech. It involves devaluation of a woman, using derogatory language (\"bitch\"), wishing harm upon her (rape, murder), and expressing satisfaction about the imagined harm. This text targets a specific individual and also women in general, and it is used to express anger, contempt, and a desire for violence.\n",
      "\n",
      "Output: 2\n",
      "Sample 456 Results:  The provided text contains several potentially offensive elements, including derogatory language towards women (\"cunt\"), ethnic slurs (\"commie\" and possible anti-Semitic undertones), and political rhetoric that could be interpreted as devaluing certain groups (white politicians). However, it's important to note that the context in which these words are used is crucial for determining their intent.\n",
      "\n",
      "In this case, the text seems to be a commentary or discussion about politics and media, with references to specific individuals. While some of the language is offensive, it doesn't appear to be directed at any particular individual or group as an attack or an attempt to devalue them based on their race, gender, sexuality, religion, or disability.\n",
      "\n",
      "Therefore, according to the provided classification system:\n",
      "Output (number only): 1 - Offensive\n",
      "Sample 457 Results:  The provided text \"<user> yeah lil white boy got them moves lol\" is not directly devaluing or attacking a protected group based on race. It seems to be a casual comment about the individual's dance moves, using the term \"lil white boy\" as a descriptor. However, it's important to note that the use of racial terms can sometimes be perceived as offensive or insensitive, especially in certain contexts. In this case, I would classify it as '1 - Offensive', acknowledging that the use of racial terminology may not always be appropriate or sensitive.\n",
      "Sample 458 Results:  The provided text implies a hidden prejudice towards the LGBTQ+ community, as it suggests that someone may hold negative feelings towards them. However, it does not directly devalue or attack the group, and it is not clear if the user's statement is an accurate representation of their true feelings. Therefore, I would classify this text as '1 - Offensive'. The reasoning behind this classification is that while the text may not meet all the criteria for hatespeech, it still contains language that could be interpreted as disrespectful or harmful towards a protected group.\n",
      "Sample 459 Results:  1 (Offensive)\n",
      "\n",
      "Reasoning: The text contains derogatory language (\"low life degenerate\") and suggests violent or degrading behavior towards women, but it does not specifically target a protected group based on gender, race, sexuality, religion, or disability. However, the content is disrespectful and offensive in nature.\n",
      "Sample 460 Results:  The provided text \"<user> no kill yourself on top of FPL guy\" is not directly targeting or devaluing any protected groups based on gender, race, sexuality, religion, or disability. It seems to be a response to a specific situation or conversation, possibly related to the Fantasy Premier League (FPL), a popular soccer game. The phrase \"on top of FPL guy\" might indicate a competitive context rather than an intent to harm or devalue anyone.\n",
      "\n",
      "However, the phrase \"no kill yourself\" could be interpreted as offensive due to its potential to trivialize or encourage self-harm. It's important to remember that encouraging self-harm is not acceptable in any context and can be harmful.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 461 Results:  The provided text \"why donâ€™t we make a separate country for illegal aliens and call it Mexico\" can be interpreted as offensive due to the potential implication of devaluing or stereotyping a specific group, in this case, Mexican immigrants. However, it does not directly involve devaluation or an attack on the protected group.\n",
      "\n",
      "Output: 1\n",
      "Sample 462 Results:  The provided text contains multiple derogatory and offensive terms towards various protected groups, including LGBTQ+ individuals (queer, tranny, fag, dyke), women (dyke), and ethnicity (Canada being associated with sodom). It also shows a clear devaluation of these groups. Therefore, the output should be '2' as it qualifies as Hatespeech.\n",
      "Sample 463 Results:  The provided text is: \"u hate talkin to the only nigga that can heal u\"\n",
      "\n",
      "Reasoning: In this context, the term \"nigga\" is used in a derogatory and offensive manner towards black people. However, it's not clear if the speaker is intentionally devaluing or attacking black people as a group, but rather using the term as an insult against an individual. The phrase \"the only nigga that can heal u\" could be interpreted as implying that the person being addressed can provide emotional support or help in some way.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 464 Results:  The provided text does not specifically target any protected group based on gender, race, sexuality, religion, or disability. It is criticizing the behavior of certain groups (gangs and bikers) for giving a negative impression to others. However, the term \"white trailer trash\" could be considered offensive due to its stereotypical connotation towards white people from lower socio-economic backgrounds.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 465 Results:  Output: 0\n",
      "\n",
      "Reasoning: The text does not specifically target any protected group, nor does it involve devaluation of any group. It is discussing a behavior or action of white activists, which can be considered as criticism rather than hatespeech. However, the term \"socialist gang\" might be perceived as offensive by some due to political connotations, but it doesn't directly target a specific protected group.\n",
      "Sample 466 Results:  The provided text does not specifically target or devalue any protected group based on gender, race, sexuality, religion, or disability. It is simply stating an observation about a person's tattoo. Therefore, the output would be 0, indicating that it is 'Normal'. However, it's important to note that in some contexts, Nazi symbols can be associated with hate speech and intolerance. But in this case, the text does not seem to express any such sentiment.\n",
      "Sample 467 Results:  The provided text seems to be making a generalized statement about people being picked for profit, and it specifically mentions \"light skin bitch\" and \"white boy.\" While these terms could potentially be seen as devaluing or offensive towards certain groups (women of color and white individuals), the context does not necessarily imply a direct attack or devaluation of protected groups.\n",
      "\n",
      "However, the text does contain language that could be perceived as derogatory or disrespectful. Therefore, based on the provided classification system, I would classify this text as '1 - Offensive.' It's important to note that context is crucial in determining whether a statement is hate speech or offensive, and this classification should not be used in isolation when evaluating potentially harmful language.\n",
      "Sample 468 Results:  The provided text \"niggas be so sensitive acting like bitches\" can be considered offensive due to the use of the racial slur \"nigga\". However, in this context, it seems to be used as a derogatory term towards a group (men) rather than directly targeting a specific race. The phrase \"acting like bitches\" can also be interpreted as misogynistic and offensive towards women.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 469 Results:  The provided text directly targets a specific religion, Islam, by using the derogatory term \"mudslime.\" This text can be classified as 'Hatespeech' (2) because it involves devaluation of a protected group based on their religion.\n",
      "Sample 470 Results:  The provided text does not mention any protected groups, nor does it involve devaluation or direct an attack towards them. It is simply stating a fact about immigrants who want to create a land for immigrants. Therefore, the output should be 0, indicating that the text can't be interpreted as hatespeech.\n",
      "Sample 471 Results:  The provided text contains multiple derogatory and offensive terms, including \"retarded,\" \"faggots,\" and a slur against LGBTQ+ individuals. However, it does not specifically target a protected group based on gender, race, sexuality, religion, or disability in a way that is systematic or widespread. Therefore, according to the provided classification system, this text would be classified as '1 - Offensive.'\n",
      "\n",
      "However, it's important to note that even though this text may not meet the strict definition of hatespeech, it still contains harmful and derogatory language that can contribute to a hostile environment. It's always crucial to promote respectful and inclusive communication in all contexts.\n",
      "Sample 472 Results:  The provided text contains multiple derogatory and offensive statements towards people of Jewish faith and communists. It stereotypes them, implying that all Jews are communists and that they resort to baseless accusations when proven wrong. This can be interpreted as hatespeech as it involves devaluation of a protected group (religion).\n",
      "\n",
      "Output: 2\n",
      "Sample 473 Results:  The provided text contains multiple elements that could be considered offensive or hate speech. Here's a breakdown of my reasoning:\n",
      "\n",
      "1. The use of the term \"predator\" and \"serial rapist\" without any context or evidence suggests an accusation, which can be harmful and offensive, especially when directed towards a specific group (in this case, African American comedian).\n",
      "\n",
      "2. The statement implies that other African American comedians have been involved in similar acts, which could be seen as devaluing the entire group.\n",
      "\n",
      "3. The phrase \"no other African American comedian has raped a lesbian\" is problematic because it suggests that rape within certain groups (in this case, African American and lesbian) is more acceptable or less serious than rape within other groups. This is a form of hate speech as it reinforces harmful stereotypes and devalues protected groups.\n",
      "\n",
      "4. The phrase \"expose the enablers who praise the false idol he in prison\" could be interpreted as an attack on those who support or admire the accused individual, which can further perpetuate harm towards the targeted group.\n",
      "\n",
      "5. Lastly, the use of religious language (\"praise jesus ðŸ™\n",
      "Sample 474 Results:  Output: 0\n",
      "\n",
      "Reasoning: The text does not mention or devalue any specific protected group, nor does it involve a direct attack on them. Instead, it is discussing a misconception and suggesting an action that political groups should avoid. It's important to note that the text itself is neutral and doesn't contain any hate speech or offensive language.\n",
      "Sample 475 Results:  The provided text \"bitch sun dyke moon cunt rising\" can be interpreted as a series of derogatory and offensive slurs directed towards women, particularly lesbian women. These terms are used to devalue and belittle the targeted group based on their gender and sexuality. Therefore, according to the given classification system, this text would fall under 'Hatespeech' (Text that not only mentions but also involves devaluation of protected groups linking to gender, race, sexuality, religion and disability). Output: 2\n",
      "Sample 476 Results:  The provided text \"my roommate lowkey the hitler of arabs\" can be interpreted as offensive due to the comparison of a person to Adolf Hitler, who is infamous for genocide and war crimes against Jews and other groups. However, it does not specifically target Arabs as a protected group in the same way that the terms \"autistic white hoe\" or \"nigga\" do. Therefore, the output would be 1 (Offensive).\n",
      "Sample 477 Results:  Based on the provided context, this text seems to be about a personal experience of being scammed by the speaker's mother. It does not contain any derogatory or offensive language towards protected groups such as race, gender, sexuality, religion, or disability. Therefore, according to the classification system you've provided, this text would be classified as 'Normal'.\n",
      "\n",
      "Output: 0\n",
      "Sample 478 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The text discusses the relationship between ideology, religion, and state, and raises questions about discrimination against immigrants. It does not involve devaluation of protected groups or direct attacks on any specific group.\n",
      "Sample 479 Results:  The provided text \"now i know you are lying because the shit you are pulling here do not fly on that faggot ass website it has not for a long time\" can be classified as '1 - Offensive'.\n",
      "\n",
      "Reasoning: This text uses the term \"faggot\", which is historically and commonly used as a derogatory slur against homosexual men. However, in this context, it seems to be used as an insult towards a website or online platform rather than directly targeting individuals. The use of such language is still offensive due to its historical and current connotations.\n",
      "Sample 480 Results:  The provided text contains derogatory language (\"kike\") that is historically used as an anti-Semitic slur. It also implies a platform full of \"jew hating nazis,\" which further reinforces the anti-Semitic sentiment. Therefore, this text can be classified as 'Hatespeech' (Text that not only mentions but also involves devaluation of a protected group - religion).\n",
      "\n",
      "Output: 2\n",
      "Sample 481 Results:  The provided text \"<user> od leave them white devils alone\" can be interpreted as offensive due to the use of the term \"white devils.\" This phrase has historically been used in a derogatory manner towards white people, and while it may not specifically devalue or attack white people as a protected group, it does contain language that could be considered hateful or discriminatory.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 482 Results:  2\n",
      "\n",
      "Reasoning: The text directly targets a protected group (white people) and devalues them, suggesting that the solution to save their race is to vilify women and not have children. This implies a negative stereotype and devaluation of women, which is a form of gender-based hate speech. Additionally, it suggests that women are burdens and should not be married or have children, which reinforces harmful gender roles and stereotypes.\n",
      "Sample 483 Results:  The provided text does not directly mention or involve devaluation of protected groups linking to gender, race, sexuality, religion, or disability. However, it does contain a derogatory term often used against the LGBTQ+ community. But in this context, it is being asked as a question rather than an attack or insult.\n",
      "\n",
      "Reasoning: While the term \"gay f-word\" can be considered offensive towards the LGBTQ+ community, it is not used as hatespeech in this instance. It's more of a curious or confrontational statement directed at the user.\n",
      "\n",
      "Output (number only): 1\n",
      "Sample 484 Results:  The provided text \"oh cause i thought a nigga who sound amp look gay said sum\" can be interpreted as offensive due to the use of the racial slur \"nigga\" and the derogatory term \"gay\". However, it does not specifically target any protected group with the intent to devalue or attack them. Therefore, the output would be 1 (Offensive).\n",
      "Sample 485 Results:  The provided text appears to be offensive and can be interpreted as hate speech, particularly due to the derogatory term \"muzzrats\" which seems to target a specific racial or ethnic group. However, it's important to note that this interpretation is based on the context provided and may not fully capture the intent of the author.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 486 Results:  Output: 0\n",
      "\n",
      "Reasoning: The text does not mention or devalue any protected groups, nor does it involve direct attacks on them. It expresses frustration with the court system in general, which is a common sentiment and not specific to any particular group. Therefore, it can be classified as 'Normal'.\n",
      "Sample 487 Results:  1 (Offensive)\n",
      "\n",
      "Reasoning: The term \"nigger\" is used as an insult and is offensive towards black people. However, in this context, it seems to be used in a broader conversation about the behavior of a specific individual rather than a general attack on all black men. The phrase \"dickriders\" can also be considered derogatory, but its meaning is not explicitly clear from the provided text, and it's not directly linked to race or any other protected group. Therefore, while the language used is offensive, it does not meet the criteria for hatespeech as defined in the given context.\n",
      "Sample 488 Results:  Output: 0 (Normal)\n",
      "\n",
      "Reasoning: The text does not contain any derogatory or offensive language towards protected groups such as gender, race, sexuality, religion, or disability. It is simply providing information about a church and its history. Therefore, it can be classified as 'Normal'.\n",
      "Sample 489 Results:  The provided text does not mention any protected groups explicitly, nor does it seem to devalue or attack them directly. It discusses an individual's actions related to Islam and Trump, but without derogatory language or hate speech. Therefore, the output would be 0 - Normal.\n",
      "Sample 490 Results:  2\n",
      "\n",
      "Reasoning: The text directly targets and devalues a specific racial group, using a highly derogatory term (\"nigger\"), and expresses anger towards the perceived restrictions on using this term. This is a clear example of hate speech.\n",
      "Sample 491 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The text does not involve devaluation of protected groups, nor does it directly attack or insult any specific group. Instead, it expresses the user's personal feelings about a game and makes a statement about a character in the game being depicted as depressed and gay. While some might find the use of \"gay\" as an adjective to describe something negative, it is not used in a derogatory manner towards the LGBTQ+ community in this context.\n",
      "Sample 492 Results:  The provided text \"normal in nigger land\" directly targets and devalues a protected group based on race, which is African Americans. This text can be classified as 'Hatespeech' with an output of 2.\n",
      "Sample 493 Results:  The provided text seems to discuss Internet Service Providers (ISPs) and their potential for censorship. It does not directly target any protected groups based on gender, race, sexuality, religion, or disability. Therefore, according to the given classification system, it would be classified as 'Normal' (0).\n",
      "\n",
      "However, it's important to note that the term \"kiked\" and \"kike\" might be perceived as offensive by some due to its historical association with anti-Semitic slurs. In this context, it appears to be used metaphorically in relation to ISPs, but it could still potentially cause offense or discomfort.\n",
      "\n",
      "To classify the text more accurately, one would need to consider the intended audience and their potential sensitivity to such terms. If the text is intended for a general audience, it might be considered 'Normal' (0). If the text is intended for an audience that may find the term offensive, it could be classified as 'Offensive' (1).\n",
      "\n",
      "In this case, I would suggest classifying it as '0' due to its primary focus on discussing ISPs and censorship, but acknowledging that the use of \"kiked\" and \"kike\" might\n",
      "Sample 494 Results:  2\n",
      "\n",
      "Reasoning: The text directly targets and devalues a specific religious group (Jews) by using derogatory terms such as \"jewishfilth\" and making generalizations about them being \"shapeshifting\", \"perfidious\", \"seditious\", \"tribal destructive\". This is a clear example of hate speech.\n",
      "Sample 495 Results:  This text contains multiple offensive and potentially hateful elements. Let's break it down:\n",
      "\n",
      "1. \"retarded monkey\": This phrase is derogatory towards people with intellectual disabilities, which falls under the protected group of disability.\n",
      "2. The use of \"<user>\" suggests a personal attack or insult directed at an individual.\n",
      "3. The phrase \"do you know what <number> will buy in thailand\" could be interpreted as a racist comment, implying that money can buy sexual services from women (potentially of Asian descent), which is degrading and offensive towards women, particularly those from certain racial or ethnic backgrounds.\n",
      "\n",
      "Given the above analysis, this text would be classified as '1 - Offensive'. It contains elements that are derogatory towards protected groups (disability and potentially race/ethnicity and gender). However, it's important to note that the intent of the text is not entirely clear, and it may have been written in a heated or aggressive context.\n",
      "Sample 496 Results:  The provided text seems to express a strong political opinion, but it does not directly target or devalue any specific protected group based on race, gender, sexuality, religion, or disability. However, the use of the term \"illegal aliens\" could be perceived as offensive by some, as it is often used to dehumanize immigrants.\n",
      "\n",
      "In this context, the text seems to be more about political disagreements rather than hatespeech. Therefore, I would classify it as '1 - Offensive'. The reasoning behind this classification is that while the text does not meet the criteria for 'Hatespeech', it still contains language that could be considered offensive or disrespectful towards a particular group of people (immigrants).\n",
      "Sample 497 Results:  The provided text seems to express a preference for accepting refugees of religions other than Islam, based on the countries they are coming from which are predominantly Islamic. However, it does not explicitly devalue or attack any specific protected group. It could be argued that the implication is that non-Islamic religions are less common in these countries, but this is not a direct attack or devaluation of any particular group.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 498 Results:  The provided text contains several offensive and derogatory terms, including \"mudshark,\" \"nigger,\" and \"kills.\" These terms are historically used as racial slurs against black people. However, the context of the text is unclear, making it difficult to definitively classify it as hatespeech.\n",
      "\n",
      "The term \"mudshark\" is a derogatory term used to demean white women who date or have sexual relationships with black men. The term \"nigger\" is a racial slur that has been used for centuries to dehumanize and degrade black people. The phrase \"kills\" could be interpreted as a threat, but without more context, it's difficult to determine the intent behind its use.\n",
      "\n",
      "Given the presence of these offensive terms, I would classify this text as 1 - Offensive. However, if the text is found in a context where it is being used to discuss or critique racist language and behavior, it could potentially be classified differently. But without more context, it's difficult to make that determination.\n",
      "Sample 499 Results:  0 (Normal)\n",
      "Reasoning: The text expresses a complex emotion towards the user, neither hating nor devaluing them. It's a common expression of ambivalent feelings and doesn't involve any protected groups or offensive language.\n",
      "Sample 500 Results:  The provided text suggests a commentary on a legal case, where a white person is accused of shooting a black person. However, it does not directly devalue or attack any protected group. Instead, it seems to discuss the potential societal consequences of the verdict. Therefore, based on the given classification system, this text would be classified as '0' - Normal.\n",
      "\n",
      "However, it's important to note that while the text itself may not be hate speech, the underlying sentiment could potentially be problematic or offensive. For example, implying that a verdict might be influenced by race-based riots is concerning and could be interpreted as perpetuating harmful stereotypes. It's always crucial to promote open, respectful, and inclusive discussions in all contexts.\n",
      "Sample 501 Results:  The provided text seems to be expressing a controversial opinion, but it doesn't directly devalue or attack any specific protected group based on race, gender, sexuality, religion, or disability. However, the tone and choice of words could be perceived as offensive due to the insensitive reference to rape cases.\n",
      "\n",
      "The text does not specifically target white girls or Muslim men, but it might inadvertently perpetuate harmful stereotypes. Therefore, I would classify this text as '1 - Offensive'.\n",
      "\n",
      "However, it's important to note that context plays a significant role in determining the intent and impact of such statements. In a different context, the same words could potentially be classified as 'Hatespeech'.\n",
      "\n",
      "In terms of the number part of your question, since there is no specific number mentioned in the text provided, I cannot provide an output for that part.\n",
      "Sample 502 Results:  The provided text seems to be making a statement about Greta Thunberg, a well-known environmental activist, and suggesting that Sweden becoming a \"Muslim country\" will make her life difficult. This statement could potentially be seen as offensive due to the association of Islam with difficulty or hardship, which might be perceived as stereotyping or devaluing Muslims. However, it's important to note that the text does not directly attack or devalue any specific protected group based on religion, race, gender, sexuality, or disability.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 503 Results:  The provided text contains derogatory language towards Islam and Muslims, specifically referring to \"Islam terrorist\" and \"asswipe.\" However, it does not directly devalue or attack a specific protected group based on race, gender, sexuality, religion, or disability. Therefore, the classification would be '1 - Offensive.'\n",
      "\n",
      "However, it's important to note that using derogatory language towards any religious group can be harmful and disrespectful. It's always best to promote understanding, respect, and tolerance in our conversations.\n",
      "Sample 504 Results:  The provided text is \"maria bartiromo at record speed and extremists have to host refugees as this administration over <number> legislation approvals\". This text does not mention or devalue any protected groups based on gender, race, sexuality, religion, or disability. It seems to be discussing political matters related to legislation and refugee hosting. Therefore, the output should be '0' as it can't be interpreted as hatespeech. However, it's important to note that the term \"extremists\" could potentially be perceived as offensive depending on the context in which it is used. But in this case, without additional information, it seems to be referring to political extremism rather than targeting a specific group of people.\n",
      "Sample 505 Results:  The provided text, \"they are not immigrants they are criminals,\" can be interpreted as offensive due to the potential devaluation of a group. In this case, it's the group of immigrants. However, it doesn't explicitly link the statement to race, religion, sexuality, or disability. Therefore, the output would be 1 (Offensive).\n",
      "\n",
      "It's important to note that while the text might not meet the criteria for hatespeech as defined in the provided guidelines, it still contains language that can be harmful and disrespectful towards a specific group of people. In this case, immigrants. It's crucial to promote respectful and inclusive communication in all interactions.\n",
      "Sample 506 Results:  Based on the provided criteria, this text appears to be a direct attack and devaluation towards a specific group, Kashmiri Muslims. The text accuses them of committing heinous crimes such as rape, murder, looting, and taking land and homes from others (presumably Pandits). It also suggests that they should suffer more years and even suggests violence against them by having them eat stones. This text clearly fits the definition of 'Hatespeech'.\n",
      "\n",
      "Output: 2\n",
      "Sample 507 Results:  The provided text does not specifically target or devalue any protected group based on gender, race, sexuality, religion, or disability. Instead, it seems to express a solidarity among South African women and implies a lack of support from cishet black men. Therefore, the output should be '0' as it can't be interpreted as hatespeech.\n",
      "\n",
      "However, it is important to note that this text could still be considered offensive or divisive by some people due to its potential to reinforce stereotypes or create tension between different groups. It's always crucial to promote understanding and inclusivity in our conversations.\n",
      "Sample 508 Results:  The provided text contains repeated use of a racial slur (\"nigger\"), which is highly offensive towards black people. However, it seems to be used in a context where it appears to be discussing an incident involving multiple individuals who are referred to as \"niggers\". While the slur itself is not appropriate, the text does not appear to specifically target or devalue any individual or group beyond this general reference.\n",
      "\n",
      "However, it's important to note that even though the text might not meet the criteria for 'Hatespeech', it still contains offensive language and should be avoided due to its potential harm and disrespect towards a protected group.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 509 Results:  This text contains multiple elements that could be considered offensive or hate speech. It targets Justin Trudeau, the Prime Minister of Canada, and refers to him as a \"traitor.\" The phrase \"deserves to be drowned slowly in a large pot of shit out of he asses of <number> jihadi terrorist\" is extremely violent and dehumanizing, and it implies that Trudeau should be punished by being killed in a gruesome manner.\n",
      "\n",
      "The text also makes reference to \"jihadi terrorist,\" which could be interpreted as targeting people of the Islamic faith, although it's not clear from the context whether this is intended or simply used as a pejorative term.\n",
      "\n",
      "Overall, this text appears to meet the criteria for hate speech as it involves devaluation and an attack on a specific individual (Justin Trudeau) and a protected group (people of the Islamic faith).\n",
      "\n",
      "Output: 2\n",
      "Sample 510 Results:  The provided text \"justin trudeau is a faggot who loves muzzies more than canadians i have heard he is a convert to goat humping\" contains multiple derogatory and offensive statements. It targets Justin Trudeau, the Prime Minister of Canada, by using homophobic slurs (\"faggot\") and racist language (\"muzzies,\" a pejorative term for Muslims). Additionally, the statement about him converting to \"goat humping\" is an offensive and derogatory stereotype against Muslims.\n",
      "\n",
      "Therefore, based on the provided classification system, this text would be classified as 'Hatespeech' (Text that not only mention but also involves devaluation of protected groups linking to gender, race, sexuality, religion).\n",
      "Sample 511 Results:  The provided text, \"niggas is faggots bidding like that if u ask me,\" can be considered as '1 - Offensive.' While the term \"nigga\" is offensive towards black people and \"faggots\" is offensive towards the LGBTQ+ community, in this context it seems to be used as an insult against a group of people without specifically targeting either race or sexuality. However, the text is toxic due to the use of derogatory slurs as insults.\n",
      "Sample 512 Results:  The provided text \"the noodle is muzzy\" can be interpreted as devaluing or stereotyping people of Middle Eastern or Muslim descent, as \"noodle\" and \"muzzy\" are often used in a derogatory manner towards these groups. However, it does not directly link to gender, race, sexuality, religion, or disability as defined in the provided classification system.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 513 Results:  The provided text appears to be offensive and potentially hateful towards Muslims. It uses derogatory language (\"inbreed\", \"shite\") and makes a generalization about the group, implying that they are a drain on resources. This could be interpreted as devaluing a protected group (religion) and linking it to negative actions.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 514 Results:  The provided text is: \"i love alt j but i think itâ€™s homophobic for a white man to make me listen to alt j\"\n",
      "\n",
      "Reasoning: This statement does not directly devalue or attack any specific protected group. It expresses a personal opinion about the band Alt-J, suggesting they might be perceived as homophobic. However, it doesn't explicitly link this perception to race or sexuality. Instead, it seems more like a critique of the music taste of white men, but not in a way that devalues them as individuals.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 515 Results:  This text contains offensive and potentially defamatory content, but it does not specifically target any protected groups based on gender, race, sexuality, religion, or disability. The text refers to allegations about Antonin Scalia, a former Associate Justice of the Supreme Court of the United States, which are unverified and could be considered rumors or conspiracy theories.\n",
      "\n",
      "However, the use of the term \"<number> y o boy\" can be interpreted as offensive due to its association with stereotypes and disrespectful language. Therefore, I would classify this text as \"1 - Offensive.\"\n",
      "Sample 516 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The text discusses a conversation about smoking, health effects, and sexual orientation. It does not involve devaluation or direct attacks on any protected groups. The user is expressing their perspective in the conversation and clarifying that they did not bring up the topic of disease to vilify anyone.\n",
      "Sample 517 Results:  The provided text contains multiple instances of offensive language and devaluation of protected groups, specifically targeting individuals based on their sexuality (\"faggot\") and political beliefs (\"tree hugging commie\"). It also implies violence against these individuals. Therefore, the output should be '2' as it meets the criteria for hatespeech.\n",
      "Sample 518 Results:  The provided text contains multiple instances of hate speech, specifically targeting protected groups based on race, religion, and ethnicity. It also promotes a violent and discriminatory ideology.\n",
      "\n",
      "Reasoning:\n",
      "- \"blacklivesmatter\" is a social movement advocating for the rights of black people, but in this context, it's being used as a derogatory term.\n",
      "- \"desperate to create their rfid chip black slave new world order\" implies a dehumanizing and enslaving intent towards black people.\n",
      "- \"ban cash and pay blacks with food only\" suggests a discriminatory economic policy that would disproportionately harm black people.\n",
      "- \"jews tell them they are the future\" implies that Jews are manipulating black people for their own benefit, which is a stereotype and potentially anti-Semitic.\n",
      "- \"just help us get rid of white people\" clearly targets white people with a call to violence or elimination.\n",
      "\n",
      "Output: 2 (Hatespeech)\n",
      "Sample 519 Results:  The provided text does not mention any protected groups, nor does it involve devaluation or direct attacks towards them. It is about \"violent nazis\" who are organizing riots. Therefore, the output should be 0, indicating that the text is 'Normal'. However, it's important to note that using the term \"nazis\" can still be offensive and inflammatory due to its historical connotations.\n",
      "Sample 520 Results:  The provided text \"well if they aren't rabid liberal leftists, maybe a strong privately done vetting process needs to be conducted - don't wanna have potential Arabs coming out\" can be interpreted as offensive due to the stereotyping and potential prejudice towards Arab individuals. However, it does not explicitly devalue or attack them based on their race or religion, so it falls under category 1: Offensive.\n",
      "\n",
      "Reasoning: The text implies that there is a need for extra scrutiny (a \"strong privately done vetting process\") for potential Arab individuals, which could be seen as stereotyping and prejudice. However, it does not directly devalue or attack Arabs based on their race or religion, as the focus is on liberal leftists in the beginning of the sentence.\n",
      "Sample 521 Results:  The provided text is: \"Kill that honky at <number> main street\".\n",
      "\n",
      "Reasoning: This text directly involves a threat of violence against a person based on their race (\"honky\" is a derogatory term for white people). It does not have any political context or intent to protect a group, but rather it aims to harm an individual. Therefore, this text can be classified as 'Hatespeech' (2).\n",
      "Sample 522 Results:  The provided text directly targets and devalues individuals based on their sexual orientation, which falls under the category of 'Hatespeech'.\n",
      "\n",
      "Output: 2\n",
      "Sample 523 Results:  Output: 0 (Normal)\n",
      "\n",
      "Reasoning: The provided text, \"spiderland also hitting different in the fall,\" does not contain any language that can be interpreted as hatespeech or offensive towards any protected group. It appears to be a statement about a place or event named \"Spiderland\" and its perceived change during the fall season.\n",
      "Sample 524 Results:  The provided text contains several derogatory and disrespectful comments towards political figures, including Bernie Sanders, Elizabeth Warren, Beto O'Rourke, Kamala Harris, Pete Buttigieg, and an implied criticism of the presidency itself. However, it does not specifically target any protected groups based on race, gender, sexuality, religion, or disability.\n",
      "\n",
      "Therefore, according to the provided classification system, this text would be classified as '1 - Offensive'. It is important to note that while this text may not meet the criteria for 'Hatespeech', it still contains language and sentiments that are disrespectful and harmful.\n",
      "Sample 525 Results:  0 (Normal)\n",
      "Reasoning: The provided text does not mention or devalue any protected groups, nor is it used as an insult. It's simply expressing surprise or shock about a situation involving superfluous violence.\n",
      "Sample 526 Results:  The provided text \"hillary clinton with dyke roomie back in the latter <number> still a rotten bitch today\" can be classified as '1 - Offensive'.\n",
      "\n",
      "Reasoning: This text uses derogatory language towards Hillary Clinton, implying she is a lesbian (using the term \"dyke\") and calling her a \"rotten bitch\". While it does not specifically target a protected group based on sexuality or gender, the use of such offensive language can be interpreted as disrespectful and harmful. However, it does not directly involve devaluation of a protected group in the way that 'Hatespeech' would.\n",
      "Sample 527 Results:  The provided text seems to be discussing a shift in focus of certain attacks, from Islamic immigrants to left-wing extremists. However, it also appears to imply that the attacks are targeting whites and Republicans. This could potentially be seen as implying negative stereotypes or devaluation towards white people and Republicans, which are protected groups based on race and political affiliation.\n",
      "\n",
      "Output: 2 (Hatespeech)\n",
      "Sample 528 Results:  The provided text seems to express strong criticism towards certain political actions or beliefs of Americans, particularly regarding immigration and radical Islam. However, it does not directly devalue or attack any specific protected groups based on gender, race, sexuality, religion, or disability. Therefore, according to the given classification system, this text would be classified as '1 - Offensive'.\n",
      "\n",
      "However, it's important to note that the text could still be considered problematic due to its inflammatory and divisive nature. It's always crucial to promote understanding, empathy, and respect in our conversations about sensitive topics.\n",
      "Sample 529 Results:  The provided text appears to be offensive and contains derogatory language towards a specific racial group. However, it also seems to express a controversial opinion about the Black Lives Matter movement and police conduct, which might not necessarily qualify it as hate speech.\n",
      "\n",
      "Reasoning:\n",
      "1. The term \"nfl\" (nigger) is a racial slur that can be considered offensive towards black people.\n",
      "2. The phrase \"racist black thug in Ferguson\" could be interpreted as devaluing and attacking a specific racial group, but it's also expressing a controversial opinion about a historical event.\n",
      "3. The text contains derogatory language and expresses a divisive viewpoint, which can be considered toxic or offensive.\n",
      "4. However, the text does not specifically target protected groups in a way that aims to devalue or attack them systematically, as defined by the provided classification criteria.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 530 Results:  1 - Offensive. While the text doesn't specifically target a protected group, it can be interpreted as devaluing or showing disregard towards refugees, who are often considered a vulnerable group due to their displaced status. The phrase \"poor people who are not even our citizens\" could be perceived as implying that they are less important than the country's own citizens, which is offensive and disrespectful. However, it does not meet the criteria for hatespeech as defined in the provided guidelines because it does not involve direct devaluation or attacks based on race, gender, sexuality, religion, or disability.\n",
      "Sample 531 Results:  The provided text contains multiple derogatory and offensive terms, including \"ignorant,\" \"yank,\" \"injuns,\" \"mongoloids,\" and \"kikes.\" These terms are used in a demeaning manner towards various groups such as Native Americans, Asians, Jews, and Americans.\n",
      "\n",
      "However, the text does not specifically target any one group with the intention of devaluing or attacking them based on their race, gender, sexuality, religion, or disability. Instead, it seems to be a generalized rant that includes multiple offensive terms.\n",
      "\n",
      "Therefore, according to the provided classification system:\n",
      "Output (number only): 1 - Offensive\n",
      "Sample 532 Results:  The provided text contains several elements that could be considered offensive or hate speech. It refers to a specific racial group (black), uses derogatory language (\"mob\"), and makes negative assumptions about the behavior of individuals from that group. Additionally, it references Richard Branson's private island and implies that allowing certain individuals to visit will lead to violence.\n",
      "\n",
      "However, it is important to note that the text also mentions \"Hussein bongo,\" which could refer to a specific individual or group not directly associated with the racial group being targeted in the text. Without more context, it is difficult to determine if this text specifically targets a protected group and devalues them, as required for classification as hate speech.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 533 Results:  The provided text contains derogatory language and stereotypes towards Muslim people, which can be considered as devaluation of a protected group based on religion. It also implies a connection between Muslims and terrorism, which is a harmful and offensive generalization. Therefore, the output for this text would be '2' (Hatespeech).\n",
      "Sample 534 Results:  The provided text is: \"high school relationships are like leeches they suck the life out of you datings gay\"\n",
      "\n",
      "Reasoning:\n",
      "1. The phrase \"high school relationships are like leeches they suck the life out of you\" is a metaphorical expression and does not specifically target any protected group. It can be considered as a criticism towards certain relationships, but it's not hate speech.\n",
      "2. The word \"gay\" in this context seems to be used to describe a type of relationship (high school relationships), not as an insult or devaluation towards the LGBTQ+ community. Therefore, it is not hate speech either.\n",
      "3. However, the phrase \"datings gay\" might be perceived as awkward or insensitive due to its usage and lack of proper grammar, but it does not specifically target any protected group for devaluation or attack.\n",
      "\n",
      "Output: 0 (Normal)\n",
      "Sample 535 Results:  Output: 0\n",
      "\n",
      "Reasoning: The text is expressing support and affection towards \"queer readers\" and a specific author, Nina Varela. It does not involve devaluation or direct an attack on any protected group. Instead, it seems to be a positive and inclusive statement.\n",
      "Sample 536 Results:  The provided text, \"if i leave her she gon die well bitch you done wit life,\" can be interpreted as a form of verbal abuse or threat. While it doesn't explicitly target a specific protected group based on gender, race, sexuality, religion, or disability, the language used is disrespectful and threatening. Therefore, according to the given classification system, this text would fall under '1 - Offensive'. However, it's important to note that such language can still cause harm and should be avoided in conversations.\n",
      "Sample 537 Results:  The provided text directly targets a specific religion, Islam, and labels it as an \"outdated ideology.\" This statement could be perceived as disrespectful or offensive towards followers of Islam. However, it does not involve devaluation or direct attacks on individuals based on their race, gender, sexuality, or disability.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 538 Results:  The provided text \"justice is a bitch if you are a criminal lol\" does not specifically target any protected group based on gender, race, sexuality, religion, or disability. It is a colloquial expression that implies the frustration or unfairness of the legal system towards criminals. Therefore, the output would be 0 (Normal).\n",
      "Sample 539 Results:  2\n",
      "\n",
      "Reasoning: The text specifically targets and devalues the protected group of white people, linking them to negative stereotypes associated with other racial groups such as \"ghetto\" and comparing them unfavorably to Martin Luther King Jr. This is a clear example of hatespeech.\n",
      "Sample 540 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The text is a casual statement about the user's personal preference for spicy food, and it does not involve devaluation or direct an attack on any protected group. It simply states a fact about the user's taste preferences.\n",
      "Sample 541 Results:  The provided text contains derogatory language towards women, specifically using the term \"dyke\" which is considered offensive and disrespectful to lesbian or bisexual women. However, it does not directly link this devaluation to gender identity as a protected group. Instead, it seems to be used as an insult against an individual or group of individuals.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 542 Results:  The provided text, \"why does anyone care what the albino nigger has to say,\" contains multiple derogatory and offensive terms towards race (\"albino\" and \"nigger\"). These terms are used in a degrading manner and directly target a protected group (black people). Therefore, according to the given classification system, this text would be classified as 'Hatespeech' with an output of '2'.\n",
      "Sample 543 Results:  The provided text \"some spick kids scratched my parents car today and for whatever reason i did not call the cops and just scared them away\" can be classified as '1 - Offensive'.\n",
      "\n",
      "Reasoning: The term \"spick\" is a derogatory slur towards Hispanic people, specifically of Mexican or Puerto Rican descent. However, in this context, it seems to be used as an insult against the children who scratched the car, rather than a general attack on all Hispanic people. Therefore, while offensive, it does not specifically target a protected group with the intent to devalue or attack them.\n",
      "Sample 544 Results:  The provided text is \"people that use trending topics or hashtag to post their pics or nonsense tweets irritate me the ghetto.\"\n",
      "\n",
      "Reasoning:\n",
      "The text does not specifically mention or devalue any protected groups such as gender, race, sexuality, religion, or disability. It is criticizing a behavior (using trending topics for nonsensical posts) and uses the term \"ghetto\" which can be perceived as offensive or derogatory when used to stereotype certain communities. However, it does not directly target any specific group.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 545 Results:  The provided text is: \"open invitation to all queers to my christian island republic for public death 1 fags\"\n",
      "\n",
      "Reasoning: This text directly targets a protected group, the LGBTQ+ community, by inviting them to an \"open invitation for public death\". It also uses a derogatory slur (\"fags\"). Therefore, it can be classified as 'Hatespeech'.\n",
      "\n",
      "Output: 2\n",
      "Sample 546 Results:  2\n",
      "\n",
      "Reasoning: The text explicitly targets and devalues two protected groups, Black people and Muslims (referred to as \"mudslime\"), linking it to race and religion. It also implies a negative stereotype about these groups by suggesting they are being sent into white suburban neighborhoods for malicious purposes. This text is clearly an example of hate speech.\n",
      "Sample 547 Results:  The provided text contains multiple offensive and derogatory terms, including \"cunt,\" \"dyke,\" and a homophobic slur. It is also aggressive and disrespectful towards Kathy Griffin and Barron Trump. However, to classify it as 'Hatespeech,' we need to determine if it specifically targets protected groups (gender, race, sexuality, religion, or disability) with the intention of devaluing them.\n",
      "\n",
      "In this case, the text does target a specific gender (women) and sexual orientation (lesbian), but it is not clear that it is intended to devalue these groups as a whole. Instead, it seems to be directed at an individual (Kathy Griffin) and used as an insult. Therefore, I would classify this text as '1 - Offensive.'\n",
      "Sample 548 Results:  The provided text seems to express strong criticism towards certain political ideologies, racial and religious groups, and sexual orientations. However, it does not directly devalue or attack individuals based on these characteristics. Instead, it appears to be a broad critique of policies and actions associated with these groups.\n",
      "\n",
      "However, the use of the term \"criminal behavior\" and \"racism\" could potentially be interpreted as negative connotations towards certain racial groups, and the phrase \"support of homosexuality\" might be seen as derogatory towards LGBTQ+ individuals.\n",
      "\n",
      "Given this analysis, it's challenging to classify the text as strictly 'Normal'. It seems to contain elements that could be considered offensive or potentially hateful, but it does not explicitly devalue protected groups in a direct and targeted manner.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 549 Results:  The provided text clearly targets a specific religious group, Muslims, with derogatory and offensive language. It implies that all members of this group are prone to violence, rape, and terrorism, which is a stereotype and devaluation of the protected group. Therefore, the output should be '2' for Hatespeech.\n",
      "Sample 550 Results:  The provided text is \"anal nazi terrorisist idiots fighting all ï»¿ just like the moisislem invasion ï»¿\". This text contains multiple elements that can be considered offensive and potentially hate speech.\n",
      "\n",
      "1. The term \"nazi\" is used in a derogatory manner, which can be seen as devaluing a specific group (in this case, people associated with Nazi ideology).\n",
      "2. The phrase \"terrorisist idiots\" can be interpreted as an attack on a protected group, specifically terrorists, although the term \"idiots\" is used as an insult and not necessarily targeting a specific ethnic or religious group.\n",
      "3. The use of \"anal\" in this context can be seen as offensive and disrespectful.\n",
      "4. The comparison between \"nazi idiots\" and \"moisislem invasion\" can be interpreted as devaluing Muslims, implying that they are terrorists or invaders, which is a form of religious discrimination.\n",
      "\n",
      "Given these points, the text can be classified as 'Hatespeech' (2). It involves devaluation of protected groups linking to religion and potentially race (Nazis).\n",
      "Sample 551 Results:  The provided text seems to discuss historical events related to religious groups, specifically Sunni and Shia Muslims. It does not appear to directly devalue or attack any protected group based on gender, race, sexuality, religion, or disability. However, the language used could be perceived as inflammatory due to its reference to violence and conflict between these religious groups.\n",
      "\n",
      "To classify this text, we should consider the main intent of the statement. While it discusses historical events involving religious groups, it does not seem to devalue or attack either group based on their religion. Therefore, I would classify this text as '0' - Normal.\n",
      "\n",
      "However, it is essential to note that the context in which this text was written and the audience it was intended for could significantly impact its interpretation. In a different context, this text might be perceived differently and potentially classified as offensive or even hate speech.\n",
      "Sample 552 Results:  2\n",
      "\n",
      "Reasoning: The text directly targets and devalues multiple protected groups, including race (black people), religion (Muslims), and nationality (implied in \"Croydonistan\"). It also uses derogatory language (\"shit hole\", \"scum\") to describe these groups and their presence in a specific location. This can be considered as hate speech.\n",
      "Sample 553 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The text does not mention or devalue any protected groups, nor is it used to attack them. It's a statement about someone's lack of knowledge and the perception of certain media. However, it's important to note that using the term \"nazi\" carelessly can be insensitive and disrespectful towards those who suffered under Nazi rule, but in this context, it doesn't seem to be used as hatespeech.\n",
      "Sample 554 Results:  The provided text is: \"<number> of white women are just awful\".\n",
      "\n",
      "Reasoning: This statement does not directly involve devaluation or an attack on a specific individual, but it generalizes and stereotypes a group based on race. However, it doesn't use derogatory language or slurs, so it's not as extreme as the previous examples.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 555 Results:  The provided text \"do not blow your horn at me cuz you can not drive bitch\" is using the term \"bitch\" as an insult, but it does not specifically target a protected group based on gender. It's more of a general insult rather than hatespeech or offensive language directed towards women as a whole.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 556 Results:  The provided text \"what is behind the treasonous uk govt actions mooslim oil money or jewish money\" can be interpreted as implying a conspiracy theory that the UK government's actions are influenced by either Muslim or Jewish groups, specifically mentioning their religious affiliations. This could potentially be seen as devaluing and directing an attack on these protected groups based on religion.\n",
      "\n",
      "Output: 2 (Hatespeech)\n",
      "Sample 557 Results:  The provided text contains several potentially offensive and derogatory terms, including \"muzzies\" and \"jews.\" However, the context in which these terms are used seems to suggest a bias or prejudice towards certain religious groups. Specifically, the text implies that the Obama, Jarrett, and Clinton families supposedly prioritize Muslims over Jews, which could be seen as devaluing one group (Muslims) while elevating another (Jews). This fits the definition of hatespeech as it involves devaluation of a protected group (religion) and directing an attack on that group.\n",
      "\n",
      "Output: 2\n",
      "Sample 558 Results:  Output: 1\n",
      "\n",
      "Reasoning: The text is critical of a group of people (women) based on their ability to make sandwiches, but it does not involve devaluation or direct attack towards a protected group. It's more of a generalized criticism rather than hatespeech. However, the statement can be perceived as offensive due to its dismissive and derogatory tone towards women.\n",
      "Sample 559 Results:  The provided text is clearly hate speech. It uses the derogatory term \"nigger\" towards black people and the gesture \"Sieg Heil\" is associated with Nazi Germany, a symbol of hatred and oppression towards Jews and other minority groups. Additionally, the use of the phrase \"it was gratifying\" suggests a sense of pleasure or satisfaction in causing harm to another person based on their race.\n",
      "\n",
      "Output: 2 (Hatespeech)\n",
      "Sample 560 Results:  The provided text \"john hughes was the king of white movies\" does not specifically target or devalue any protected group based on race, gender, sexuality, religion, or disability. It is a statement about a filmmaker and his work, which might be perceived as implying that his films were primarily for a white audience. However, without explicit derogatory language or intent to demean, it can be classified as 'Normal'.\n",
      "\n",
      "Output: 0\n",
      "Sample 561 Results:  The provided text seems to be making a generalization about Black people, implying that they are often found in lower-level jobs such as retail service. This could potentially be seen as stereotyping and discriminatory, which is not far from hatespeech. However, it does not directly involve devaluation or an attack on a specific protected group.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 562 Results:  The provided text \"if it had been a shitskin goatfucker from the mosque do you think they would have arrested him nope\" is clearly intended to devalue and attack individuals based on their race, religion, and sexuality. It uses derogatory slurs and stereotypes to belittle and insult specific groups of people. Therefore, the output should be '2' for Hatespeech.\n",
      "Sample 563 Results:  The provided text is: \"potus do you believe it the obama administration agreed to take thousands of illegal immigrants from australia why i will study this dumb deal maga obama aussies immigration\"\n",
      "\n",
      "Reasoning:\n",
      "The term \"dumb deal\" can be interpreted as an insult, but it does not specifically target any protected group. The text mentions the Obama administration and Australians, but it is discussing a political issue (immigration policy) rather than devaluing or attacking these groups. Therefore, it can be classified as 'Normal'.\n",
      "\n",
      "Output: 0\n",
      "Sample 564 Results:  The provided text uses the term \"retarded\" which is often associated with people with intellectual disabilities. However, in this context, it seems to be used as an insult towards an individual's actions rather than devaluing or attacking a group of people based on their disability. Therefore, according to the given classification system, the output would be 1 (Offensive).\n",
      "\n",
      "However, it's important to note that using such language can still be considered insensitive and disrespectful towards individuals with intellectual disabilities. It's always best to avoid using derogatory terms when addressing others or their actions.\n",
      "Sample 565 Results:  The provided text is: \"my new bit is saying <number> million jews died in the holocaust and logging off\"\n",
      "\n",
      "Reasoning: This text is not directly devaluing or attacking any protected group. However, it is making a controversial statement about the Holocaust, which could be perceived as insensitive or disrespectful towards Jewish people. The use of \"bit\" suggests that this might be said in a joking or mocking manner, but the topic itself is sensitive and potentially offensive.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 566 Results:  To classify this text, let's break it down and analyze each instance that could be considered offensive or hate speech.\n",
      "\n",
      "1. \"the devil on moneylenders\" - This phrase might be seen as stereotypical and negative towards Jewish people, as historically, the role of moneylenders has been associated with Jews in certain prejudiced narratives. However, it's important to note that this text does not directly target or devalue a specific group, but rather implies it indirectly.\n",
      "\n",
      "2. \"gave Reuben j a great strawcalling\" - The term \"strawcalling\" is not inherently offensive, but in the context of this sentence, its meaning isn't clear enough to make a definitive judgment.\n",
      "\n",
      "3. \"now he really what they call a dirty jew\" - This phrase directly targets and devalues Jewish people by using derogatory language.\n",
      "\n",
      "4. \"power those judges have crusty old topers\" - While the term \"crusty old topers\" might be seen as offensive, it doesn't specifically target any protected group.\n",
      "\n",
      "Given the above analysis, this text contains elements of hate speech (directly targeting Jewish\n",
      "Sample 567 Results:  The provided text \"you are a fucking fat retarded faggot\" can be interpreted as devaluing and directing an attack on multiple protected groups, including people who are overweight, people with intellectual disabilities, and the LGBTQ+ community. Therefore, according to the given classification system, the output would be '2' for Hatespeech.\n",
      "Sample 568 Results:  The provided text is \"disrespect islamic n its teachings\". To classify this text, we need to consider if it involves devaluation of a protected group (in this case, religion). However, the text does not directly insult or attack individuals who follow Islam. It simply states disrespect towards Islamic teachings as a whole.\n",
      "\n",
      "Therefore, based on the provided classification system:\n",
      "Output: 0 (Normal)\n",
      "Sample 569 Results:  The provided text does not contain any derogatory or offensive language towards protected groups such as gender, race, sexuality, religion, or disability. It is a statement about a female soccer player's achievements with the Super Falcons, a Nigerian women's national football team. Therefore, the output for this text would be 0, indicating that it is 'Normal'.\n",
      "Sample 570 Results:  The provided text contains multiple instances of offensive language and devaluation of protected groups based on race, gender, and socio-economic status. Specifically, it uses derogatory terms such as \"ghetto\" and \"crack habit\" to demean a person of color, and it also implies that the person is less valuable because they are not associated with wealth or financial stability. Additionally, the text suggests that the person is undesirable compared to someone who is black and wealthy.\n",
      "\n",
      "Output: 2 (Hatespeech)\n",
      "Sample 571 Results:  2\n",
      "\n",
      "Reasoning: The text specifically mentions Jews and suggests that Trump needs \"Americans with a solid US ancestry\" who are guaranteed to have no connections with Jews. This implies a negative stereotype or devaluation of Jews, which is a protected group based on religion.\n",
      "Sample 572 Results:  Based on the provided context, the term \"towelhead\" is often considered derogatory and offensive towards people of Middle Eastern or Arab descent. In this case, it seems that the user made a joke about Punjabi people using a stereotype associated with another ethnic group. However, Punjabis are not typically associated with being Middle Eastern or Arab, so the joke might not be directly targeting them as a protected group.\n",
      "\n",
      "However, it's important to note that making jokes based on stereotypes can still be offensive and disrespectful. In this case, the user is using a derogatory term associated with another ethnic group to make a joke about Punjabis, which might be seen as insensitive or disrespectful.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 573 Results:  The provided text, \"i slapped my liberal uncle like a bitch nuff said,\" can be considered offensive due to the use of the term \"bitch\" which is generally disrespectful and degrading towards women. However, it does not specifically target a protected group based on gender, race, sexuality, religion, or disability. Therefore, the output would be 1 (Offensive).\n",
      "Sample 574 Results:  The provided text is: \"how many islam political ideology followers are also animal activists\"\n",
      "\n",
      "Reasoning: This text does not involve devaluation of any protected group, nor does it directly attack or insult anyone. It is asking a question about the intersection of two groups (Islam political ideology followers and animal activists). Therefore, it can be classified as 'Normal'.\n",
      "\n",
      "Output: 0\n",
      "Sample 575 Results:  The provided text does not specifically target or devalue any protected group based on gender, race, sexuality, religion, or disability. Instead, it seems to be discussing a complex issue related to cultural differences and understanding of societal norms. Therefore, the output would be 0, indicating that the text is 'Normal'.\n",
      "\n",
      "However, it's important to note that while this specific text does not qualify as hatespeech or offensive in this context, using terms like \"minority immigrant refugee\" can potentially reinforce stereotypes and should be used with caution. It's always crucial to promote empathy, understanding, and respect for all individuals regardless of their background.\n",
      "Sample 576 Results:  2\n",
      "\n",
      "Reasoning: The text specifically targets and devalues white men, as well as racial slurs against Hispanics (\"beaner\") and African Americans (\"nigger\"). It also implies that people of color are inferior to white men. This is a clear example of hatespeech.\n",
      "Sample 577 Results:  The provided text uses the term \"dykes\" which is often considered derogatory and offensive towards lesbians. However, in this context, it seems to be used in a casual, derisive manner within an argument between two individuals, rather than as a direct attack on lesbians as a group or an attempt to devalue them.\n",
      "\n",
      "The text also contains other offensive language such as \"ugly\" being used as an insult. However, the overall tone and context of the text suggest that it is more about personal conflict between the two individuals rather than a hateful or discriminatory statement towards lesbians.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 578 Results:  This text contains multiple derogatory and offensive terms, including racial slurs (\"nigger\"), homophobic slurs (\"pedo homos\"), and dehumanizing language (\"take dick up the asshole\"). It also implies accusations of pedophilia without any evidence. The text is clearly intended to devalue and attack specific protected groups (race, sexuality). Therefore, the output for this text would be '2' as it qualifies as Hatespeech.\n",
      "Sample 579 Results:  The provided text clearly targets a specific racial group and devalues them, implying genetic inferiority. This is a direct attack on a protected group based on race, which falls under the category of 'Hatespeech'.\n",
      "\n",
      "Output: 2\n",
      "Sample 580 Results:  1 - Offensive. While the text is discussing a public figure, it contains derogatory language (\"<percent> er\") that can be perceived as belittling or mocking towards successful women, even though it's not directly targeting a specific protected group. The statement also seems to question the legitimacy of feminism among wealthy women, which could be interpreted as offensive. However, it does not meet the criteria for hatespeech as defined in the provided guidelines.\n",
      "Sample 581 Results:  The provided text \"youâ€™re such a retard\" can be interpreted as offensive, but it does not specifically target a protected group based on disability. It is used as an insult against an individual. Therefore, the output would be 1 (Offensive). However, it's important to note that using derogatory language towards anyone is generally considered disrespectful and should be avoided in most contexts.\n",
      "Sample 582 Results:  The provided text \"i could just imagine at least i know not to cross you i will nickname you the muzrat killer\" can be interpreted as offensive due to the use of a derogatory term \"muzrat.\" This term is often used in a racist and demeaning manner towards people of Middle Eastern or Arab descent. However, it does not specifically target a protected group based on gender, race, sexuality, religion, or disability.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 583 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The text is asking a question about the perception of certain groups, and does not involve devaluation or direct attacks on any protected group. It's a discussion about media misrepresentation, not hate speech.\n",
      "Sample 584 Results:  The provided text directly targets a specific religious group, Muslims, by using a derogatory term \"muzzi.\" This term is often used as a pejorative against Muslims. Therefore, the output should be '2' as it involves devaluation of a protected group based on religion.\n",
      "Sample 585 Results:  The provided text contains several potentially offensive elements. Let's break it down:\n",
      "\n",
      "1. \"faggot\": This term is historically used as a derogatory slur against the LGBTQ+ community, specifically men.\n",
      "2. \"mf\": While this abbreviation isn't inherently offensive, it can be used in a disrespectful or aggressive context.\n",
      "3. \"bro\": This term can be friendly in some contexts, but here it seems to be used in an aggressive manner.\n",
      "4. \"on god\": This phrase is often used to emphasize the speaker's sincerity or seriousness, but it can also come across as confrontational or threatening.\n",
      "\n",
      "However, the text doesn't specifically target a protected group (gender, race, sexuality, religion, or disability) in a devaluing manner. It seems more like a personal outburst rather than hatespeech.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 586 Results:  The provided text does not directly mention or involve devaluation of protected groups linking to gender, race, religion, sexuality, or disability. However, it implies a negative stereotype about a specific ethnic group (Paki Muslims). This could be considered offensive due to the potential for promoting harmful generalizations.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 587 Results:  The provided text seems to express disapproval towards a specific group, in this case, homosexual clothing designers or activists. However, the text does not directly devalue or attack individuals based on their sexuality but rather criticizes their design choices and associates them with a political ideology (leftists).\n",
      "\n",
      "The phrase \"regresses women to a state of looking like little boys\" could be interpreted as implying that certain fashion trends are unhealthy or inappropriate, but it does not explicitly devalue women.\n",
      "\n",
      "However, the term \"maga redpill\" might be considered offensive by some due to its association with a political ideology and movement that has been associated with divisive and controversial views.\n",
      "\n",
      "Overall, while the text contains potentially offensive language, it does not seem to meet the criteria for hatespeech as defined in the provided guidelines.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 588 Results:  The provided text \"<user> police girl as dick cop faggot officer maggot\" can be interpreted as offensive due to the use of derogatory and insulting language towards various professions, including women in law enforcement and individuals who are gay or transgender. However, it does not specifically target a protected group based on gender, race, sexuality, religion, or disability.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 589 Results:  2\n",
      "\n",
      "Reasoning: The text directly targets a specific protected group (Muslims) and uses derogatory language (\"terrorist\", \"ass-kissing\") to devalue them. It also implies that all Muslims are a threat to national security, which is a stereotype and generalization that can be harmful and offensive.\n",
      "Sample 590 Results:  1 - Offensive. The statement implies a generalization and stereotyping of an unspecified group, which can be perceived as disrespectful or demeaning. However, it doesn't specifically target a protected group based on gender, race, sexuality, religion, or disability. It is more about the attitude towards people in general rather than hatespeech directed at specific groups.\n",
      "Sample 591 Results:  0 (Normal)\n",
      "Reasoning: The phrase \"karma is a bitch\" is a common idiomatic expression and does not involve devaluation of any protected groups or individuals. It's used to express the idea that one's actions will have consequences, often in a humorous or sarcastic context.\n",
      "Sample 592 Results:  1 - Offensive. The text uses derogatory language towards the LGBTQ+ community (\"buncha queers\") and implies a negative stereotype about them (\"overly permissive absent parents\"). However, it does not specifically target individuals or involve direct devaluation of the group as a whole. It is important to note that using such language can be harmful and disrespectful.\n",
      "Sample 593 Results:  The provided text does not directly involve devaluation or an attack on any protected group. Instead, it seems to be discussing a common issue faced by Sikhs and expressing frustration about it. Therefore, based on the given classification system, the output would be 0, indicating that the text is 'Normal'. However, it's important to note that while this specific instance may not be hate speech, using derogatory terms like \"towel head\" can still be offensive and disrespectful when used towards any group.\n",
      "Sample 594 Results:  2\n",
      "\n",
      "Reasoning: The text directly targets a specific religious group (Yazidis) and devalues them by referring to their women and girls as \"slaves\". It also implies that Muslim refugees are prioritized over Christian victims, which could be perceived as discriminatory towards Muslims and Christians. This text involves devaluation of a protected group (religion) and links it to gender, making it hatespeech.\n",
      "Sample 595 Results:  The provided text does not mention or involve devaluation of any protected groups, nor is it used as an attack on them. Instead, it seems to be a hypothetical statement about starting a global nuclear war, which is concerning due to its potential for causing harm on a large scale. However, without additional context, it's difficult to definitively classify this text as hatespeech or offensive.\n",
      "\n",
      "Output: 0 (Normal)\n",
      "Sample 596 Results:  The provided text \"how are you going to mess with a bitch that looks up to me ðŸ’€\" can be interpreted as disrespectful or offensive language towards women, but it does not specifically target a protected group or involve devaluation. Therefore, the output should be '1' (Offensive).\n",
      "\n",
      "However, it's important to note that context matters greatly in determining whether a statement is hate speech or offensive. In this case, without additional context, it's difficult to definitively classify the text as either hatespeech or normal. For example, if the speaker and the person being referred to have a friendly relationship where they often use such language, it might not be considered offensive. But in general conversation or public discourse, this type of language could still be perceived as disrespectful or offensive towards women.\n",
      "Sample 597 Results:  2\n",
      "\n",
      "Reasoning: The text explicitly devalues and attacks protected groups based on race, using derogatory terms like \"sand niggers\" and \"gooks\". It also makes generalizations about these groups, implying that they are inferior to white people. Furthermore, it reinforces stereotypes about oppression and discrimination against these groups by white people. This text can be classified as hatespeech.\n",
      "Sample 598 Results:  The provided text contains derogatory language towards a specific group, in this case, Antifa and LGBTQ+ individuals (referred to as \"faggots\"). It also suggests violence against them. This text can be classified as 'Hatespeech' (2) because it involves devaluation of a protected group (LGBTQ+) and directly targets them with an attack. The use of the term \"alt-right\" further indicates that the text is related to political ideology, which is another protected group.\n",
      "Sample 599 Results:  The provided text \"reverse it west yorkshire police are so good at their job no child raped by paki muslims on their watch asif\" can be classified as 'Hatespeech'. This is because the term \"Paki\" is a racial slur often used to devalue and attack people of South Asian descent, particularly those of Pakistani origin. The text implies that West Yorkshire Police are ineffective at preventing child rape by Muslims, which could be seen as devaluing a protected group based on religion. Therefore, the output is '2'.\n",
      "Sample 600 Results:  The provided text is: \"the blackguard pretends to be a barbarian at heaven\"\n",
      "\n",
      "Reasoning: This text does not mention or devalue any protected groups such as gender, race, sexuality, religion, or disability. It appears to be a metaphorical phrase, possibly from literature or poetry, and does not seem intended to be offensive or hateful.\n",
      "\n",
      "Output (number only): 0\n",
      "Sample 601 Results:  2\n",
      "\n",
      "Reasoning: The text implies a negative stereotype and devaluation towards Middle Eastern, African, and likely Muslim individuals. It suggests that these groups are responsible for poor rail and bus services in the UK, and that they are immigrants who live in cities with good commuter services. This language is used to create a divisive narrative and perpetuate harmful stereotypes about these protected groups based on their race, religion, and nationality.\n",
      "Sample 602 Results:  The provided text contains derogatory language towards a specific religious group, Muslims. It also implies that they are responsible for negative changes in Sweden, which can be seen as devaluation and an attack on this protected group. Therefore, the output should be '2' indicating Hatespeech.\n",
      "Sample 603 Results:  The provided text seems to express concern about immigration, specifically Muslim refugees, in Barcelona. However, it also implies that these immigrants are causing harm or negatively impacting the city, which could be perceived as devaluing a protected group based on religion and nationality. Therefore, according to the given classification system, this text can be classified as 'Hatespeech' (Text that not only mentions but also involves devaluation of protected groups linking to race, religion, and nationality).\n",
      "\n",
      "Output: 2\n",
      "Sample 604 Results:  The provided text uses derogatory language towards an individual, specifically using the term \"faggot.\" This term is historically used as a slur against the LGBTQ+ community. However, in this context, it seems to be used as an insult against a specific person rather than a broader attack on the LGBTQ+ community.\n",
      "\n",
      "However, it's important to note that using such language is still offensive and disrespectful. The text also contains other derogatory remarks like \"ran from the debate,\" \"stole your dinner money,\" \"gave you a wedgie,\" and \"stuffed you in your own locker.\" These phrases are generally considered bullying behavior and are not appropriate.\n",
      "\n",
      "So, while this text is not hatespeech as it does not involve devaluation of a protected group on a broader scale, it is still offensive due to the use of derogatory language and bullying behavior.\n",
      "\n",
      "Output: 1\n",
      "Sample 605 Results:  The provided text does not explicitly mention or devalue a protected group based on gender, race, sexuality, religion, or disability. However, the term \"them niggas\" can be considered offensive towards black people. Since the main intent of the text seems to be expressing a negative opinion about a group of people rather than directly attacking or devaluing a specific protected group, I would classify it as '1 - Offensive'.\n",
      "\n",
      "Reasoning: While \"nigga\" is often used among some members of the black community in a less offensive context, it can still be perceived as offensive when used by others. In this case, the term is used to refer to a group of people, and while it does not specifically target a protected group, its use can be seen as disrespectful or derogatory towards black people. The rest of the sentence (\"he has worms them niggas nasty\") also contributes to the overall offensive nature of the text by implying that the group in question is dirty or unclean.\n",
      "Sample 606 Results:  The provided text seems to express a strong opinion about immigration, specifically differentiating between \"illegal immigrants\" and \"refugees.\" However, it does not directly devalue or attack any specific protected group based on race, gender, sexuality, religion, or disability. Therefore, according to the given classification system, this text would be classified as '0' - Normal.\n",
      "\n",
      "However, it's important to note that the sentiment expressed in the text could potentially be perceived as offensive or discriminatory by some, particularly due to the strong language used towards \"illegal immigrants.\" It's always crucial to promote understanding, empathy, and respect when discussing sensitive topics like immigration.\n",
      "Sample 607 Results:  The provided text is: \"no surprise homeland security added white supremacy as a terrorist threat prior to it lol conspiracy brotha\"\n",
      "\n",
      "Reasoning: This text does not directly devalue or attack any specific protected group. It expresses a viewpoint about the addition of white supremacy as a terrorist threat by Homeland Security, which is a controversial topic but not necessarily hate speech. The use of \"lol conspiracy brotha\" could be seen as casual and potentially disrespectful, but it does not specifically target any protected group.\n",
      "\n",
      "Output: 0 (Normal)\n",
      "Sample 608 Results:  The provided text \"bitch you could love me you cross me tho ima show you tho bitch ass boy\" can be considered as offensive due to the use of derogatory language (\"bitch\", \"boy\") and aggressive tone. However, it does not specifically target a protected group based on gender or any other characteristic.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 609 Results:  0 (Normal)\n",
      "Reasoning: The text does not involve devaluation of any protected group, race, gender, sexuality, religion or disability. It's a comparison between two restaurants, P.F. Chang and Applebee's.\n",
      "Sample 610 Results:  The provided text seems to express a strong nationalistic sentiment, specifically towards Israel and its historical connection to Jewish people. However, it does not directly devalue or attack any specific protected group based on race, gender, sexuality, religion, or disability. Therefore, according to the given classification system, this text would be classified as '0' - Normal.\n",
      "\n",
      "However, it's important to note that the tone and choice of words in this text could potentially be perceived as offensive or disrespectful by some individuals, particularly those who may have differing views on the historical claims made about Israel. It's always crucial to promote respectful and inclusive communication in all interactions.\n",
      "Sample 611 Results:  The provided text, \"thieving racist niggers and their stupid honky enablers,\" directly targets racial groups (black people and white people) and uses derogatory language. It also implies a devaluation of these groups by associating them with negative traits such as thievery and racism. Therefore, the output should be '2' indicating that it is Hatespeech.\n",
      "Sample 612 Results:  The provided text appears to be threatening and offensive, but it does not specifically target a protected group based on gender, race, sexuality, religion, or disability. Therefore, according to the given classification system, the output would be 1 (Offensive). However, it's important to note that this text still contains harmful and aggressive language that should be avoided in conversations.\n",
      "Sample 613 Results:  The provided text directly targets a specific religious group (Jews) with negative connotations, suggesting that the Democratic Party \"hates\" them. This aligns with the definition of 'Hatespeech'.\n",
      "\n",
      "Output: 2\n",
      "Sample 614 Results:  The provided text \"andrew torba is a nigger faggot\" directly targets two protected groups, race (black people) and sexuality (gay or LGBTQ+). It involves devaluation of these groups by using derogatory slurs. Therefore, the output is 2. This text can be classified as Hatespeech.\n",
      "Sample 615 Results:  The provided text seems to be discussing political groups and their actions, but it doesn't directly devalue or attack individuals based on protected characteristics such as race, gender, sexuality, religion, or disability. However, the term \"nazi\" is used in a derogatory manner towards certain groups (KKK, white supremacists). While this text criticizes these groups for their violent actions, it does not necessarily devalue or attack individuals based on their race or political beliefs.\n",
      "\n",
      "However, it's important to note that the term \"nazi\" is historically associated with a hate ideology and genocide, so using it as an insult can be considered offensive. Therefore, I would classify this text as '1 - Offensive'.\n",
      "\n",
      "Reasoning: The text discusses political groups and their actions, but uses derogatory terms towards certain groups (KKK, white supremacists). While it criticizes these groups for their violent actions, it does not necessarily devalue or attack individuals based on their race or political beliefs. However, the term \"nazi\" is historically associated with a hate ideology and genocide, so using it as an insult can be considered offensive.\n",
      "Sample 616 Results:  The provided text seems to express a negative view towards refugees, particularly those of Islamic background, and suggests they are responsible for violence against women, girls, LGBTQ+ individuals, and native people. This text can be interpreted as devaluing and attacking a protected group based on their race and religion, which aligns with the definition of 'Hatespeech'.\n",
      "\n",
      "Output: 2\n",
      "Sample 617 Results:  The provided text does not specifically target or devalue any protected group based on gender, race, sexuality, religion, or disability. It seems to be a casual comment about the number of white people in a photo. Therefore, the output should be 0 (Normal). However, it's important to note that this interpretation assumes good faith and lacks context. If the text is part of a larger conversation or if there are other indicators suggesting ill intent, the classification might change.\n",
      "Sample 618 Results:  The provided text is \"wise men say u a faggot\". To classify this text, let's follow the given criteria:\n",
      "\n",
      "1. Identify if the text mentions or involves devaluation of protected groups linking to gender, race, sexuality, religion, and disability. In this case, it does mention a group related to sexuality (gay men).\n",
      "\n",
      "2. Determine if the text specifically targets the mentioned group. The phrase \"wise men say\" suggests that the opinion is not the speaker's own but attributed to others, which may imply that the speaker is repeating or quoting someone else's words. However, the use of the term \"faggot\" is derogatory and offensive towards gay men.\n",
      "\n",
      "3. Consider the main intent of the text. While it's possible that the speaker might not have intended to devalue or attack the group, the use of the word \"faggot\" in this context can be interpreted as such.\n",
      "\n",
      "Based on the above reasoning:\n",
      "Output (number only): 1 - Offensive\n",
      "Sample 619 Results:  The provided text is: \"the nigger loses hands down\"\n",
      "\n",
      "Reasoning: This text uses a racial slur (\"nigger\") which is highly offensive and devaluing towards black people. It does not seem to be used in a context that implies a competition or comparison, but rather as an insult. Therefore, it can be classified as 'Hatespeech'.\n",
      "\n",
      "Output: 2\n",
      "Sample 620 Results:  The provided text directly targets a group (Irish people) and suggests they want to start a holocaust, which is a reference to one of history's most horrific genocides. This implies devaluation and an attack on the Irish people, linking to race and religion. Therefore, the output should be '2'.\n",
      "Sample 621 Results:  The provided text contains multiple derogatory terms that can be interpreted as devaluing or attacking protected groups based on race, height, and occupation. Specifically, the terms \"dwarf,\" \"sand nigger,\" and \"street shitter\" are offensive and potentially hateful towards people of short stature, Middle Eastern descent, and homeless individuals respectively. Therefore, the output for this text would be: 2 (Hatespeech)\n",
      "Sample 622 Results:  The provided text contains derogatory language towards Jewish people, specifically using the term \"kike\" which is widely recognized as an anti-Semitic slur. This text can be classified as 'Hatespeech' with a score of 2. It directly targets and devalues a protected group based on religion.\n",
      "Sample 623 Results:  The provided text contains multiple offensive and hateful slurs, including \"wooly,\" \"nappy,\" and \"nigger.\" These terms are historically used to devalue and dehumanize people of African descent. In this context, the text is clearly intended to attack and demean a specific racial group. Therefore, the output for this text would be: 2 (Hatespeech)\n",
      "Sample 624 Results:  The provided text seems to discuss a political issue, specifically the Muslim ban, and advocates for its defense. It does not directly devalue or attack any protected group based on race, gender, sexuality, religion, or disability. However, it could be perceived as offensive due to the sensitive nature of the topic and potential generalizations about Muslims and Arabs.\n",
      "\n",
      "To classify this text, we will consider its main intent:\n",
      "- It does not aim to devalue or attack a specific protected group, but rather discusses a political issue.\n",
      "- It could be perceived as offensive due to the sensitive nature of the topic and potential generalizations about Muslims and Arabs.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 625 Results:  The provided text is: \"no nigger in this blood stream\". This text directly targets and devalues a protected group based on race, specifically African Americans. It uses a derogatory slur to express exclusion, which aligns with the definition of hatespeech. Therefore, the output should be '2'.\n",
      "Sample 626 Results:  The provided text is: \"some random nigger hotep berating me pardon if i blew up everyone timeline are not you glad you are not a nigger\"\n",
      "\n",
      "Reasoning: This text contains the racial slur \"nigger\", which is highly offensive and devaluing towards black people. It also includes the term \"hotep\", which is often used as a derogatory term for African Americans who are perceived to be overly nationalistic or conservative. The text also expresses hatred and aggression towards black people, implying that they are inferior and undesirable. Therefore, this text can be classified as 'Hatespeech'.\n",
      "\n",
      "Output: 2\n",
      "Sample 627 Results:  The provided text is: \"want to know the real bubble the usd under the fed we will remove the nigger fed\"\n",
      "\n",
      "Reasoning: This text contains a racial slur (\"nigger\") which is highly offensive and devaluing towards black people. It also implies a threat of violence against an institution (the Fed) that represents the U.S government, which could be interpreted as a call to harm protected groups (black people in this case).\n",
      "\n",
      "Output: 2 (Hatespeech)\n",
      "Sample 628 Results:  The provided text is: \"do the democrats feel white privilege or white racists are the problem these retards are retarted\"\n",
      "\n",
      "Reasoning:\n",
      "1. The term \"retards\" can be considered offensive towards people with intellectual disabilities, as it is a derogatory slur.\n",
      "2. However, the text does not specifically target any protected group (race, gender, sexuality, religion, or disability) for devaluation or attack. Instead, it seems to be discussing a political issue (white privilege and white racists) in a controversial manner.\n",
      "3. The text does not express hate towards any specific group but rather questions the stance of Democrats on certain issues.\n",
      "\n",
      "Output: 1 - Offensive\n",
      "Sample 629 Results:  The provided text does not specifically target any protected group based on gender, race, sexuality, religion, or disability. Instead, it seems to be an insult directed towards the user's intelligence. However, the term \"dumb shit\" can still be considered offensive due to its derogatory nature.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 630 Results:  The provided text contains derogatory language towards people with intellectual disabilities (\"retarded\"). However, it does not specifically target a protected group based on gender, race, sexuality, religion, or disability. It is more of a general insult rather than hatespeech. Therefore, the output would be 1 (Offensive).\n",
      "Sample 631 Results:  1 - Offensive. While the text does mention Jewish and Israeli connections, it seems to be used in a way that could be perceived as stereotypical or biased, which can be offensive. However, it doesn't specifically involve devaluation of a protected group or direct an attack on them, so it's not hatespeech.\n",
      "Sample 632 Results:  The provided text contains multiple derogatory terms, including \"hearsay peddling moron,\" \"kike,\" and \"peasant.\" These terms can be considered offensive as they are used as insults. However, the term \"kike\" is historically associated with anti-Semitic hate speech due to its origin from a derogatory slur for Jewish people. Therefore, even though it might not be directly linked to devaluing or attacking a specific protected group in this context, it still carries a strong connotation of hate speech.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 633 Results:  The provided text is expressing a hypothetical scenario and does not contain any direct devaluation or attack towards a protected group. Instead, it questions the concept of \"reverse homophobia.\" Therefore, based on the given classification system, this text would be classified as '0' - Normal.\n",
      "\n",
      "However, it is important to note that while the text itself may not be considered hate speech, the sentiment expressed in the hypothetical scenario could be interpreted as promoting violence or intolerance, which is generally discouraged. It is always crucial to promote respect and understanding for all individuals regardless of their sexual orientation.\n",
      "Sample 634 Results:  The provided text contains derogatory language towards individuals, specifically using the term \"kike\" which is historically offensive to Jewish people. However, it's not clear if the text is intended as hatespeech towards all Jewish people or just a specific individual named Laura Loomer. Since we can't definitively determine if this text involves devaluation of a protected group linking to religion, I would classify it as '1 - Offensive'.\n",
      "\n",
      "It's important to note that using derogatory language is harmful and disrespectful, regardless of the intended target or context. It's crucial for everyone to promote respectful and inclusive communication in all interactions.\n",
      "Sample 635 Results:  The provided text, \"<user> <user> fucking retard\", can be interpreted as offensive due to the use of \"retard\" as an insult. However, it does not specifically target a protected group based on disability. Therefore, the output would be 1 (Offensive).\n",
      "Sample 636 Results:  The provided text directly targets and devalues a specific religious group (Muslims) and involves an animal (goat), which could potentially be interpreted as devaluing or attacking another protected group (animals). However, it's important to note that the text is not just about one individual but rather a generalization of Muslims. This text can be considered as promoting hate speech towards Muslims.\n",
      "\n",
      "Output: 2\n",
      "Sample 637 Results:  The provided text, \"most criminals in france are moslem or from some shit hole in africa so\", can be interpreted as devaluing and directing an attack towards people of Muslim faith and potentially African descent. This is because it stereotypes Muslims as criminals and makes derogatory comments about Africa. Therefore, the output would be '2' for Hatespeech.\n",
      "Sample 638 Results:  The provided text seems to be critical or mocking the show \"Queer Eye\" and its cast members, specifically labeling them as \"milquetoast safe gay white dudes.\" While this could potentially be seen as offensive due to the use of stereotypes related to sexuality and race, it does not appear to directly devalue or attack any specific protected group. Therefore, based on the provided classification system, the output would be:\n",
      "\n",
      "Output (number only): 1 - Offensive\n",
      "Sample 639 Results:  The provided text \"where are the german men to protect this child and beat the living shit out of the muslim retards who are bullying him\" can be classified as 'Hatespeech'. This statement not only mentions but also involves devaluation of a protected group (Muslims) and incites violence against them, which is a direct attack. The use of derogatory language (\"retards\") and the violent nature of the statement (\"beat the living shit out\") further supports this classification.\n",
      "Sample 640 Results:  The provided text is \"4 ftsomething studs love tall women tho init\". This text does not mention or devalue any protected groups based on gender, race, sexuality, religion, or disability. It seems to be a casual conversation about height preferences among men and women. Therefore, the output should be '0' as it can't be interpreted as hatespeech.\n",
      "Sample 641 Results:  The provided text appears to be offensive and toxic, but it does not specifically target a protected group based on race, gender, sexuality, religion, or disability. It is used as an insult towards white people in South Africa, but the term \"whites\" is not used in a devaluing or derogatory manner that would classify it as hate speech.\n",
      "\n",
      "However, the use of the word \"inferior\" can be interpreted as demeaning and disrespectful towards the individuals being addressed. The overall tone of the text is aggressive and hostile, which contributes to its offensive nature.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 642 Results:  The provided text contains derogatory language towards Jews, linking them to negative stereotypes and historical events. It implies that Jews are manipulative and malicious, which can be seen as devaluation of a protected group based on religion. Therefore, the output for this text would be '2' (Hatespeech).\n",
      "Sample 643 Results:  The provided text, \"finally an emoji for faggots\", directly targets and devalues a protected group based on sexuality. This can be considered as Hatespeech.\n",
      "Output: 2\n",
      "Sample 644 Results:  The provided text is: \"democrats are so retarded they might be eligible for disability\"\n",
      "\n",
      "Reasoning: This statement is using the term 'retarded' as an insult towards Democrats, which can be seen as devaluing a political group. However, it does not directly link to any protected groups such as race, gender, sexuality, religion, or disability. Therefore, it falls under the category of 'Offensive'.\n",
      "\n",
      "Output: 1\n",
      "Sample 645 Results:  The provided text \"trulay a pathetic unfunny zhid cunt\" can be interpreted as offensive due to the use of derogatory language (\"zhid\" and \"cunt\"). However, it does not specifically target any protected group based on gender, race, sexuality, religion, or disability.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 646 Results:  The provided text does not specifically target any protected group based on gender, race, sexuality, religion, or disability. Instead, it seems to express frustration towards \"illegal aliens\" and \"men and women in blue.\" However, the use of emoticons (\"ðŸ˜¡ ðŸ˜¡\") could be interpreted as aggressive or disrespectful.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 647 Results:  The provided text does not specifically mention or devalue any protected groups based on gender, race, sexuality, religion, or disability. Instead, it seems to discuss a general concept of right-wing violence and power dynamics. Therefore, the output would be 0, indicating that the text is 'Normal'.\n",
      "\n",
      "However, it's important to note that the context can sometimes influence the interpretation of a statement. For example, if the user has a history of promoting or supporting violent actions, this could potentially change the classification. But based on the provided text alone, it appears to be normal.\n",
      "Sample 648 Results:  The provided text does not mention any protected groups, gender, race, sexuality, religion, or disability explicitly. It also doesn't seem to involve devaluation of these groups. Instead, it appears to be a statement about the number of boys being raped. Therefore, based on the given criteria, this text can be classified as 'Normal'.\n",
      "\n",
      "However, it's important to note that the context in which this statement is used could potentially change its classification. For example, if this statement was made in a conversation where the intention was to devalue or attack boys, then it might be considered offensive or even hatespeech. But in the provided context, it seems like a neutral statement about a number.\n",
      "\n",
      "Output: 0 (Normal)\n",
      "Sample 649 Results:  The provided text \"it an infinite regress of jews jewing romans jewing anglos jewing jews\" can be interpreted as implying a pattern of exploitation or control by Jews over various groups, which could be seen as devaluing or stereotyping Jews. However, it does not directly attack or incite harm against Jews, and the use of \"jewing\" is a play on words rather than a direct slur. Therefore, this text can be classified as '1 - Offensive'.\n",
      "\n",
      "Reasoning: The text implies a pattern of control or exploitation by Jews over various groups, which could be seen as devaluing or stereotyping Jews. However, it does not directly attack or incite harm against Jews, and the use of \"jewing\" is a play on words rather than a direct slur. The text also seems to be making a philosophical point about infinite regress, which may contribute to its ambiguity.\n",
      "Sample 650 Results:  The provided text directly targets individuals with autism and sociopaths, linking them to specific ideological groups (Nazi and Islamic movements). This implies a devaluation of these groups based on their characteristics. Therefore, the output for this text would be '2' as it falls under the category of 'Hatespeech'.\n",
      "Sample 651 Results:  The provided text, \"sounds like a kike to me\", can be interpreted as devaluing or directing an attack on people of Jewish faith. Therefore, according to the given classification system, it falls under 'Hatespeech'.\n",
      "\n",
      "Reasoning: The term \"kike\" is a derogatory slur used against Jews. In this context, using the term implies that the person being referred to sounds like a Jew, which is an offensive and devaluing statement towards Jewish people.\n",
      "Sample 652 Results:  0 (Normal)\n",
      "Reasoning: The text does not mention or devalue any protected groups based on gender, race, sexuality, religion, or disability. It is a statement of dislike towards a zodiac sign, which is not a protected group. The use of \"fucking\" and laughter emoji might indicate strong dislike but it doesn't qualify as hatespeech or offensive in this context.\n",
      "Sample 653 Results:  The provided text uses the term \"muzzrat\" and \"com rats,\" which could potentially be perceived as derogatory or offensive towards a specific group, such as Muslims. However, it's important to note that the context of the text is a birthday greeting and includes phrases like \"greatest muzzrat slayer\" and \"may mahadev bless you.\" These elements suggest that the user might be referring to an ongoing debate or conflict in a specific online community, possibly related to a game or discussion forum.\n",
      "\n",
      "In this context, it seems that the use of \"muzzrat\" is not intended as hatespeech towards Muslims but rather as a term used within a specific online community or context. However, it's essential to remember that such terms can still be offensive and potentially harmful to some individuals.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 654 Results:  The reasoning for the provided text \"this coon is full of shit\" would be as follows:\n",
      "\n",
      "The term \"coon\" has a long history of being used as a racial slur against black people, specifically African Americans. In this context, it is used to devalue and attack a person based on their race, which falls under the category of protected groups. Therefore, the output would be: 2 (Hatespeech)\n",
      "Sample 655 Results:  Based on the provided criteria, the text in question appears to be a clear example of Hatespeech. It directly targets a specific ethnic group (Pakistani heritage Muslims) and makes derogatory statements about them, linking them to criminal activities such as grooming and raping children. This text not only mentions but also involves devaluation of the targeted group, which is a protected group based on race and religion. Therefore, the output for this text should be '2'.\n",
      "\n",
      "However, it's important to note that this classification is based on the provided text alone and without any context or additional information about the author's intent or the circumstances in which the text was written. In some cases, a more nuanced understanding of the situation might lead to a different interpretation. But in this case, the text as it stands seems to meet the criteria for Hatespeech.\n",
      "Sample 656 Results:  Based on the provided context, this text seems to be discussing a reported incident involving racial discrimination. However, the term \"niglet\" is derogatory and offensive towards black people. While it might not necessarily be used as direct hatespeech in this instance, it does contribute to devaluing or stereotyping a protected group (race).\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 657 Results:  The provided text contains multiple instances that could be considered offensive or hateful towards specific groups. It targets whites, people of diverse nationalities, and the LGBTQ+ community. Therefore, according to the given classification system, the output would be '2' as it involves devaluation of protected groups linking to race and sexuality.\n",
      "Sample 658 Results:  The provided text seems to express a desire for unity among white ethnic groups, which could potentially be seen as divisive or exclusionary. However, it does not explicitly devalue or attack any specific protected group based on race, gender, sexuality, religion, or disability. Therefore, according to the given classification system, this text would be classified as '1 - Offensive'.\n",
      "\n",
      "However, it's important to note that context is crucial in determining whether a statement is offensive or not. In some cases, statements like these can be interpreted as hate speech due to their potential to fuel division and prejudice. It's always essential to consider the broader social and historical context when evaluating such texts.\n",
      "Sample 659 Results:  The provided text \"lggbdttibraappabcdefghijklmnopqrstuvwxyz now i know my lggbdttibraapps next time will not you gay with me\" does not specifically target or devalue any protected group based on gender, race, sexuality, religion, or disability. It seems to be a jumbled combination of letters and the term \"lggbdttibraapps,\" which could potentially refer to the LGBTQ+ community, but it is not used in a derogatory or offensive manner. Therefore, the output would be 0 (Normal).\n",
      "Sample 660 Results:  The provided text contains derogatory language towards Jews, referring to them as \"dogs\" and implying they were excluded from various societies. This can be seen as devaluation of a protected group based on religion. Therefore, the output would be '2' for Hatespeech.\n",
      "Sample 661 Results:  The provided text is \"niggahs was sayin she to pretty to b actin like a hoe and dey <percent> rite ðŸ˜‚\".\n",
      "\n",
      "Reasoning:\n",
      "The term \"niggahs\" is highly offensive towards black people. In this context, it is used as a derogatory slur against the black community. The phrase \"acting like a hoe\" can be interpreted as devaluing women, particularly black women. Therefore, the text involves direct attacks on both protected groups: race and gender.\n",
      "\n",
      "Output: 2 (Hatespeech)\n",
      "Sample 662 Results:  The provided text \"ok volks lets downboat this filthy kikess <user>\" can be interpreted as offensive due to the use of the term \"kikess\" which could be seen as derogatory towards Jewish people, even though it's not a direct reference to religion. However, the intent seems more focused on insulting an individual rather than devaluing or attacking a specific protected group.\n",
      "\n",
      "Output: 1\n",
      "Sample 663 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The text is using colloquial language and emojis to express the speaker's emotions about their dogs and personal situation. It does not involve devaluation or direct attacks towards any protected groups based on gender, race, sexuality, religion, or disability.\n",
      "Sample 664 Results:  The provided text does not specifically target any protected groups based on gender, race, sexuality, religion, or disability. It is a criticism of the political actions of Justin Trudeau, the Prime Minister of Canada, regarding funding for various crises and infrastructure issues. Therefore, the output would be 0, as it can't be interpreted as hatespeech.\n",
      "Sample 665 Results:  The provided text contains multiple instances of offensive language, including racial slurs (\"blacks\", \"niggers\") and religious stereotypes (\"Islamism abuse\"). It also demonstrates a generalization and devaluation of both black people and Muslims. Therefore, the output for this text would be: 2 (Hatespeech)\n",
      "Sample 666 Results:  The provided text \"dumb idiot retard\" does not specifically target any protected group based on gender, race, sexuality, religion, or disability. It is a general insult and can be used against anyone. Therefore, the output should be 0 (Normal). However, it's important to note that using such language can still be disrespectful and hurtful, even if not intended as hatespeech.\n",
      "Sample 667 Results:  The provided text, \"i bet most germans would rather be bored than raped and killed by migrant monsters,\" can be classified as 'Hatespeech' (2). This is because the text involves devaluation of a protected group (migrants) and links it to fear, violence, and dehumanization. The use of the term \"monsters\" is particularly problematic as it reinforces negative stereotypes and encourages hatred towards migrants.\n",
      "Sample 668 Results:  0 (Normal)\n",
      "Reasoning: The provided text does not mention or devalue any protected groups, nor is it used as an insult. It's a simple question about the content of a conversation or document.\n",
      "Sample 669 Results:  The provided text \"<user> good lock up the rest of the white devils\" can be interpreted as a form of hate speech, specifically targeting the race (white people). It suggests a desire for violence or imprisonment towards an entire group based on their race, which is discriminatory and harmful.\n",
      "\n",
      "Output: 2\n",
      "Sample 670 Results:  The provided text \"i remember something to that effect gotta dig deeper for the pedo thing i may well have him mixed up with another yid\" does not directly involve devaluation or an attack on any protected groups such as race, gender, sexuality, religion, or disability. However, it does contain a derogatory term \"yid,\" which is often used as a pejorative against Jewish people.\n",
      "\n",
      "In this context, the term \"yid\" is not used in a way that devalues or attacks all Jewish people but rather seems to be referring to an individual or group of individuals who are being accused of being pedophiles. This accusation can be considered offensive and harmful, but it does not meet the criteria for hatespeech as defined in the provided classification system.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 671 Results:  The provided text does not specifically target any protected group or individual, nor does it involve devaluation. It seems to be a sentence fragment expressing a negative opinion about people's behavior. Therefore, the output would be 0, indicating that it is 'Normal'. However, it's important to note that the term \"niggas\" can be offensive when used in certain contexts, but in this case, it appears to be used as a colloquialism or slang, not as hatespeech.\n",
      "Sample 672 Results:  The provided text seems to describe demographic changes in certain areas, mentioning various ethnic groups such as Greeks, Italians, Hispanics, Asians, and whites. However, it does not explicitly devalue or attack any specific protected group. Instead, it appears to express a sense of nostalgia for the past and perhaps discomfort with current demographic changes.\n",
      "\n",
      "Therefore, based on the given classification system, this text would be classified as '0' - Normal. It can be interpreted as a description or observation rather than hatespeech or offensive language. However, it's important to note that the tone and intent of the text could potentially be interpreted differently depending on context and personal biases.\n",
      "Sample 673 Results:  1 (Offensive)\n",
      "\n",
      "Reasoning: The text implies that the speaker believes there is racism in Australia, specifically towards non-white Europeans. While it doesn't directly devalue or attack any specific group, it does suggest a bias and could be interpreted as offensive due to its potential to perpetuate stereotypes or divisive sentiments.\n",
      "Sample 674 Results:  The provided text is about a poll regarding immigration policies, and it does not contain any direct or indirect devaluation of protected groups. It's simply presenting data from a political poll. Therefore, the output would be 0, as this text can't be interpreted as hatespeech.\n",
      "Sample 675 Results:  The provided text is: \"it ll work as long as you only arm the whites the niglets would just shoot all the white kids if they had guns\"\n",
      "\n",
      "Reasoning: This text directly targets white people and black people, suggesting that black people (referred to as \"niglets\") would harm white people if given weapons. This implies a devaluation of both races and can be interpreted as inciting violence based on race, which is a form of hate speech.\n",
      "\n",
      "Output: 2\n",
      "Sample 676 Results:  The provided text does not specifically target a protected group or involve devaluation. It seems to be expressing a personal observation about behavior, albeit in a somewhat confrontational manner. Therefore, based on the given classification system, the output would be 1 (Offensive). However, it's important to note that context can greatly influence the interpretation of text, and this analysis is based solely on the provided statement without additional context.\n",
      "Sample 677 Results:  The provided text is: \"it be the unbothered bitches that be knowing everything you post ðŸ˜­ ðŸ˜­ ðŸ˜­\"\n",
      "\n",
      "Reasoning: This text seems to be using the term \"bitches\" as a colloquial or informal way to refer to women, and it's used in a context that suggests these women are aware of what someone else is posting. However, it does not seem to involve devaluation or direct an attack on any specific protected group based on gender, race, sexuality, religion, or disability. It can be interpreted as playful banter or sarcasm rather than hatespeech.\n",
      "\n",
      "Output: 0 (Normal)\n",
      "Sample 678 Results:  Based on the provided context, the text seems to be referring to a painting technique (\"alla prima\") in an informal and possibly aggressive manner (\"that bitch\"). However, it does not specifically target any protected group or devalue them. Therefore, the output would be 0 - Normal.\n",
      "Sample 679 Results:  The provided text does not specifically target a protected group or involve devaluation of any group based on gender, race, sexuality, religion, or disability. It is used as an insult towards people in general who are perceived to be slow-witted or lacking intelligence. Therefore, the output should be '1' (Offensive). However, it's important to note that using such language can still be hurtful and disrespectful, even if not intended as hatespeech.\n",
      "Sample 680 Results:  The provided text contains multiple offensive and derogatory terms, including \"boomer,\" \"kike,\" and \"jism.\" These terms are used as slurs against older people, Jewish individuals, and sexuality respectively. Therefore, the text can be classified as '1 - Offensive.'\n",
      "\n",
      "Here's a breakdown of why each term is offensive:\n",
      "\n",
      "- \"Boomer\": Originally used to refer to people born between 1946 and 1964, it has been appropriated as a pejorative term for older individuals, often associated with outdated views or technology.\n",
      "- \"Kike\": This term is an anti-Semitic slur that demeans Jewish people by using a derogatory nickname for them.\n",
      "- \"Jism\": While not directly related to a protected group, the use of this term in a sexual context can be considered offensive due to its vulgar and disrespectful nature.\n",
      "Sample 681 Results:  Based on the provided context, this statement does not seem to involve devaluation of any protected groups or individuals. It appears to be a hypothetical question about Islamic law and does not contain any offensive language or intent. Therefore, the output for this statement would be '0' (Normal).\n",
      "Sample 682 Results:  The provided text does not mention or involve devaluation of any protected groups, nor is it used as an insult against individuals. It seems more like a personal comment about physical appearance, which can be subjective and varies from person to person. Therefore, the output would be 0, indicating that the text is 'Normal'. However, it's important to note that this classification assumes good faith on the part of the user and does not consider any potential malicious intent or context outside of the provided statement.\n",
      "Sample 683 Results:  This text contains multiple instances of offensive language and hate speech. It devalues and attacks protected groups based on race, religion, and nationality. The use of derogatory terms such as \"bastards,\" \"goat-fucking,\" and \"motherfuckers\" is offensive towards Muslims, while the phrase \"leave none alive from the womb to the tomb they gotta go\" suggests a desire for genocide against this group. Therefore, the output for this text would be '2' as it involves direct devaluation of a protected group (Muslims) and promotes violence or hatred towards them.\n",
      "Sample 684 Results:  The provided text \"i am hoping hillary and o think trump will not press charges so o dosent pardon her trumps new team can put that bitch and all the rest away\" contains derogatory language towards Hillary Clinton, specifically using the term \"bitch.\" However, it does not directly involve devaluation of a protected group based on gender, race, sexuality, religion, or disability. Therefore, according to the provided classification system, this text would be classified as '1 - Offensive.'\n",
      "Sample 685 Results:  The provided text, \"fucking toxic weird ass retarded bitch,\" can be interpreted as offensive due to the use of derogatory language towards women and the disabled. However, it does not specifically target a protected group based on gender, race, sexuality, religion, or disability with the intent to devalue them.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 686 Results:  The provided text does not directly mention or devalue any protected groups based on gender, race, sexuality, religion, or disability. However, it does seem to promote a racial ideology that could potentially be offensive or divisive. The term \"Aryan\" has been historically associated with white supremacist and Nazi ideologies.\n",
      "\n",
      "However, the text does not explicitly devalue or attack any specific group. It is more about discussing historical origins of names. So, it's hard to classify this as 'Hatespeech'. It might lean towards being 'Offensive' due to the sensitive nature of the term \"Aryan\" in certain contexts.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 687 Results:  The provided text clearly targets a specific racial and ethnic group, Ashkenazi Jews and others, with derogatory language. It also makes a comparison between them and a racial slur for people from the Middle East or North Africa (\"sand nigger\"). This text is directly devaluing protected groups based on their race and religion, linking to both race and ethnicity.\n",
      "\n",
      "Output: 2 (Hatespeech)\n",
      "Sample 688 Results:  2\n",
      "\n",
      "Reasoning: The text directly references a hate group, Nazis, and encourages or condones violence against a specific group, \"the left\". This can be considered as promoting hatred towards a protected group based on political beliefs.\n",
      "Sample 689 Results:  The reasoning for the provided text \"are you retarded or what\" would be as follows:\n",
      "\n",
      "This text can be interpreted as offensive towards people with intellectual disabilities, specifically those diagnosed with Retardation. However, it does not directly involve devaluation of a protected group or link it to gender, race, sexuality, religion, or disability beyond the use of the term \"retarded.\" Therefore, the output would be 1 (Offensive).\n",
      "Sample 690 Results:  The provided text is: \"a nigga that works hard to get his bag needs a girl that has a vision not a term that likes to smoke and party\"\n",
      "\n",
      "Reasoning:\n",
      "The term \"nigga\" can be considered offensive towards black people. However, in this context, it seems to be used as a self-referential term by the speaker who identifies as black. The phrase \"a nigga\" is not used to devalue or attack any individual or group but rather to describe a certain type of person (one who works hard).\n",
      "\n",
      "The text also implies that the desired partner for this person should have ambition and goals, which can be seen as positive. However, the use of \"term\" instead of \"girl\" could be interpreted as dehumanizing, but it doesn't specifically target a protected group based on gender, race, sexuality, religion, or disability.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 691 Results:  The provided text \"<user> wow porch monkey ur mean\" can be interpreted as a racial slur towards black people, specifically using the term \"porch monkey\". This term is historically derogatory and dehumanizing towards African Americans. Therefore, the output should be: 2 (Hatespeech)\n",
      "Sample 692 Results:  The provided text, \"white boys and ghetto white girls make me sick i can not stand you all,\" seems to be targeting a specific racial group (white people) and also stereotyping a subgroup within that race (\"ghetto white girls\"). This text can be interpreted as devaluing white people, which is a protected group based on race. Therefore, the output would be: 2 (Hatespeech).\n",
      "Sample 693 Results:  The provided text \"shocker a little white boy flopping\" does not specifically target or devalue a protected group based on race, gender, sexuality, religion, or disability. It seems to be more of a casual comment or expression of surprise and disappointment, possibly related to a game or sports context. Therefore, the output would be 0 (Normal).\n",
      "Sample 694 Results:  Based on the provided definition, let's break down the text:\n",
      "\n",
      "\"<number> unlike the Islamic world, the West cherishes human life so we do not need Muslims to teach us how to love <number> religious groups which facilitate refugee immigration are paid by the head making venture Catholic Lutheran churches lead in this operation\"\n",
      "\n",
      "1. The text does not directly mention or devalue a specific protected group (gender, race, sexuality, religion, disability) based on their identity. Instead, it compares the West to the Islamic world and mentions religious groups that facilitate refugee immigration.\n",
      "\n",
      "2. However, the text implies a negative connotation towards certain religious groups (Catholic Lutheran churches in this case), suggesting they are paid for facilitating refugee immigration. This could potentially be seen as offensive or biased, but it does not directly involve devaluation or an attack on a specific protected group.\n",
      "\n",
      "3. The text also includes a comparison between the West and the Islamic world regarding human life, which might be perceived as stereotyping or generalizing, but again, it doesn't specifically target any protected group.\n",
      "\n",
      "Given these points, I would classify this text as '1\n",
      "Sample 695 Results:  The provided text seems to contain derogatory language towards individuals working in the public sector, implying they are incompetent and subpar. However, it does not specifically target any protected group based on gender, race, sexuality, religion, or disability. Therefore, according to the given classification system, the output would be:\n",
      "\n",
      "Output (number only): 1 - Offensive\n",
      "Sample 696 Results:  The provided text is \"how much money would it take for you to lick a dogs asshole not very much considering you are a wetback\".\n",
      "\n",
      "Reasoning: This text uses the term \"wetback\" which is historically and currently offensive towards Hispanic people, particularly Mexican immigrants. It devalues and attacks a specific protected group based on their race and nationality. Therefore, the output is 2 (Hatespeech).\n",
      "Sample 697 Results:  The provided text does not specifically target any protected group based on gender, race, sexuality, religion, or disability. It seems to be a request for clarification about the terms \"refugee illegals\" and \"Indian citizens\". Therefore, according to the given classification system, this text can be classified as '0' - Normal.\n",
      "\n",
      "However, it's important to note that the term \"illegal refugee\" is often considered offensive and inaccurate by many, as refugees are not illegal by definition. But in this context, without additional information or context, it's hard to definitively classify it as '1' - Offensive. It could still be interpreted as a simple request for clarification.\n",
      "Sample 698 Results:  The provided text \"i said ignore not mute i am following you retard\" can be interpreted as offensive due to the use of the term \"retard\" which is often used in a derogatory manner towards people with intellectual disabilities. However, it does not specifically target a protected group or involve devaluation of them.\n",
      "\n",
      "Output: 1\n",
      "Sample 699 Results:  This text seems to contain several elements that could be interpreted as offensive or hate speech. Here's a breakdown:\n",
      "\n",
      "1. The phrase \"Kalergi plan\" is a conspiracy theory often used by far-right groups to claim that there is a plot to dilute the white race in Europe. This can be seen as promoting racial superiority and devaluing non-white populations, which fits the definition of hate speech.\n",
      "\n",
      "2. The statement \"empty greater Israel then hope eu is gonna clash with all these different cultures religions\" could be interpreted as expressing a desire for conflict between different cultural and religious groups, which could potentially incite hatred or violence.\n",
      "\n",
      "3. The phrase \"so people will accept nwo\" (new world order) is often associated with various conspiracy theories that can be seen as divisive and potentially harmful.\n",
      "\n",
      "Given these points, I would classify this text as 'Hatespeech' (2). However, it's important to note that context is crucial in determining the intent of a statement, and without additional context, my analysis may not be fully accurate.\n",
      "Sample 700 Results:  The provided text uses the term \"honky,\" which historically has been a racial slur against white people. However, in this context, it seems to be used self-referentially by the author, who identifies as white. The author also expresses disdain for other white people who hate other whites, and suggests a movement to Mecca that would include LGBT and Jews.\n",
      "\n",
      "While the use of \"honky\" is offensive due to its historical context, it's not clear if the author intends to devalue or attack white people as a group. Instead, they seem to be criticizing certain behaviors within the white community. The text also includes a suggestion for inclusivity towards LGBT and Jews, which could be interpreted as a positive gesture.\n",
      "\n",
      "Therefore, based on the provided criteria, I would classify this text as '1 - Offensive'. However, it's important to note that context is crucial in determining whether a statement is hate speech or offensive, and this classification should not be used in isolation when making judgments about harmful language.\n",
      "Sample 701 Results:  The provided text seems to criticize Fox News and Robert De Niro, but it doesn't explicitly devalue or attack any protected groups based on gender, race, sexuality, religion, or disability. Therefore, the output should be '0' for Normal.\n",
      "\n",
      "However, it's important to note that the term \"white privilege\" could potentially be interpreted as a reference to race, but in this context, it appears to be used in a critical manner towards Fox News, not as an attack on white people as a group.\n",
      "\n",
      "For a more accurate classification, one might want to consider the broader context in which the text was written or spoken, including the author's intent and the audience's interpretation. But based solely on the provided text, it seems most appropriate to classify it as 'Normal'.\n",
      "Sample 702 Results:  Output: 0 (Normal)\n",
      "\n",
      "Reasoning: The text provides information about a historical figure, Charwe Nyakasikana, who was one of the major spiritual leaders of African resistance to white rule in Zimbabwe during the late 19th century. It does not contain any derogatory or offensive language towards protected groups such as gender, race, sexuality, religion, or disability. Therefore, it can be classified as normal.\n",
      "Sample 703 Results:  The provided text contains statements that could be interpreted as stereotyping and devaluing a specific religious group (Jews), which is one of the protected groups. It also includes derogatory language towards another racial group (whites). Therefore, based on the given classification system, the output for this text would be:\n",
      "\n",
      "Output: 2\n",
      "Sample 704 Results:  The provided text \"tv a mental ghetto where thought goes to die\" does not specifically target any protected group based on gender, race, sexuality, religion, or disability. It is criticizing television as a medium that stifles intellectual growth, which can be considered a strong critique but not necessarily hate speech or offensive.\n",
      "\n",
      "Output: 0\n",
      "Sample 705 Results:  The provided text \"<user> facts smh dumb niggers\" can be interpreted as offensive due to the use of the racial slur \"nigger\", which is derogatory and disrespectful towards black people. However, in this context, it seems like the user is expressing frustration with someone or something (indicated by \"facts\" and \"smh\"), but the use of the racial slur makes the statement offensive.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 706 Results:  Based on the provided definition, let's analyze the text:\n",
      "\n",
      "Text: \"this was a total bullshit rule housing is segregated by income more than anything this rule would force wealthy neighborhoods to allow section <number> housing be built in high end communities under the guise of diversity and equality bringing the ghetto to you\"\n",
      "\n",
      "Reasoning: The text seems to express frustration with a perceived unfair housing policy. However, it does not directly devalue or attack any specific protected group (race, gender, sexuality, religion, or disability). Instead, it criticizes a rule that could potentially affect different income groups. Therefore, the output would be:\n",
      "\n",
      "Output: 0 (Normal)\n",
      "Sample 707 Results:  The provided text \"food coop of Olympia Washington anti white propaganda they hate you\" can be interpreted as offensive due to the accusation of anti-white sentiment, which could potentially be perceived as devaluing a protected group based on race. However, it's important to note that the text does not directly attack or devalue individuals but rather an organization.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 708 Results:  The provided text directly targets a racial group, \"white people,\" and uses derogatory language towards another racial group, \"shitskins.\" This can be interpreted as an attempt to devalue or attack a protected group based on race. Therefore, the output is '2' for Hatespeech.\n",
      "Sample 709 Results:  The provided text contains derogatory language towards Jewish people, which is a protected group based on religion. The text also includes the phrase \"genociding white adults and our white babies,\" which implies a call to violence or harm against another group (white people). This text meets the criteria for 'Hatespeech' as it involves devaluation of a protected group and directs an attack, in this case, both towards Jewish people and white people.\n",
      "\n",
      "Output: 2\n",
      "Sample 710 Results:  The provided text, \"i donâ€™t wanna go to your homophobic fucking prom anyway,\" can be classified as '1 - Offensive.'\n",
      "\n",
      "Reasoning: While the term \"homophobic\" suggests a negative attitude towards homosexuality or LGBTQ+ individuals, it is not directly devaluing or attacking them. Instead, it seems to be used to criticize an event (prom) that is perceived as homophobic. However, the use of the word \"fucking\" and the overall tone of the text can be considered offensive.\n",
      "Sample 711 Results:  The provided text \"didnt think some had minds sand niggers dont\" can be interpreted as hatespeech towards black people. It uses the racial slur \"nigger\" and implies that some people, possibly referring to blacks, are not intelligent. Therefore, the output is 2.\n",
      "Sample 712 Results:  The provided text is advocating for an active stance against racism, misogyny, and queerphobia in educational work environments. It does not contain any derogatory or devaluing language towards protected groups such as gender, race, sexuality, religion, or disability. Therefore, the output should be 0, indicating that it is 'Normal'.\n",
      "\n",
      "However, if we consider the context of \"harassment\" mentioned in the text, it could potentially imply harmful behavior towards individuals. But the text itself does not directly devalue or attack any specific group, so it remains 'Normal' in this classification.\n",
      "Sample 713 Results:  Output: 0\n",
      "\n",
      "Reasoning: The text does not mention or devalue any protected groups, nor is it used as an attack on them. It's a general statement about people finding reasons to dislike someone without knowing them well. While the use of \"hate\" might imply negativity, it doesn't specifically target any particular group based on gender, race, sexuality, religion, or disability. Therefore, it can be classified as 'Normal'.\n",
      "Sample 714 Results:  Output: 1\n",
      "\n",
      "Reasoning: The text is criticizing the use of certain offensive elements such as racism, homophobia, sexism, and rape in humor. While it mentions these topics, it does not directly devalue or attack any specific protected groups. Instead, it is expressing a negative opinion about the use of such elements in humor.\n",
      "Sample 715 Results:  2\n",
      "\n",
      "Reasoning: The text directly targets Shaun King, a black man, by using the term \"black supremacist,\" which is a derogatory and offensive label often used to devalue or attack individuals who are perceived as promoting racial superiority. Additionally, the use of the term \"retarded\" to describe him is ableist language that devalues people with intellectual disabilities. The text also implies that King's followers, who are primarily black women, are \"dumb teenage girls,\" which reinforces harmful stereotypes and devalues a protected group based on gender and age. Furthermore, the statement suggests that racial dating preferences are racist, which is a common trope used to silence and devalue individuals who advocate for racial justice.\n",
      "Sample 716 Results:  The provided text contains multiple derogatory terms and slurs, including \"kike,\" a term historically used as an anti-Semitic slur against Jewish people, and \"faggot,\" which is often used as a homophobic slur. Additionally, the use of \"trs\" (transgender) in a derogatory context can be seen as targeting individuals based on their gender identity.\n",
      "\n",
      "Given that this text uses multiple slurs to devalue and attack protected groups (Jewish people, transgender individuals, and potentially LGBTQ+ individuals), it can be classified as 'Hatespeech'.\n",
      "\n",
      "Output: 2\n",
      "Sample 717 Results:  The provided text is: \"<user> <user> this dude josh a racist ðŸ¤£ not only white ppl can be racist clown\"\n",
      "\n",
      "Reasoning: This text is not directly devaluing or attacking any specific protected group. Instead, it's accusing an individual (Josh) of being racist and also stating that racism is not exclusive to white people. The use of \"racist\" implies a negative connotation but it's not aimed at a particular race or ethnicity. The laughter emoji (\"ðŸ¤£\") might suggest some level of humor, which could be seen as less offensive.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 718 Results:  The provided text seems to discuss historical facts and comparisons between certain groups, but it does not directly involve devaluation or an attack on protected groups. However, the comparison could be perceived as offensive or insensitive due to its tone and choice of words.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 719 Results:  The provided text seems to express a strong negative opinion towards Tommy Robinson, who is known for his controversial views on Islam, and also mentions his alleged conversion to Judaism and support of Zionism. However, it does not directly devalue or attack any specific protected group based on race, gender, sexuality, religion, or disability.\n",
      "\n",
      "The text does contain strong language (\"cancerous\" and \"potential zionist shill\") that could be considered offensive due to its derogatory nature. But it doesn't seem to be primarily about devaluing or attacking a protected group.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 720 Results:  The provided text compares abortion to the Holocaust, which was a genocide that targeted six million Jews during World War II. In this context, the text implies that abortion is a mass killing, and while it doesn't explicitly mention any protected group, it could be interpreted as devaluing the lives of unborn children. However, it's important to note that the text does not specifically target any particular race or ethnicity.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 721 Results:  The provided text, \"<user> is a faggot not an argument let that sink in\", can be interpreted as offensive. While the term \"faggot\" is historically used as a derogatory slur towards the LGBTQ+ community, in this context it seems to be used as an insult against the user, rather than devaluing or attacking the LGBTQ+ community as a whole. However, the use of such language can still be considered harmful and disrespectful.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 722 Results:  This text contains racial slurs (\"nigger\") which can be highly offensive towards black people. However, in this context, it seems to be used to describe the behavior of individuals on a specific online forum (_the_donald), rather than as a general attack on all black people. Therefore, while it is still offensive, it might not necessarily qualify as hatespeech due to its specific targeting of individuals within a group, rather than the group as a whole.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 723 Results:  The provided text does not specifically target a protected group based on race, gender, sexuality, religion, or disability. It discusses the level of Muslim immigration in Nordic countries, but it doesn't devalue or attack Muslims as a group. Therefore, the output would be 0 (Normal). However, it's important to note that this text could potentially be interpreted as offensive or inflammatory depending on the context and tone in which it was said or written.\n",
      "Sample 724 Results:  The provided text \"another twitter refugee has arrived banned for standing up to snowflakes maga\" does not specifically mention or devalue any protected groups based on gender, race, sexuality, religion, or disability. It seems to be a political statement related to Twitter users and the MAGA (Make America Great Again) movement. Therefore, according to the given classification system, this text can be classified as '0' - Normal.\n",
      "\n",
      "However, it's important to note that the term \"snowflakes\" can sometimes be used pejoratively to dismiss or belittle individuals who are perceived as overly sensitive or easily offended. This could potentially be considered offensive, but in this specific context, it might not be intended as hatespeech.\n",
      "\n",
      "For a more accurate classification, one would need additional context about the conversation or the original tweet that this statement is referring to.\n",
      "Sample 725 Results:  Output: 2\n",
      "\n",
      "Reasoning: The text specifically targets a racial group (\"sand niggers\" and \"shitskins\") and devalues them, suggesting they should be banned from the country. This is a clear example of hate speech.\n",
      "Sample 726 Results:  The provided text does not mention any protected groups, nor is there an intent to devalue or attack them. It appears to be a response to a personal interaction that went wrong, using profanity as an expression of anger. Therefore, the output would be 0 - Normal.\n",
      "Sample 727 Results:  1 (Offensive)\n",
      "\n",
      "Reasoning: While the text does contain derogatory language towards women, it is not specifically targeting a protected group based on gender, race, sexuality, religion, or disability. The text is more focused on attacking the individual's intelligence and arrogance rather than devaluing women as a whole. However, the tone and language used are disrespectful and offensive.\n",
      "Sample 728 Results:  2\n",
      "\n",
      "Reasoning: The text uses derogatory and offensive language (\"filthy dykes\") towards a protected group (LGBTQ+) and also implies that they are committing \"sins,\" which could be interpreted as devaluing their identity. Furthermore, the statement suggests that members of this group should organize for themselves, implying that others do not care about them or their rights, which could be seen as a form of discrimination.\n",
      "Sample 729 Results:  The provided text \"paul jayda jailed meanwhile muslim preachers are free to spout their hatred unhindered the law is an ass\" can be classified as '1 - Offensive'.\n",
      "\n",
      "Reasoning: While the text implies a perceived unfairness in the legal system, it does not directly devalue or attack any specific protected group (race, gender, sexuality, religion, or disability). However, the phrase \"Muslim preachers are free to spout their hatred\" could be interpreted as offensive due to its potential association with negative stereotypes about Muslims. The overall tone of the text is critical and potentially divisive, but it does not specifically single out or devalue a protected group in a way that would classify it as 'Hatespeech'.\n",
      "Sample 730 Results:  The provided text is \"free speech my ass it was terrorism and the incitement of violence say it name radicalwhiteterrorism\".\n",
      "\n",
      "Reasoning: This text seems to express frustration or criticism towards a perceived lack of recognition for certain acts as terrorism, specifically those committed by white extremists. It does not directly devalue or attack any specific protected group based on gender, race, sexuality, religion, or disability. Instead, it appears to be a political statement about the inconsistent application of terms like \"terrorism\" and \"violence\".\n",
      "\n",
      "Output: 0 (Normal)\n",
      "Sample 731 Results:  The provided text, \"<user> sorry that paging dr faggot does not land anymore,\" can be interpreted as offensive due to the use of the term \"faggot\" which is often used in a derogatory manner towards the LGBTQ+ community. However, it's important to note that this text doesn't specifically target or devalue individuals based on their sexuality but rather it's used as an insult against someone named Dr. Faggot.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 732 Results:  The provided text criticizes a Muslim individual and uses the phrase \"bigot.\" However, it also includes religious references such as \"may Allah guide you\" and \"straight to hell,\" which could be interpreted as a form of religious intolerance. Furthermore, the use of emojis like ðŸ˜¼ (smiling cat) and â˜ (pointing hand) might suggest a mocking or disrespectful tone.\n",
      "\n",
      "However, it's important to note that the text does not explicitly devalue or attack Muslims as a group, but rather targets an individual. Therefore, based on the given criteria, I would classify this text as:\n",
      "\n",
      "Output (number only): 1 - Offensive\n",
      "Sample 733 Results:  The provided text contains multiple derogatory and offensive terms, including slurs against women (\"cuckold\"), Jews (\"kike\"), homosexuals (\"faggot\"), and ethnic or political groups (\"bolshie\", \"libertarian CIA operative\"). This text is intended to devalue and attack these protected groups, making it a clear example of hatespeech.\n",
      "\n",
      "Output: 2\n",
      "Sample 734 Results:  The provided text contains multiple derogatory and offensive terms towards various racial, ethnic, and religious groups. It also includes a reference to a hate crime (\"dindu nuffins\" is a phrase often used by white supremacists to mock the \"hands up, don't shoot\" movement). Therefore, this text can be classified as 'Hatespeech'.\n",
      "\n",
      "Output: 2\n",
      "Sample 735 Results:  The provided text seems to contain derogatory language and stereotypes, particularly towards women of Middle Eastern or North African descent (referred to as \"muzrat\"). This term can be considered offensive and disrespectful. However, it does not specifically target a protected group based on gender, race, sexuality, religion, or disability in the way that hatespeech would.\n",
      "\n",
      "The text also contains political and cultural commentary about Europe, which might be interpreted as controversial or inflammatory by some. The use of \"junker\" and the suggestion that communist uniforms should replace German WW2-era uniforms could be seen as provocative.\n",
      "\n",
      "However, the main intent of the text does not appear to be devaluing or attacking a specific protected group, so it can be classified as 'Offensive' (1). It is important to note that this classification does not diminish the potential harm or discomfort caused by such language and sentiments.\n",
      "Sample 736 Results:  The provided text does not directly mention or devalue any protected groups based on gender, race, sexuality, religion, or disability. However, it seems to express a negative sentiment towards a specific educational reform (Common Core) and its perceived impact on calligraphy. The phrase \"bring everyone down to ghetto levels\" could be interpreted as offensive or derogatory towards certain communities, but it is not explicitly directed at any particular group.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 737 Results:  The provided text is \"This user and this user, oh come on we all know that the Democrats put illegal aliens first, they do nothing for the American people, resign Pelosi.\"\n",
      "\n",
      "Reasoning:\n",
      "The text seems to express a strong political opinion against the Democratic party and specifically mentions \"illegal aliens\" without any positive or negative connotation. However, it does not directly devalue or attack a protected group based on race, gender, sexuality, religion, or disability. Instead, it criticizes the actions of a political party and a specific individual (Pelosi).\n",
      "\n",
      "Output: 0 (Normal)\n",
      "Sample 738 Results:  The provided text is: \"niggas be hating on immigrants but donâ€™t even got a license bro u worried about driving away the wrong foreigns ðŸ¤¦ðŸ¾â€â™‚ï¸\"\n",
      "\n",
      "Reasoning:\n",
      "The term \"nigga\" can be considered offensive towards black people. However, in this context, it seems to be used among a group of black individuals (as indicated by the use of \"niggas\"). The text is criticizing others for hypocrisy regarding immigration while not having their own legal documents in order. The criticism is directed at a behavior or action (\"hating on immigrants\") rather than a specific racial or ethnic group.\n",
      "\n",
      "However, it's important to note that the use of \"nigga\" can still be considered offensive and disrespectful, even when used among members of the same racial or ethnic group. The text also includes a reference to foreigners, but it does not seem to devalue or attack any specific protected groups based on race, gender, sexuality, religion, or disability.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 739 Results:  The provided text is: \"jews created communism <number> million stupid morons voted for the commie kike sanders\"\n",
      "\n",
      "Reasoning: This text directly targets a specific religious group (Jews) and makes false accusations about them creating communism. It also uses derogatory language (\"kike\") towards Jews, which is historically offensive. The addition of \"stupid morons voted for the commie kike sanders\" further devalues a political group (Sanders supporters). Therefore, this text can be classified as 'Hatespeech'.\n",
      "\n",
      "Output: 2\n",
      "Sample 740 Results:  The provided text \"another foreign born gay moslem\" can be interpreted as a statement that mentions multiple protected groups: foreign-born individuals, gay people, and Muslims. However, it does not seem to involve devaluation or direct an attack on these groups. Instead, it appears to be a descriptive phrase about a person's identity.\n",
      "\n",
      "Output: 0 (Normal)\n",
      "Sample 741 Results:  1 (Offensive)\n",
      "\n",
      "Reasoning: While the text expresses disdain for Stephen Miller, a former White House advisor, it does not specifically devalue or attack protected groups. However, the use of \"fucking psycho\" can be considered offensive due to its derogatory nature.\n",
      "Sample 742 Results:  The provided text, \"tfw how the daily stormer protects a spic like he some kind of god,\" can be classified as 'Hatespeech'. This is because it uses the derogatory term \"spic\" which is offensive towards Hispanic or Latino people. Additionally, the context suggests that the speaker views this group negatively and the use of \"daily stormer\" implies a connection to white supremacist groups. Therefore, the text involves devaluation of a protected group (Hispanics/Latinos) and is linked to race. Output: 2\n",
      "Sample 743 Results:  Based on the provided criteria, the text can be classified as 'Offensive' (1). The text is using derogatory language (\"idiot bot trudeau\") and making fun of someone's intelligence, but it does not specifically target a protected group based on race, gender, sexuality, religion, or disability. However, it is important to note that the use of such language can still be harmful and disrespectful. The numbers in the text are placeholders and do not affect the classification.\n",
      "Sample 744 Results:  The provided text \"to the mans who angrily but lovingly yelled get a helmet you fucking faggot at me yesterday you right and i love you\" is not directly devaluing or attacking any protected group based on gender, race, sexuality, religion, or disability. However, the term \"faggot\" is historically used as a derogatory slur against homosexual men. In this context, it seems to be used in an aggressive and potentially offensive manner, but it's not clear if it's intended as hatespeech towards the LGBTQ+ community.\n",
      "\n",
      "The text also contains a contradictory sentiment of anger and love, which might suggest a complex emotional dynamic between the speaker and the recipient that is not fully understood from this statement alone.\n",
      "\n",
      "Considering these factors, I would classify this text as '1 - Offensive'. It's important to note that context plays a significant role in determining whether a statement is offensive or not, and without additional information, it can be challenging to make a definitive judgment.\n",
      "Sample 745 Results:  The provided text is: \"any news on that nigga lorenzo when he hitting uk\"\n",
      "\n",
      "Reasoning:\n",
      "The term \"nigga\" can be considered offensive towards black people, but in this context, it seems to be used as a common name or nickname for an individual named Lorenzo. It does not appear to be used in a derogatory manner or as hatespeech against black people. However, the use of \"nigga\" can still be considered offensive by some due to its historical and cultural context.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 746 Results:  The provided text does not contain any derogatory or offensive language towards protected groups such as gender, race, sexuality, religion, or disability. It is a statement about a team's name, colors, location, and president. Therefore, the output should be 0, indicating that it is 'Normal'.\n",
      "\n",
      "However, the phrase \"anybody but Bruce Allen\" could potentially be interpreted as offensive if it implies dislike towards an individual named Bruce Allen without any context provided. But in this case, since it's related to a team president and no personal attacks are made, it can still be considered 'Normal'.\n",
      "Sample 747 Results:  The provided text is: \"just remembered that renee is a lesbian the dykes won this one\"\n",
      "\n",
      "Reasoning: This text mentions a specific protected group, i.e., lesbians, and uses a derogatory term (\"dykes\") to devalue them. However, it seems more like a casual comment or joke rather than an attack or direct insult. Therefore, it can be classified as 'Offensive' (1).\n",
      "Sample 748 Results:  The provided text is asking for help regarding the availability of facial plasters in different skin tones, specifically mentioning a black lady and white person. It does not seem to devalue or attack any protected group, but rather expresses a concern about representation in product offerings. Therefore, the output would be 0 (Normal).\n",
      "Sample 749 Results:  The provided text seems to be making a statement about pitbulls and violence, but it also includes references to social justice and privilege. However, it does not directly mention or devalue any specific protected groups based on gender, race, sexuality, religion, or disability. Therefore, the text can be classified as '0' - Normal.\n",
      "\n",
      "However, it's important to note that the phrase \"chickens coming home to roost\" has historical connotations related to blame and retribution, which some might find offensive or inappropriate. But in this context, it seems to be used metaphorically within a broader discussion about social justice and power dynamics.\n",
      "\n",
      "So, while the text is generally 'Normal', there are elements that could potentially be interpreted as offensive or inappropriate by some readers.\n",
      "Sample 750 Results:  The provided text seems to be a news headline or statement about certain events and individuals. It mentions QAnon, MAGA, fake news, Pope Francis, Cardinal Law, and the abuse of children by priests. However, it does not specifically target any protected group based on gender, race, sexuality, religion, or disability.\n",
      "\n",
      "Therefore, according to the given classification system, this text would be classified as '0' - Normal. It can be interpreted as a statement about controversial topics and individuals, but it does not involve devaluation or direct attacks on protected groups.\n",
      "Sample 751 Results:  2\n",
      "\n",
      "Reasoning: The text directly links to devaluation of a protected group (disability) and is used as an attack on another individual. It implies that Calyko and the user are both \"retarded,\" which is derogatory and disrespectful towards people with intellectual disabilities.\n",
      "Sample 752 Results:  The provided text is: \"ya it getting hard to normally function in many towns anymore with this ghetto mentality going on everywhere\"\n",
      "\n",
      "Reasoning:\n",
      "The term \"ghetto\" is often used as a pejorative to stereotype and devalue communities of color, particularly African American communities. However, in this context, the text does not specifically target or devalue any particular racial or ethnic group. Instead, it seems to express frustration about a perceived social issue that affects many towns.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 753 Results:  The provided text \"dawg i just seen a chinese dyke i did not even kno those existed\" can be classified as '1 - Offensive'.\n",
      "\n",
      "Reasoning: This statement uses derogatory language towards both Chinese people and the LGBTQ+ community, specifically targeting lesbians with the term \"dyke\". However, it does not explicitly devalue or attack these groups in a way that would classify it as 'Hatespeech'. Instead, it is used as an expression of surprise and discomfort, which can be considered offensive.\n",
      "Sample 754 Results:  Output: 0\n",
      "\n",
      "Reasoning: The text does not mention or devalue any protected groups, nor is it used to attack or devalue individuals based on their gender, race, sexuality, religion, or disability. It is a humorous reference to the popular movie \"Five Feet Apart\" and the current COVID-19 social distancing guidelines. The use of the term \"gay\" in this context is not derogatory but rather playful and non-discriminatory.\n",
      "Sample 755 Results:  The provided text does not directly mention or devalue any specific protected groups based on gender, race, sexuality, religion, or disability. However, it contains strong political rhetoric and potentially inflammatory language, such as \"communism\" and \"indoctrination.\" It also references Christianity, which could be perceived as targeting non-Christians or those who do not adhere to a specific religious belief.\n",
      "\n",
      "However, the text does not explicitly devalue or attack any particular group in a way that would classify it as hatespeech. Instead, it seems to be expressing a political viewpoint with strong language and potentially divisive rhetoric.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 756 Results:  The provided text does not mention any protected groups such as gender, race, sexuality, religion, or disability explicitly. However, the term \"slut\" can be considered offensive towards women. But it's important to note that the term is used in reference to a fictional character named Avdol from the anime series JoJo's Bizarre Adventure and his grandfather, not a real person. Therefore, the text can be classified as 'Offensive' with a score of 1.\n",
      "\n",
      "Reasoning: While \"slut\" can be considered offensive towards women, it is used in a fictional context and does not directly devalue or attack a specific individual or group. However, the term is still disrespectful and should be avoided in most conversations.\n",
      "Sample 757 Results:  2\n",
      "\n",
      "Reasoning: The text makes a generalization and devaluation of certain ethnic groups (Vietnamese, Mizoram, Assamese) by implying they are not genetically Indian. This statement is based on racial stereotypes and perpetuates harmful ideas about race and identity, which can be considered as hate speech.\n",
      "Sample 758 Results:  1 (Offensive)\n",
      "\n",
      "Reasoning: While \"nigga\" can be very offensive towards black people, in this context it is used as a general term to describe someone, not specifically directed at a particular individual or group. However, the use of \"dumb\" as an insult makes the text toxic. It's important to note that while this text may not meet the criteria for hatespeech, it still contains language that can be harmful and disrespectful.\n",
      "Sample 759 Results:  The provided text is: \"<user> <user> but answer the question first ya is Islam mein sawaal puchna bhi haraam hai\"\n",
      "\n",
      "Reasoning: This text does not mention or involve devaluation of any protected groups such as gender, race, sexuality, religion, or disability. It seems to be a conversation between users discussing a question and stating that asking questions in Islam might be forbidden (haram). Therefore, the output is 0 (Normal).\n",
      "Sample 760 Results:  The provided text contains multiple offensive elements, including racial slurs (\"nigger\"), derogatory language towards people with disabilities (\"chimp\"), and hate speech against the LGBTQ+ community (\"gay bar\"). It also includes a statement that could be interpreted as threatening or promoting violence (\"Iran has nukes\").\n",
      "\n",
      "However, it's important to note that this text does not specifically target a protected group based on gender, race, sexuality, religion, or disability in a way that would classify it as \"Hatespeech\" according to the provided criteria. Instead, it uses offensive language and hate speech against multiple groups.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 761 Results:  The provided text does not mention any protected groups, nor does it involve devaluation or direct an attack towards them. It seems to be a statement about people's immigration status on campus. Therefore, based on the given classification system, the output would be 0, indicating that the text is 'Normal'.\n",
      "\n",
      "However, it's important to note that context can greatly influence the interpretation of a text. For example, if the term \"immigrants\" was used in a derogatory or discriminatory manner, it could potentially fall under the category of 'Offensive' or even 'Hatespeech'. But without such context provided, it is difficult to classify the text as anything other than 'Normal' based on the given information.\n",
      "Sample 762 Results:  The provided text is: \"a nigga have a baby on me i swear i â€™ ll take out the whole family sorry not sorry ðŸ˜‹ ðŸ—¡\"\n",
      "\n",
      "Reasoning: This text contains the racial slur \"nigga\", which is highly offensive towards black people. Additionally, the threat of violence against an individual and their family can be interpreted as a direct attack on a protected group (in this case, black people). Therefore, it falls under the category of 'Hatespeech'.\n",
      "\n",
      "Output: 2\n",
      "Sample 763 Results:  2\n",
      "\n",
      "Reasoning: The text directly links race (\"white\") and a derogatory term (\"nigger\") in a way that devalues and attacks a specific racial group, which falls under the category of hatespeech.\n",
      "Sample 764 Results:  The provided text is: \"a chinaman he forced to sell we got it for pennies on the dollar b noir detour\"\n",
      "\n",
      "Reasoning: This text seems to refer to a Chinese individual being forced into selling something at a low price. The term \"chinaman\" is historically and culturally offensive towards people of East Asian descent, as it reduces them to stereotypes rather than recognizing their individuality. Furthermore, the phrase \"we got it for pennies on the dollar\" implies that the Chinese individual was taken advantage of financially, which could be seen as devaluing a protected group based on race.\n",
      "\n",
      "Output: 2 (Hatespeech)\n",
      "Sample 765 Results:  The provided text does not specifically target any protected group based on gender, race, sexuality, religion, or disability. It seems to be a humorous comment about British people living abroad, comparing them to Jesus and expats. However, the use of \"many\" before \"British\" could potentially be seen as generalizing all British people, which might not be appreciated by everyone.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 766 Results:  The provided text, \"fuck off we have more than enough muzzies to deal with,\" can be interpreted as a form of hate speech. It directly targets people of the Muslim faith by using a derogatory term (\"muzzies\") and expresses an unwelcoming or hostile sentiment towards them. Therefore, the output would be: 2 (Hatespeech).\n",
      "Sample 767 Results:  The provided text suggests a comparison between modern society and Muslim countries, implying that there might be a future where men and women are segregated. However, it does not directly devalue or attack any specific protected group based on gender, race, sexuality, religion, or disability. Therefore, the output would be 0 (Normal).\n",
      "\n",
      "However, it's important to note that this text could potentially be interpreted as offensive or insensitive due to its reference to segregation, which is a practice associated with discrimination and marginalization in certain contexts. It's always crucial to consider the broader social and cultural implications of our words and actions.\n",
      "Sample 768 Results:  The provided text \"if you still support the small handed nazi nut bag you â€™ re one sick ignorant racist mother fucker fucktrumpsupporters\" can be classified as 'Hatespeech'. This is because it directly targets a specific group (Trump supporters, which can be linked to political affiliation) and uses derogatory language to devalue them. The use of the term \"nazi\" is also associated with a protected group (Jews during the Holocaust), even though in this context it's used metaphorically to insult Trump supporters. The text shows hostility, contempt, and intolerance towards a specific group, which are characteristics of hatespeech. Therefore, Output: 2.\n",
      "Sample 769 Results:  The provided text contains multiple instances of offensive language, including the use of racial slurs (\"nigger\") and derogatory terms for sexual orientation (\"gay\"). Additionally, the user seems to be using these terms as a form of self-identification, which can be seen as a form of self-degradation. However, it's important to note that the text does not specifically target or devalue any protected group based on race, gender, sexuality, religion, or disability.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 770 Results:  The provided text seems to be targeting a specific group, \"illegal aliens.\" However, it doesn't directly devalue or attack them based on their race, gender, sexuality, religion, or disability. Instead, it criticizes their legal status. Therefore, the text can be classified as '1 - Offensive.'\n",
      "\n",
      "Reasoning: While the statement implies a negative view towards \"illegal aliens,\" it doesn't involve devaluation of protected groups in the traditional sense. However, the tone and language used are disrespectful and could potentially stir up prejudice or discrimination against this group.\n",
      "Sample 771 Results:  The provided text contains multiple instances that can be considered as hate speech. It targets protected groups such as Muslims, immigrants, and the Democratic party. The use of derogatory terms like \"barbarians,\" \"cult sharia law,\" and \"ohell\" to describe Muslims is devaluing and discriminatory. The statement also implies that all Muslims are a threat to America, which is not only offensive but also promotes fear and hostility towards this particular group.\n",
      "\n",
      "The text also contains derogatory language towards the Democratic party, referring to them as \"tyranny\" and accusing them of loving women who are not slaves in America. This statement is offensive and disrespectful towards a political party and its supporters.\n",
      "\n",
      "Lastly, the statement suggests that armed women are necessary for their protection, which can be interpreted as promoting violence against women and implying that they are vulnerable or in danger.\n",
      "\n",
      "Output: 2 (Hatespeech)\n",
      "Sample 772 Results:  The provided text \"<user> looks more like white trailer trash\" can be interpreted as offensive, but it does not specifically involve devaluation of a protected group based on race or disability. It is used as an insult against the user's perceived social class or lifestyle, which can be considered derogatory and disrespectful.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 773 Results:  The provided text seems to compare two species, bonobos and chimpanzees, using colloquial and potentially offensive language (\"pussy\" and \"ghetto drug dealer\"). However, it does not specifically target or devalue any protected groups based on gender, race, sexuality, religion, or disability.\n",
      "\n",
      "Therefore, according to the provided classification system, this text would be classified as '0' - Normal. The reasoning is that while the language used might be considered inappropriate or disrespectful, it does not meet the criteria for hatespeech as defined in the system.\n",
      "Sample 774 Results:  The provided text does not specifically target or devalue any protected groups. It expresses frustration about a situation related to non-binary culture, but it doesn't involve devaluation or an attack on this group. Therefore, the output would be 0, indicating that the text is 'Normal'.\n",
      "Sample 775 Results:  The provided text does not contain any direct reference or devaluation of protected groups such as gender, race, sexuality, religion, or disability. It seems to be a common phrase used in informal communication, expressing disagreement with someone who might have given false information. Therefore, the output should be '0' (Normal).\n",
      "\n",
      "However, it's important to note that context can greatly influence the interpretation of text. If this phrase was used in a way that could be perceived as offensive or disrespectful towards a specific group, then it may not fall under the 'Normal' category. But based on the provided example and without additional context, it appears to be a normal statement.\n",
      "Sample 776 Results:  This text contains racial slurs (\"sheboon\") and derogatory language (\"diss\"), which can be offensive towards black people. However, it does not specifically target a specific individual or group, but rather seems to be part of a conversation or dialogue. Therefore, the output would be 1 (Offensive).\n",
      "\n",
      "However, if we consider the number in the text as a replacement for a racial slur, then the text could potentially be interpreted as hatespeech due to the use of a racial slur and derogatory language towards black people. In this case, the output would be 2 (Hatespeech).\n",
      "\n",
      "It's important to note that context plays a significant role in determining whether a statement is considered hatespeech or offensive. In this case, without additional context, it's difficult to definitively classify the text as either hatespeech or offensive.\n",
      "Sample 777 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The text does not mention or devalue any protected groups, nor is it used as an insult against individuals. It's a simple statement about dinosaurs and humans, which doesn't fall under the categories of hatespeech or offensive language.\n",
      "Sample 778 Results:  The provided text, \"not to mention eating beans and a nigger work song\", contains the racial slur \"nigger\". This term is highly offensive towards black people. In this context, it seems to be used in reference to a historical racist song that involves the word \"nigger\" (a derogatory term for African Americans). Therefore, the output should be:\n",
      "\n",
      "Output: 2 (Hatespeech)\n",
      "Sample 779 Results:  The provided text \"<user> did not understand it tho you going hoe\" is not directly related to any protected groups such as gender, race, sexuality, religion, or disability. It seems to be an informal way of expressing frustration or annoyance towards the user. Therefore, based on the given classification system, this text can be classified as '0' - Normal.\n",
      "Sample 780 Results:  The provided text does not directly mention or devalue any protected groups based on gender, race, sexuality, religion, or disability. However, it does seem to be critical of a man for his actions towards a woman, specifically for rape, sexual assault, and infidelity. While this text might be perceived as offensive due to the serious nature of the accusations, it is not hatespeech as defined in the provided criteria.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 781 Results:  The provided text contains several elements that could be considered offensive or hateful. It targets specific religious groups (Jews, Muslims) and ethnicities (Jewish people, Christian people), and also includes derogatory language (\"dog\"). However, it's important to note that the text is not just an insult against individuals but seems to express a broader conspiracy theory.\n",
      "\n",
      "In this context, the text can be interpreted as devaluing protected groups based on their religion and ethnicity, which aligns with the definition of hatespeech provided. However, it's also important to consider that the text is not just about devaluation but also includes a narrative that could be seen as attacking these groups collectively.\n",
      "\n",
      "Output: 2 (Hatespeech)\n",
      "Sample 782 Results:  The provided text is: \"me you know what they say about people with big hands and big feet wife they â€™ re retarded me okay\"\n",
      "\n",
      "Reasoning: This text seems to be making a generalization about people with certain physical characteristics, linking it to intellectual disability. However, it's not directly targeting or devaluing a specific protected group based on race, gender, sexuality, religion, or disability. Instead, it appears to be a joke or stereotype, which can still be offensive but may not necessarily qualify as hatespeech.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 783 Results:  The provided text is: \"<user> i rly enjoying this gay moment of urs\"\n",
      "\n",
      "Reasoning: This text does not involve devaluation or direct an attack on any protected group, such as sexuality. Instead, it seems to express enjoyment towards a perceived \"gay moment\". Therefore, the output should be '0' (Normal).\n",
      "Sample 784 Results:  To classify the provided text, let's break it down:\n",
      "\n",
      "1. The term \"shaslum\" and \"ghetto\" can be perceived as derogatory or offensive, but they do not specifically target a protected group based on race, gender, sexuality, religion, or disability. Instead, they seem to be used as general insults.\n",
      "\n",
      "2. The phrase \"muh meh\" is a meme term and does not have any direct relation to any protected groups.\n",
      "\n",
      "3. The name \"Andy Cemhight\" does not indicate any affiliation with a specific protected group.\n",
      "\n",
      "4. The statement \"free speech is not just for losers\" can be interpreted as a controversial opinion, but it doesn't directly devalue or attack any protected group.\n",
      "\n",
      "Given the above analysis, the text seems to be more offensive than hatespeech. However, it's important to note that context plays a significant role in determining whether a statement is hate speech or not. In this case, without additional context, it's challenging to definitively classify the text as either hatespeech or normal.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 785 Results:  The provided text seems to be a response or argument, and it doesn't directly use derogatory language towards any specific protected group. However, the term \"bigot\" is used as an insult, which can be perceived as offensive. But it's not clear if the user is specifically targeting a certain group with this term.\n",
      "\n",
      "The text also includes a statement about loving one's country, which could potentially be interpreted as a reference to race or nationality, but without more context, it's hard to definitively classify it as hatespeech.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 786 Results:  This text does not mention or involve devaluation of any protected groups, nor is it used as an insult against individuals. It seems to be a casual conversation about the number of Muslims in the world. Therefore, based on the provided classification system, this text would be classified as '0' - Normal.\n",
      "\n",
      "However, it's important to note that context can greatly influence the interpretation of a statement. For example, if the conversation was about something related to Islam or Muslims and the number was used in a derogatory manner, it could potentially be considered offensive or even hatespeech. But based on the provided text alone, it appears to be a simple statement about population statistics.\n",
      "Sample 787 Results:  The provided text is: \"starting to lose more and more faith in black men each day ðŸ˜ ðŸ¥´\"\n",
      "\n",
      "Reasoning: This statement expresses a negative sentiment towards a specific racial group, which could be interpreted as devaluation. However, it does not directly attack or insult individual black men, nor does it advocate for harm or discrimination against them. It is more of a personal opinion or sentiment expressed by the author.\n",
      "\n",
      "Output (number only): 1 - Offensive\n",
      "Sample 788 Results:  The provided text \"hey liberals i am an immigrant and i hate niggers triggered yet snowflakes ðŸ˜‚ ðŸ˜‚ ðŸ˜‚ ðŸ˜‚\" contains the term \"nigger\", which is highly offensive towards black people. In this context, it seems to be used as a racial slur. Additionally, the phrase \"i hate niggers\" directly devalues and attacks a protected group (black people). Therefore, according to the given classification system, the output would be:\n",
      "\n",
      "Output: 2 (Hatespeech)\n",
      "Sample 789 Results:  The provided text \"barn full of white bitches\" can be interpreted as devaluing a protected group based on race and gender, therefore it falls under the category of 'Hatespeech'. Output: 2\n",
      "Sample 790 Results:  The provided text directly targets and devalues a specific ethnic group (Latino) by using the term \"illegal alien.\" This is a derogatory and offensive term that links to race. Therefore, the output for this text would be '1 - Offensive.'\n",
      "Sample 791 Results:  The provided text does not specifically target or devalue a protected group based on gender, race, sexuality, religion, or disability. Instead, it seems to be an observation about a person's appearance and gender identity. Therefore, the output would be 0, indicating that the text is 'Normal'. However, it's important to note that using terms like \"butch dyke\" might still be considered offensive or disrespectful by some individuals within the LGBTQ+ community due to potential stereotypes or misconceptions. It's always crucial to communicate with empathy and respect towards others.\n",
      "Sample 792 Results:  The provided text seems to be discussing a complex social issue, specifically the perception of certain groups (presumably black men and LGBTQ+ individuals) and their treatment by others. However, it does not appear to directly devalue or attack any specific protected group. Instead, it seems to be critiquing societal conditioning and prejudice.\n",
      "\n",
      "Therefore, based on the provided classification system, this text would fall under '0' - Normal. It is important to note that while this text may not meet the criteria for hatespeech or offensive language, it does touch upon sensitive topics and could potentially be interpreted as inflammatory or divisive by some readers.\n",
      "\n",
      "However, without additional context, it is difficult to definitively classify this text as '0' - Normal with absolute certainty. It is always crucial to consider the broader social and historical context when evaluating such texts.\n",
      "Sample 793 Results:  The provided text is: \"wth i got kicked off twitter all i did was say ghetto hood rat on snop doggs photo of a trump photo\"\n",
      "\n",
      "Reasoning: In this context, the term \"ghetto hood rat\" can be interpreted as devaluing or stereotyping a specific racial group (African-American women). However, it is important to note that the term was used in response to a photo of Snopp Dogg with Trump, which could be seen as a political statement rather than a direct attack on African-Americans.\n",
      "\n",
      "However, the use of the term \"ghetto hood rat\" can still be considered offensive due to its negative connotations and potential for reinforcing harmful stereotypes. Therefore, while it may not meet the strict definition of hatespeech (directly devaluing or attacking a protected group), it is still inappropriate and disrespectful language.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 794 Results:  The provided text \"tsekk faggot kike puppet\" contains derogatory slurs towards Jewish people (\"kike\") and the LGBTQ+ community (\"faggot\"). These terms are historically used as hate speech to devalue and attack these protected groups. Therefore, the output would be '2' for Hatespeech.\n",
      "Sample 795 Results:  The provided text \"um but you do realize that jesus was a kike\" is using the term \"kike,\" which is historically and currently offensive to Jewish people. It's used as an ethnic slur against Jews, and in this context it seems to be used to devalue or attack a specific religious group. Therefore, according to the provided classification system, the output would be:\n",
      "\n",
      "Output: 2 (Hatespeech)\n",
      "Sample 796 Results:  The provided text directly targets a specific group, \"white supremacist, nazi, radical evangelical,\" which is linked to race and religion. It also implies negativity towards this group (\"bigoted pos road rage waiting to happen\"). Therefore, according to the given classification system, the output would be '2' as it involves devaluation of a protected group (race and religion).\n",
      "Sample 797 Results:  2\n",
      "\n",
      "Reasoning: The text directly targets and devalues multiple protected groups, including Muslims, people of color, and individuals with disabilities. It also encourages violence against a specific group based on their religion, which is a clear example of hate speech.\n",
      "Sample 798 Results:  Based on the provided context, this text seems to be discussing the usage of a racial slur among certain groups. However, it does not appear to directly devalue or attack any protected group. Instead, the user is questioning the necessity of using such language. Therefore, the output would be 0 (Normal).\n",
      "\n",
      "However, it's important to note that while this text may not meet the criteria for 'Hatespeech' or 'Offensive', it does involve a racial slur which can still be harmful and offensive in many contexts. It's always crucial to promote respectful and inclusive language in all conversations.\n",
      "Sample 799 Results:  This text contains multiple instances of offensive language, including the use of racial slurs (\"white\" and \"nigger\"). However, it's important to note that the context seems to be self-deprecating, with the author stating they live in a \"white nigger ghetto\" and claiming no affiliation with such a place. This could potentially be interpreted as an attempt at humor or satire, although it is still offensive due to the use of racial slurs.\n",
      "\n",
      "However, without more context or understanding of the author's intent, it's difficult to definitively classify this text as hatespeech (2) or normal (0). It seems to fall somewhere in between, leaning towards offensive (1) due to the use of racial slurs, even if they are used in a self-deprecating manner.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 800 Results:  The provided text does not specifically target any protected group based on gender, race, sexuality, religion, or disability. However, the statement seems to express a negative sentiment towards immigrants and America, which could be perceived as offensive due to its generalization. But it doesn't involve devaluation of these groups, so I would classify this text as '1 - Offensive'.\n",
      "\n",
      "Reasoning: The text mentions immigrants in a negative context, but it does not single out any specific group based on protected characteristics. Furthermore, the statement implies that Putin is right about America ruining itself, which could be seen as critical or disrespectful towards the country and its people. However, there's no direct devaluation of any particular group in this text.\n",
      "Sample 801 Results:  The provided text contains homophobic slurs (\"faggot basher\") and offensive language (\"stupid\", \"fucking\"). However, it does not specifically target or devalue a protected group based on sexuality. Instead, it seems to be a personal insult directed towards the user. Therefore, the output should be 1 (Offensive).\n",
      "Sample 802 Results:  Output: 0 (Normal)\n",
      "\n",
      "Reasoning: The text does not involve devaluation or direct an attack on any protected groups such as gender, race, sexuality, religion, or disability. Instead, it encourages gathering a list of female POC queer brewery representatives and advocating for equality in craft brewing. It promotes unity and inclusion rather than hate speech or offense.\n",
      "Sample 803 Results:  The provided text \"but imma have to get ghetto and start picking from the medsci building\" does not specifically target or devalue any protected group. It seems to be using the term \"ghetto\" in a colloquial sense, possibly referring to a rough or disadvantaged area, and \"picking\" might refer to stealing or taking something. However, without additional context, it's hard to definitively classify this text as 'Hatespeech', 'Offensive', or 'Normal'.\n",
      "\n",
      "Output: 0 (Normal) - This text can't be interpreted as hatespeech based on the provided information and common usage of these terms. However, it's important to note that context plays a significant role in determining whether a statement is offensive or not.\n",
      "Sample 804 Results:  The provided text, \"that unfortunate the dancing jiggaboo with the tambourine was pretty entertaining,\" can be classified as '1 - Offensive.'\n",
      "\n",
      "Reasoning: The term \"jiggaboo\" is a racial slur historically used to demean African Americans. While it's not explicitly clear whether the person being referred to is African American, the use of this derogatory term indicates an intent to offend or devalue a protected group based on race. However, the phrase \"unfortunate\" and \"entertaining\" might suggest that the speaker has mixed feelings about the situation, which could complicate the classification as 'Hatespeech.' Nevertheless, the use of the slur is offensive and inappropriate.\n",
      "Sample 805 Results:  The provided text, \"these filthy yellow color jews jelly of our ivory color skin,\" directly targets a specific religious group (Jews) and devalues them based on their ethnicity (yellow). It also implies jealousy towards another racial group (white/ivory), which can be seen as an attempt to create division and promote prejudice. Therefore, the output should be '2' for Hatespeech.\n",
      "Sample 806 Results:  The provided text contains derogatory language towards Jewish people, specifically using the term \"kike\" which is widely considered a racial slur against Jews. This text can be classified as 'Hatespeech' because it directly targets and devalues a protected group based on their religion.\n",
      "\n",
      "Output: 2\n",
      "Sample 807 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The term \"white pill\" is a phrase often used in online communities to refer to accepting or facing harsh truths, especially those that are difficult to accept. It doesn't specifically target any protected group or involve devaluation of any group based on race, gender, sexuality, religion, or disability.\n",
      "Sample 808 Results:  The provided text does not specifically target any protected group or individuals, and it doesn't involve devaluation. It seems like a casual comment about a business idea. Therefore, the output would be 0, indicating that the text is 'Normal'. However, it's important to note that this interpretation assumes good faith on the part of the user making the statement. If there were additional context suggesting otherwise, the classification could change.\n",
      "Sample 809 Results:  1 (Offensive)\n",
      "\n",
      "Reasoning: The text contains derogatory language (\"lard ass\") and a generalized insult towards women (\"learn to read clearly\"). However, it does not specifically target a protected group based on gender, race, sexuality, religion, or disability. It is offensive due to the use of disrespectful and demeaning language.\n",
      "Sample 810 Results:  Output: 0\n",
      "\n",
      "Reasoning: The provided text, \"gay moslem support group\", does not contain any derogatory or offensive language towards protected groups such as gender, race, sexuality, religion, or disability. Instead, it seems to be a description of a supportive community for individuals who identify as both gay and Muslim. Therefore, it can't be interpreted as hatespeech or offensive.\n",
      "Sample 811 Results:  The provided text \"when a hoe wants to talk about morals ðŸ˜‚\" does not specifically target or devalue any protected group. It is used as a colloquial term and humor, although it may be considered disrespectful or offensive by some. However, the intent of the text does not seem to involve devaluation or directing an attack on any specific group.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 812 Results:  The provided text uses a derogatory slur (\"faggots\") towards the LGBTQ+ community, which is a protected group. However, it's important to note that the intent of the text isn't clear as it doesn't explicitly devalue or attack the LGBTQ+ community. Instead, it seems to be used as an insult against the other user.\n",
      "\n",
      "Given the context and the definition provided, this text can be classified as '1 - Offensive'. It's important to remember that using such language is harmful and disrespectful, even if not intended as hatespeech.\n",
      "Sample 813 Results:  The provided text, \"whatever happened to allegations Fox was involved with beaner drug cartels,\" can be interpreted as offensive due to the use of the term \"beaner.\" This term is historically derogatory and stereotypical towards Hispanic or Latino individuals. However, it does not specifically involve devaluation or an attack on a protected group in this context. It's more about the content of the allegations rather than targeting a specific individual or group.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 814 Results:  The provided text \"so heartless bitch i hate you i can not believe you did me\" does not specifically target a protected group based on gender, race, sexuality, religion, or disability. However, the use of the term \"bitch\" can be considered offensive and disrespectful towards women.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 815 Results:  The provided text contains multiple instances of offensive language and hate speech. It devalues and attacks protected groups based on race, religion, and potentially ethnicity. Specifically, the repeated use of the racial slur \"nigga\" is highly offensive towards black people. The phrase \"ye olde niggra tax\" implies that there is a financial burden (tax) specifically targeted towards black people, which is a form of devaluation and discrimination.\n",
      "\n",
      "The text also contains hate speech against Muslims, as it suggests that in a perfect world, they would harm or attack blacks, which is a direct attack on the Muslim community. The use of the phrase \"<happy>\" after these statements implies a sense of satisfaction or approval towards the suggested violence, further escalating the level of offense and hate speech.\n",
      "\n",
      "Output: 2 (Hatespeech)\n",
      "Sample 816 Results:  The provided text \"this retarded nazi think that i said hitler banned guns is their any hope for these liberal socialists i think not\" can be classified as '1 - Offensive'.\n",
      "\n",
      "Reasoning:\n",
      "- The term \"retarded\" is often used in a derogatory manner towards people with intellectual disabilities. However, in this context, it seems to be used as an insult against the individual, rather than devaluing or targeting people with intellectual disabilities as a group.\n",
      "- The use of \"nazi\" can be seen as offensive due to its historical connotations and negative associations with extremist ideologies. In this context, it is used to criticize the individual's beliefs, not to promote hate speech against any specific protected group.\n",
      "- The phrase \"liberal socialists\" could potentially be interpreted as a derogatory term towards political groups, but without further context, it's difficult to definitively classify it as such.\n",
      "\n",
      "Overall, while the text contains offensive language, it does not specifically involve devaluation of protected groups or direct attacks on them, making it '1 - Offensive'.\n",
      "Sample 817 Results:  Output: 0\n",
      "\n",
      "Reasoning: The text is suggesting a costume idea, and while \"slutty\" can be considered offensive or inappropriate due to its sexual connotation, it does not devalue or attack any specific group based on gender, race, sexuality, religion, or disability. It's important to note that the intent of the text seems to be playful and not intended as hate speech or offensive towards a protected group.\n",
      "Sample 818 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The text does not involve devaluation or direct an attack on any protected groups such as race, gender, sexuality, religion, or disability. Instead, it expresses a concern about the plight of white farmers in South Africa, which is a political and social issue rather than hate speech or offensive language.\n",
      "Sample 819 Results:  The provided text contains multiple derogatory and offensive statements towards various groups, including Muslims, people with syphilis, and the police. It also includes hate speech targeting these groups by using slurs and making generalizations that devalue them. Therefore, the output for this text would be '2' as it meets the criteria of hatespeech.\n",
      "Sample 820 Results:  The provided text is a question about the number of \"illegal aliens\" in a state, addressed to the governor. It does not contain any derogatory or offensive language towards a protected group based on race, gender, sexuality, religion, or disability. Therefore, according to the given classification system, it would be classified as 'Normal' (Output: 0).\n",
      "\n",
      "However, it's important to note that the term \"illegal alien\" is often considered controversial and offensive by some, as it can be perceived as dehumanizing undocumented immigrants. Some prefer to use terms like \"undocumented immigrant\" instead. But in this specific context, without additional derogatory or offensive language, it doesn't meet the criteria for 'Hatespeech' or 'Offensive'.\n",
      "Sample 821 Results:  2\n",
      "\n",
      "Reasoning: The text directly targets a specific group, \"the retarded liberal media,\" using derogatory language (\"retarded\") and suggesting violence against them. This can be considered as hate speech towards people with intellectual disabilities and those who identify as liberal.\n",
      "Sample 822 Results:  The provided text is: \"bitches act like a nigga do not got feelings\"\n",
      "\n",
      "Reasoning: This text uses the term \"nigga,\" which can be considered offensive towards black people. However, in this context, it seems to be used as an insult against women (the use of \"bitches\") rather than a racial slur directed at black people. The phrase \"do not got feelings\" could be interpreted as devaluing or belittling women's emotions, which is offensive.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 823 Results:  Output: 0 (Normal)\n",
      "\n",
      "Reasoning: The text does not mention or devalue any protected groups, nor is it used in a derogatory manner. It appears to be a statement about a general rule regarding left vs right violence, which is not inherently offensive.\n",
      "Sample 824 Results:  The provided text contains racial slurs and derogatory language towards a specific ethnic group, which can be considered offensive and potentially hate speech. However, it is important to note that the context of the statement suggests it is celebrating the overthrow of a political figure, Bob Mugabe, who was known for his controversial policies and human rights abuses. This could be interpreted as a form of political commentary rather than a direct attack on the ethnic group in question.\n",
      "\n",
      "However, the use of racial slurs and derogatory language is still offensive and disrespectful, and it is important to remember that such language has been used historically to dehumanize and justify violence against marginalized groups. Therefore, I would classify this text as 1 - Offensive. It is crucial to promote respectful and inclusive language in all forms of communication.\n",
      "Sample 825 Results:  The provided text \"<user> send me fat girls and I will become even gayer vro\" does not specifically target a protected group based on gender, race, sexuality, religion, or disability. It is more of a personal preference expressed in a casual, humorous manner. However, it could be considered offensive due to the objectification of women based on their physical appearance.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 826 Results:  The provided text contains multiple derogatory and offensive terms towards a specific ethnic group (Rohingya Muslims) and other groups, including racial slurs (\"retarded\"), religious slurs (\"terrorists\"), and ableist slurs (\"retarded\"). This text can be classified as 'Hatespeech' (2). It not only mentions but also involves devaluation of a protected group (Rohingya Muslims) and uses offensive language towards other groups.\n",
      "Sample 827 Results:  The provided text does not specifically mention or devalue a protected group based on gender, race, sexuality, religion, or disability. However, it could be interpreted as implying that Muslim women are excluded from the celebration of International Women's Day. This might be seen as offensive or exclusionary towards Muslim women.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 828 Results:  The provided text \"so me being African doesn't give me the pass to understand more, can do research and know what's appropriate and what's not ðŸ¤¡ some white people are so funny\" does not specifically target a protected group or involve devaluation. Instead, it seems to be expressing frustration about cultural understanding and humor, with a hint of sarcasm.\n",
      "\n",
      "Output: 0 (Normal)\n",
      "Sample 829 Results:  The provided text seems to express a political viewpoint, but it also contains derogatory language towards certain groups such as \"blacks,\" \"Muslims,\" and \"victim groups.\" However, the text does not specifically devalue or attack these groups based on their race, religion, gender, or disability. Instead, it seems to be using these terms as a way to categorize and criticize political ideologies.\n",
      "\n",
      "Therefore, according to the provided classification system, this text would fall under category 1: Offensive. It is important to note that while this text may not meet the criteria for hatespeech, it still contains language that can be harmful and divisive.\n",
      "Sample 830 Results:  The provided text seems to be about personal experiences, self-identification, and humor. It doesn't appear to devalue or attack any specific protected group based on race, gender, sexuality, religion, or disability. Instead, it describes the speaker's background and interests in a lighthearted manner.\n",
      "\n",
      "Output: 0 (Normal)\n",
      "Sample 831 Results:  The provided text \"confess it was the naked negress tits when you were young\" can be classified as 'Hatespeech'. This statement not only mentions but also involves devaluation of a protected group, in this case, race (black people). The term \"negress\" is historically and culturally offensive towards black women. Additionally, the use of \"tits\" objectifies women, which can be seen as degrading and disrespectful. Therefore, the output for this text would be '2'.\n",
      "Sample 832 Results:  The provided text \"thots am retarded\" can be interpreted as offensive, but it does not specifically target a protected group such as gender, race, sexuality, religion, or disability. The term \"thots\" is often used in a derogatory manner towards women, but in this context, it's not directly linked to devaluation of women. However, the use of \"retarded\" can be seen as disrespectful and offensive towards people with intellectual disabilities.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 833 Results:  The text \"do not be a retarded tool and do your research before you start defaming people who are just trying to tell you the truth\" can be interpreted as offensive due to the use of the term \"retarded\" which is often used in a derogatory manner towards individuals with intellectual disabilities. However, it does not specifically target or devalue a protected group, so it falls under category 1 - Offensive.\n",
      "Sample 834 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The text is discussing a hypothetical situation about the physical resemblance of two individuals in a TV show, \"Stranger Things,\" and comparing them to other characters. There's no devaluation or direct attack on any protected group based on race, gender, sexuality, religion, or disability. It's simply a casual conversation about a pop culture reference.\n",
      "Sample 835 Results:  Output: 0\n",
      "\n",
      "Reasoning: The statement does not involve any devaluation or attack on protected groups such as gender, race, sexuality, religion, or disability. Instead, it expresses admiration towards the individual Zayn Malik. While \"fucking\" can be considered strong language, it is not used in a derogatory manner towards anyone or anything specific. Therefore, it falls under the 'Normal' category.\n",
      "Sample 836 Results:  0\n",
      "\n",
      "Reasoning: The statement does not involve devaluation or direct attack towards any protected groups such as gender, race, sexuality, religion, or disability. It simply states a perceived similarity between two individuals and the religion they might practice. Without further context, it cannot be classified as hatespeech or offensive.\n",
      "Sample 837 Results:  Output: 1\n",
      "\n",
      "Reasoning: The text uses derogatory terms (\"brainless\", \"retarded\") which can be considered offensive towards people with intellectual disabilities. However, it does not specifically target a particular group or individual, and the intent seems to be an insult rather than hate speech.\n",
      "Sample 838 Results:  The provided text seems to be comparing different groups, including Sharialaw, HRC (presumably Hillary Clinton), YourPizzaScooked (possibly a derogatory term for a specific group or individual), and \"radical Islamic terrorists.\" However, it does not specifically target any protected group based on gender, race, sexuality, religion, or disability.\n",
      "\n",
      "The text does contain some potentially offensive language (\"huma\" might be a derogatory term), but it's not used in a way that devalues or attacks a specific protected group. Therefore, according to the provided classification system, the output would be:\n",
      "\n",
      "Output (number only): 1 - Offensive\n",
      "Sample 839 Results:  2\n",
      "\n",
      "Reasoning: The text directly targets and devalues a specific religious group, Jews. It uses derogatory language (\"kike\") and accuses them of intentionally trying to \"tear down society.\" This fits the definition of hatespeech as it involves devaluation of a protected group (religion).\n",
      "Sample 840 Results:  The provided text clearly targets and devalues a protected group based on race, which is African Americans. It also expresses a negative view towards abortion for this specific group, implying that their lives are not valued as highly as others. This can be considered as hate speech.\n",
      "\n",
      "Output: 2\n",
      "Sample 841 Results:  The provided text contains racial slurs (\"nigger\") which are highly offensive and can be interpreted as devaluing a protected group (in this case, people of African descent). However, the context suggests that the text is not just about devaluing the group but also includes derogatory comments towards an individual named Tariq. Therefore, it seems to involve both personal attack and racial slurs.\n",
      "\n",
      "Output: 2 (Hatespeech)\n",
      "Sample 842 Results:  The provided text is: \"this nigga thanos done killed aquaman\". In this context, the term \"nigga\" is used in a colloquial and informal manner, often associated with hip-hop culture. It's important to note that the usage of this term can be offensive to some people, but it doesn't necessarily involve devaluation or an attack on a specific racial group.\n",
      "\n",
      "In this case, the text is referring to fictional characters Thanos and Aquaman from Marvel Comics, not real individuals. Therefore, it does not specifically target any protected groups.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 843 Results:  Output: 1\n",
      "\n",
      "Reasoning: The text does not specifically mention or devalue any protected groups. It is asking someone to post something that could be considered inappropriate, but it doesn't directly involve hatespeech or offensive language towards a specific group. However, the request for advocating for violence can be seen as problematic and inappropriate.\n",
      "Sample 844 Results:  The provided text \"the barbecue sauce comment really affected my psyche but you do not want to fight a gay cannibal\" does not specifically target any protected group or involve devaluation. It is more of a humorous or exaggerated statement, and while it might contain offensive language (\"gay\"), it is not used in a derogatory manner towards the LGBTQ+ community.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 845 Results:  The provided text seems to express a concern about immigration diversity, suggesting that only \"vetted immigrants\" will be allowed in the future. While it doesn't directly target any specific protected group, it could potentially be interpreted as implying bias against certain groups or cultures. However, without explicit devaluation or direct attacks on protected groups, I would classify this text as '1 - Offensive'.\n",
      "\n",
      "Reasoning: The text expresses a concern about diversity in immigration, which could potentially be perceived as biased or exclusionary towards certain groups. However, it does not explicitly devalue or attack any specific protected group, making it 'Offensive' rather than 'Hatespeech'.\n",
      "Sample 846 Results:  0 (Normal)\n",
      "Reasoning: The text is a common greeting, using the term \"baby gays\" in a friendly and non-offensive manner. It does not involve devaluation or direct an attack on any protected group based on sexuality.\n",
      "Sample 847 Results:  The provided text, \"the singularity already happened retard where do you think you even came from,\" can be interpreted as offensive due to the use of the derogatory term \"retard.\" However, it does not specifically target a protected group based on disability. Therefore, the output would be 1 (Offensive).\n",
      "\n",
      "The reasoning behind this is that while the term \"retard\" is often used to demean individuals with intellectual disabilities, in this context, it seems to be used as an insult against someone who may hold a different viewpoint or opinion (\"where do you think you even came from\"). The text does not demonstrate a clear intention to devalue or attack people with intellectual disabilities as a group. Instead, it appears to be directed at the individual being addressed.\n",
      "Sample 848 Results:  The provided text contains multiple instances of hate speech and offensive language. It targets specific racial groups (white people, Boers) and promotes violence against them, which is a clear example of hatespeech. Additionally, it references the swastika flag, a symbol closely associated with Nazi Germany and its genocidal policies, further indicating an intent to incite hatred and violence towards certain groups.\n",
      "\n",
      "Output: 2 (Hatespeech)\n",
      "Sample 849 Results:  The provided text does not directly mention or devalue any specific protected group based on gender, race, sexuality, religion, or disability. Instead, it refers to a hypothetical person's opinion about another group (white people). However, the question is whether the user agrees that this brown Muslim's statement makes things worse, not whether they are devaluing white people.\n",
      "\n",
      "Therefore, based on the given criteria, the text can be classified as '0 - Normal'. The user's statement does not involve hatespeech or offensive language towards any specific group.\n",
      "Sample 850 Results:  The provided text is \"<user> <user> <user> so me\". This text does not mention or devalue any protected groups, nor is it used as an insult against individuals. It appears to be a casual statement or conversation between users. Therefore, the output would be 0 (Normal).\n",
      "Sample 851 Results:  The provided text \"<user> eye hate you\" does not mention or involve devaluation of any protected groups based on gender, race, sexuality, religion, or disability. It is simply an expression of dislike towards the user. Therefore, the output would be 0, indicating that it's a 'Normal' statement.\n",
      "Sample 852 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The text is discussing a definition of \"white\" in the context of Western civilization, and does not involve devaluation or direct attacks on any protected groups. It's an academic-like discussion about cultural identity and ethnicity.\n",
      "Sample 853 Results:  The provided text is: \"set my lil brother bail at half a mill rat ass niggas\"\n",
      "\n",
      "Reasoning: In this context, the term \"nigga\" is used as an insult towards black people. However, it seems to be directed towards a group of people (rat ass niggas) rather than an individual. The use of \"lil brother\" suggests that the speaker has some connection with one of the individuals in the group. The word \"rat\" can be considered derogatory and demeaning. The phrase \"half a mill\" could imply a high amount of money, which might suggest a negative stereotype about black people and wealth.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 854 Results:  The provided text does not specifically target a protected group or involve devaluation. Instead, it seems to express confusion and criticism towards the perceived behavior of white Australians towards immigrants. However, the phrase \"hate poc\" (people of color) can be considered offensive as it implies a generalized hatred towards people of color.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 855 Results:  The provided text, \"yeah and nobody wants to see nigger tits either\", directly targets a protected group (black people) and involves devaluation. It is not used as an insult against an individual but rather a generalization about the entire race. Therefore, according to the given classification system, this text would be classified as 'Hatespeech' with an output of '2'.\n",
      "Sample 856 Results:  The provided text does not directly mention or devalue any protected groups based on gender, race, sexuality, religion, or disability. However, it does imply a potential conflict between Jews and Chinese people, which could be perceived as offensive due to the possibility of stereotyping or prejudice. But without explicit devaluation or direct attacks, I would classify this text as '1 - Offensive'.\n",
      "\n",
      "Reasoning: The text suggests a hypothetical scenario involving two groups (Jews and Chinese) that could potentially lead to conflict. While it does not explicitly devalue either group, the implication of such a scenario might be perceived as offensive due to potential stereotyping or prejudice. However, it is important to note that the text does not directly attack or devalue any protected groups based on the criteria provided.\n",
      "Sample 857 Results:  The provided text contains multiple offensive elements. It uses derogatory language towards both women (\"no lady\") and people of African descent (\"nigger\"). Additionally, it implies that the person is not English or British, which could be interpreted as an attack on their nationality or identity. Therefore, the output for this text would be 1 (Offensive).\n",
      "Sample 858 Results:  The provided text does not directly mention or devalue any specific protected group based on gender, race, sexuality, religion, or disability. However, it seems to suggest that a certain individual (Naseeruddin Shah) should preach something to Rohingya Muslims, which could potentially be interpreted as offensive or disrespectful towards the Rohingya community.\n",
      "\n",
      "However, without knowing the exact content of what Naseeruddin Shah is supposed to preach, it's hard to definitively classify this text as hatespeech. Therefore, based on the given criteria, I would classify this text as '1 - Offensive'.\n",
      "Sample 859 Results:  The provided text is \"i have absolutely nothing against patrick little but his personal opinion on mudslimes matters not in the least to me\".\n",
      "\n",
      "Reasoning:\n",
      "The term \"mudslime\" is a derogatory and offensive term used to devalue or attack people of Islamic faith. However, it's important to note that the text does not directly target Patrick Little but rather his opinion on Muslims. The text also indicates that the speaker has no personal issue with Patrick Little, which might suggest that the offensive language is directed towards Muslims as a group rather than an individual.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 860 Results:  1 - Offensive. While the text implies a negative sentiment towards Muslims and Islam, it does not directly devalue or attack them as a protected group. Instead, it comments on societal attitudes and perceptions, which can be considered offensive due to its insensitive and disrespectful tone. However, it does not specifically target individuals or groups with the intent to demean or harm them, making it different from hatespeech.\n",
      "Sample 861 Results:  The provided text uses the term \"rag head,\" which is derogatory towards people of Middle Eastern or Muslim descent. This text can be interpreted as devaluing a protected group based on religion, and it directly links to this group. Therefore, according to the given classification system, the output would be: 2 (Hatespeech)\n",
      "Sample 862 Results:  The provided text mentions a \"black Muslim refugee congresswoman,\" which could be considered a protected group based on race, religion, and nationality. However, it does not seem to involve devaluation or direct an attack on this group. Instead, it appears to be criticizing bipartisanship in relation to this individual.\n",
      "\n",
      "Therefore, the output would be: 0 (Normal)\n",
      "Sample 863 Results:  Output: 0 (Normal)\n",
      "\n",
      "Reasoning: The text does not mention or devalue any protected groups, nor is it used to attack anyone. It's a simple statement about enjoying a movie.\n",
      "Sample 864 Results:  The provided text is: \"no because the nigger word should only be used by blax when whites use it they should be killed\"\n",
      "\n",
      "Reasoning: This text directly targets a specific race (black people) and devalues them, using a racial slur. It also suggests violence against white people based on their race, which is a clear form of hate speech.\n",
      "\n",
      "Output: 2 (Hatespeech)\n",
      "Sample 865 Results:  2 (Hatespeech)\n",
      "\n",
      "Reasoning: The text refers to \"holocaust denial\" which is a form of devaluation and attack on a protected group, in this case, Jews. Holocaust denial is a controversial and offensive statement that negates the historical facts about the genocide of six million Jews during World War II. It's important to note that any form of denial or minimization of the Holocaust can be considered hatespeech due to its potential to cause harm, distress, and offense to Jewish people.\n",
      "Sample 866 Results:  Output: 2\n",
      "\n",
      "Reasoning: The statement explicitly targets a specific racial group (white Europeans) and devalues them by implying that they are the only desirable legal immigrants. This is a clear example of hate speech as it involves devaluation of a protected group based on race.\n",
      "Sample 867 Results:  The provided text does not specifically mention or devalue a protected group based on gender, race, sexuality, religion, or disability. However, it seems to express concern about Islam, which could be perceived as offensive by some members of the Muslim community due to potential stereotyping or generalization.\n",
      "\n",
      "However, the text does not directly attack or devalue individuals but rather criticizes an institution (the press) for its actions. Therefore, I would classify this text as '1 - Offensive'.\n",
      "Sample 868 Results:  To classify this text, let's break it down:\n",
      "\n",
      "1. \"that <number>\": This term does not seem to have any specific connotation related to protected groups.\n",
      "2. \"bouncer\": This is a common profession and doesn't target any specific group.\n",
      "3. \"boys\": This term can be used in various contexts, but it doesn't specifically refer to a particular gender or race.\n",
      "4. \"jumped up\": This phrase could be interpreted as an insult, but it doesn't directly devalue any protected groups.\n",
      "5. \"little nazi fag\": Here we have two problematic terms: \"nazi\" and \"fag\".\n",
      "   - \"Nazi\" is associated with the ideology of National Socialism, which targeted Jews and other minorities during World War II. However, in this context, it seems to be used as an insult rather than a direct attack on Jews or any specific group.\n",
      "   - \"Fag\" is a derogatory term for homosexual men. Using it in this context can be considered offensive towards the LGBTQ+ community.\n",
      "\n",
      "However, the combination of these two terms (\"little nazi fag\") could\n",
      "Sample 869 Results:  2\n",
      "\n",
      "Reasoning: The text makes direct comparisons between different racial groups, implying that one group (white) is capable of creating something positive (\"a glorious cathedral\"), while another group (black) is depicted as violent and destructive (\"he will bash another nigger skull in\"). This text involves devaluation of a protected group (African Americans) and links it to race, which fits the definition of hatespeech.\n",
      "Sample 870 Results:  The provided text does not mention any protected groups, nor does it involve devaluation or direct an attack on them. Instead, it seems to be a metaphorical comparison of a situation to the Holocaust, which is generally considered inappropriate due to its historical significance and gravity. However, without explicit intent from the user, it's challenging to classify this as hatespeech.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 871 Results:  The provided text \"enjoy your kike faith\" can be interpreted as a derogatory term towards Jewish people, which is a protected group based on religion. This text directly targets and devalues the Jewish community by using a slur. Therefore, the output should be '2' (Hatespeech).\n",
      "Sample 872 Results:  The provided text is: \"leonardo divinci was a nigger i did not know that the cell phone they claim was not even the first cell phone to call between different railroad cars hooked up to each other\"\n",
      "\n",
      "Reasoning:\n",
      "The term \"nigger\" is highly offensive and devalues a specific racial group (black people). In this context, it is used as hatespeech towards black people. The rest of the text seems unrelated to any protected groups or hate speech.\n",
      "\n",
      "Output: 2 (Hatespeech)\n",
      "Sample 873 Results:  The provided text is: \"look a stupid nigger posting directly to twitter gabfam even knows that a fucking mark of the retard\"\n",
      "\n",
      "Reasoning: This text uses racial slurs (\"nigger\") and ableist language (\"retard\"), both of which are derogatory terms aimed at devaluing and attacking specific protected groups (black people and individuals with intellectual disabilities). Therefore, it can be classified as 'Hatespeech' (2).\n",
      "Sample 874 Results:  2\n",
      "\n",
      "Reasoning: The text explicitly targets white people, referring to them as a group and suggesting they should avoid becoming part of \"the worlds hidden history of white extermination.\" This implies a devaluation and attack on the protected group based on race.\n",
      "Sample 875 Results:  The provided text does not mention or involve devaluation of protected groups linking to gender, race, sexuality, religion, or disability. It is a reference to the TV show \"Game of Thrones\" and includes a joke about aliens interacting with characters from the show. Therefore, the output should be 0 (Normal).\n",
      "Sample 876 Results:  This text specifically mentions and targets a group based on their immigration status, which can be considered a protected group. The use of \"fuck\" and the negative sentiment towards immigrants as a whole suggests devaluation. However, it does not directly attack or incite harm against all immigrants, but rather seems to focus on a specific individual (\"where is she\").\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 877 Results:  The provided text seems to express frustration or disillusionment towards a political figure (Trump) and an individual (Kanye West). It does not specifically target any protected group based on gender, race, sexuality, religion, or disability. Therefore, according to the given classification system, this text would be classified as '0' - Normal.\n",
      "\n",
      "However, it's important to note that the tone of the text could still be perceived as offensive due to its dismissive and disrespectful nature towards a political base (presumably Trump's supporters). This is not necessarily hatespeech but it does reflect a negative attitude or disregard for a particular group.\n",
      "\n",
      "In this case, I would suggest adding a '0.5' category for texts that are offensive in tone but do not specifically target protected groups. This would allow for a more nuanced classification of such texts.\n",
      "\n",
      "Output (with suggested modification): 0.5\n",
      "Sample 878 Results:  The provided text contains derogatory language and stereotypes towards Jewish people, which is a protected group based on religion. It also involves devaluation by accusing them of stealing money and using it for their own benefit, rather than for the greater good of society. Therefore, according to the given classification system, this text can be classified as 'Hatespeech' (Text that not only mentions but also involves devaluation of protected groups linking to religion).\n",
      "\n",
      "Output: 2\n",
      "Sample 879 Results:  The provided text does not directly mention or involve devaluation of protected groups linking to gender, race, sexuality, religion, or disability. However, it contains a statement that could be perceived as offensive or insensitive towards survivors of sexual assault. The use of the phrase \"still nearly got raped\" might trivialize the gravity of the experience and potentially re-victimize survivors.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 880 Results:  Output: 2\n",
      "\n",
      "Reasoning: The statement directly devalues a specific religious group, Jews, by implying they are inherently troublesome. This is a classic antisemitic trope and can be classified as hate speech.\n",
      "Sample 881 Results:  The provided text appears to be offensive and contains elements that could be interpreted as hate speech. It targets specific racial and ethnic groups, including Muslims, black people, and immigrants, and makes derogatory statements about them. It also expresses a fear of cultural change and loss of heritage, which can be seen as xenophobic. Therefore, the output for this text would be 1 (Offensive). However, it's important to note that the use of the term \"3rd worlders\" could also be considered hate speech due to its derogatory connotation towards developing countries and their inhabitants.\n",
      "Sample 882 Results:  The provided text contains multiple offensive and derogatory terms, including \"nigger\" and \"noogie,\" which is a slur against black people. Additionally, the use of \"female\" as an insult is also inappropriate. Therefore, based on the given criteria, this text would be classified as '1 - Offensive'.\n",
      "Sample 883 Results:  The provided text seems to be offensive, but it doesn't specifically target a protected group based on gender, race, sexuality, religion, or disability. Instead, it appears to be an insult directed towards the user, using derogatory terms like \"ass scratching,\" \"finger sniffing,\" and \"redneck.\" However, these terms are generally considered disrespectful and offensive rather than hate speech.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 884 Results:  The provided text seems to be offensive and can be interpreted as devaluing a specific ethnic group, in this case Pakistani people. However, it's important to note that the term \"jihadi terrorists\" is often used pejoratively and could be seen as stereotyping an entire nation based on negative actions of some individuals.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 885 Results:  Output: 2\n",
      "\n",
      "Reasoning: The text explicitly mentions multiple protected groups (race, religion) and calls for their removal, which is a clear example of hate speech.\n",
      "Sample 886 Results:  The provided text does not directly mention or involve devaluation of any protected groups based on gender, race, sexuality, religion, or disability. However, it does reference a \"dyke salon,\" which could be perceived as offensive to the lesbian community. But the text itself is not using this term in a derogatory manner, rather it's implying that someone who posted about a hypothetical lesbian-themed business might be homophobic.\n",
      "\n",
      "So, based on the given classification system:\n",
      "Output: 1 (Offensive)\n",
      "Sample 887 Results:  The provided text contains derogatory language towards a specific individual, Mohammad bin Salman Al Saud, and uses offensive terms such as \"camel jockey\" which is often used to demean people of Arab or Middle Eastern descent. However, it does not specifically target any protected groups based on gender, race, sexuality, religion, or disability. Therefore, the text can be classified as 'Offensive' with a value of 1.\n",
      "\n",
      "Reasoning: While the term \"camel jockey\" is used as an insult, it is not used to devalue or attack a protected group based on race or nationality. However, the language used is disrespectful and offensive towards the individual mentioned.\n",
      "Sample 888 Results:  The provided text is: \"what about the black violence and you said that he chased them and that was bad you had no idea that the gun was illegal <number> niggers destroyed his store there should be no gun registration\"\n",
      "\n",
      "Reasoning: This text directly targets a specific racial group (black people) and devalues them by using a derogatory term (\"niggers\"). It also implies that all black people are violent, which is a stereotype and a form of discrimination. The use of the term \"illegal\" in relation to gun ownership could be interpreted as promoting violence or vigilantism against this group. Therefore, the output for this text would be '2' (Hatespeech).\n",
      "Sample 889 Results:  2\n",
      "\n",
      "Reasoning: The text directly targets and devalues a specific racial group (Africans and Arabs) by implying they are more likely to commit rape. It also makes a derogatory comment about a specific ethnicity (Nazis) and implies that victims of sexual assault are liars if they accuse members of this group. This text fits the definition of hatespeech as it involves devaluation of a protected group (race).\n",
      "Sample 890 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The text does not mention or devalue any protected groups, nor is it used as an attack on them. Instead, it expresses a general sentiment about seeking help from the police in case of emergencies such as robbery, rape, and attacks. It also clarifies that the individuals being referred to are not criminals but victims. Therefore, it can be classified as normal text.\n",
      "Sample 891 Results:  The provided text appears to be derogatory and offensive towards a specific group of people, specifically those from rural areas or with a certain socio-economic status. However, it does not directly target protected groups based on race, gender, sexuality, religion, or disability as defined in the given classification system.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 892 Results:  The provided text \"oh that lady yeah she a hate filled racist bitch go nuts\" can be interpreted as offensive due to the use of derogatory language towards an individual. However, it does not specifically target a protected group based on race, gender, sexuality, religion, or disability. Therefore, the output should be 1 (Offensive).\n",
      "Sample 893 Results:  The provided text does not specifically mention or devalue any protected groups based on gender, race, sexuality, religion, or disability. However, it does contain a derogatory and disrespectful comment about immigrants, referring to them as if they need to be inspected by the speaker's \"elite men.\" This can be considered offensive due to its dehumanizing nature towards a particular group of people.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 894 Results:  The provided text seems to express feelings of self-loathing, paranoia, and despair. It doesn't explicitly target or devalue any specific protected group based on gender, race, sexuality, religion, or disability. However, the use of derogatory terms like \"nut\" and \"faggot\" can be considered offensive due to their historical and current connotations.\n",
      "\n",
      "To classify this text, we should consider its main intent: while it contains offensive language, it doesn't appear to be primarily aimed at devaluing or attacking a specific group. Therefore, the classification would be '1 - Offensive'.\n",
      "Sample 895 Results:  The provided text contains derogatory and offensive language towards individuals who may be identified as Muslim, which is a protected group based on religion. The user refers to Muslims as \"raghead\" and \"colostomy bags,\" both of which are highly disrespectful and dehumanizing terms. Therefore, the output for this text would be '2' (Hatespeech).\n",
      "Sample 896 Results:  The provided text \"<user> <user> keep running to Russia you Nazi sympathizer\" can be classified as '1 - Offensive'.\n",
      "\n",
      "Reasoning: While the term \"Nazi\" is historically associated with a hate group, in this context it seems to be used more as an insult towards someone who is perceived to have sympathetic or supportive views towards Russia. However, it does not specifically target people of a particular race, religion, gender, sexuality, or disability. The text is toxic due to the use of \"Nazi\" as an insult and the aggressive tone.\n",
      "Sample 897 Results:  To classify this text, let's break it down:\n",
      "\n",
      "1. \"planned parenthood does not help women who wish to keep their baby\" - This statement could be interpreted as controversial or opinionated, but it doesn't specifically devalue or attack a protected group, so it's not hatespeech.\n",
      "\n",
      "2. \"women who kill babies get depressed take psyche drugs big pharma wins\" - This part of the text seems to generalize and potentially stigmatize women who have abortions, which could be seen as offensive towards women. However, it doesn't directly link this to a protected group based on gender, race, sexuality, religion, or disability, so it's not hatespeech.\n",
      "\n",
      "3. \"see the truth and share the truth gabfam marchforlife maga\" - These phrases are associated with political movements, but they don't contain any derogatory language towards protected groups, so they are normal.\n",
      "\n",
      "Overall, the text seems to be more offensive than hatespeech, as it contains language that could be interpreted as stigmatizing towards women who have abortions. However, it doesn't specifically\n",
      "Sample 898 Results:  The provided text contains derogatory language towards multiple protected groups, including Jews (using the term \"kike\") and black people (\"counter-signaling my kike gassing\"). It also shows a clear intention to devalue these groups. Therefore, according to the given classification system, this text would be classified as 'Hatespeech' (Text that not only mentions but also involves devaluation of protected groups linking to gender, race, sexuality, religion and disability).\n",
      "\n",
      "Output: 2\n",
      "Sample 899 Results:  The provided text is: \"i did not expect something kike that holy shit i t looks so good\"\n",
      "\n",
      "Reasoning:\n",
      "The term \"kike\" is historically and currently used as a derogatory slur against Jewish people. However, in this context, it seems to be misspelled as a typo for \"kind of\". The text does not seem to involve devaluation or an attack on any protected group intentionally. It's more about expressing surprise and admiration for something.\n",
      "\n",
      "Output: 0 (Normal)\n",
      "Sample 900 Results:  To classify this text, we will analyze each term and determine if it falls under 'Hatespeech', 'Offensive', or 'Normal'.\n",
      "\n",
      "1. \"amsyar\" - This is a name, so it's neither hatespeech nor offensive. (0)\n",
      "2. \"he used to look more chinese during form one\" - This statement seems neutral and doesn't involve any devaluation of a protected group, so it's normal. (0)\n",
      "3. \"a bitch\" - Using this term as an insult can be considered offensive towards women, but in this context, it appears to be directed at an individual rather than a broader group, so it's classified as 'Offensive'. (1)\n",
      "4. \"uri dumbass\" - Similar to the previous term, using \"dumbass\" as an insult can be offensive and disrespectful, so it's classified as 'Offensive'. (1)\n",
      "5. \"good advices\" - This is a neutral statement, so it's normal. (0)\n",
      "6. \"he always there if u need him\" - This seems like a positive statement, so it's normal. (0)\n",
      "\n",
      "Sample 901 Results:  Output: 1 (Offensive)\n",
      "\n",
      "Reasoning: While the text does involve a reference to a gay man, it's not necessarily hatespeech as it doesn't devalue or attack the LGBTQ+ community as a whole. However, the librarian's response (\"fuck off\") is disrespectful and offensive towards the individual. The context of the book request (HIV) might be interpreted as insensitive, but it doesn't necessarily imply hatespeech.\n",
      "Sample 902 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The user is expressing frustration about spelling a term related to a specific genre of music, and uses \"retarded\" in a colloquial or informal way as an expression of their own perceived lack of intelligence. This does not involve devaluation or direct attack on any protected group.\n",
      "Sample 903 Results:  1 (Offensive)\n",
      "\n",
      "Reasoning: While the text contains strong religious language and a derogatory term (\"heretics\"), it does not specifically target or devalue a protected group based on gender, race, sexuality, religion, or disability. However, the tone and language used can be considered disrespectful and offensive towards those with different religious beliefs.\n",
      "Sample 904 Results:  The provided text seems to contain multiple elements that could be interpreted as offensive or derogatory towards certain groups, including gay men and individuals with special needs. However, it does not explicitly devalue or attack these groups in a way that would classify it as hate speech.\n",
      "\n",
      "The text implies negative stereotypes about gay couples adopting children, particularly those with special needs, and suggests a lack of concern for the quality of schools. It also seems to make a generalization about all gay couples, which could be seen as disrespectful.\n",
      "\n",
      "However, it does not directly use hate speech or slurs towards these groups. Therefore, based on the provided classification system, I would classify this text as '1 - Offensive'.\n",
      "Sample 905 Results:  The provided text uses the term \"ghetto\" and \"slow,\" which could potentially be perceived as stereotyping or devaluing a specific group, in this case, possibly African Americans or people from lower-income communities. However, it is important to note that the context suggests that the speaker is referring to their own family members with humor and affection, implying they love them despite their perceived shortcomings.\n",
      "\n",
      "In this case, while the text might be considered offensive due to the use of potentially stereotypical language, it does not seem to be intended as hatespeech against a specific protected group. The speaker's tone and the inclusion of laughter emojis suggest that they are joking about their family members in a light-hearted manner.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 906 Results:  The provided text is: \"niggas really let idubbz say nigger faggot and ain't even care\"\n",
      "\n",
      "Reasoning: This text contains multiple derogatory slurs, \"nigger\" which is offensive towards black people and \"faggot\" which is offensive towards the LGBTQ+ community. The use of these terms in this context can be interpreted as hatespeech aimed at devaluing both racial and sexual minorities.\n",
      "\n",
      "Output: 2 (Hatespeech)\n",
      "Sample 907 Results:  The provided text contains several offensive and derogatory terms, including \"kike,\" \"cuck,\" and \"fuckers.\" These terms are historically used as slurs against Jewish people. Therefore, the text can be classified as 'Hatespeech' with an output of '2'. It is important to note that using such language is harmful and disrespectful, and it should not be tolerated in any context.\n",
      "Sample 908 Results:  The provided text contains racial slurs (\"dune coons\") and violent language (\"dropping bombs\"), which can be considered offensive and potentially hateful towards a specific group, in this case, people of Middle Eastern or North African descent. However, the context seems to be related to a video game or military strategy discussion, which might dilute the intent of hate speech.\n",
      "\n",
      "To classify it accurately, we should consider the broader context in which the text is used. If it's part of a casual conversation about a video game or military strategy, it could be classified as 1 (Offensive). However, if it's found in a more serious or public setting, such as social media or online forums, where the intent might be to devalue or attack a specific group, it could potentially be classified as 2 (Hatespeech).\n",
      "\n",
      "In this case, I would classify it as 1 (Offensive) due to the context provided.\n",
      "Sample 909 Results:  The provided text is: \"lay down that pressure on the iffy niggas that will not leap\"\n",
      "\n",
      "Reasoning:\n",
      "The term \"nigga\" can be considered offensive towards black people, but in this context, it seems to be used as a colloquial term among some groups. However, without additional context, it's hard to definitively say whether it is being used as a form of hatespeech or not.\n",
      "\n",
      "The phrase \"iffy niggas that will not leap\" could potentially be interpreted as targeting a specific group (black men), but it doesn't necessarily involve devaluation or an attack on the group. Instead, it appears to be referring to individuals who are uncertain or unwilling to act.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 910 Results:  The provided text seems to express a political opinion, but it also contains derogatory language (\"dumbass\") and stereotypes (\"white Europeans\"). However, it does not specifically target or devalue a protected group based on race, gender, sexuality, religion, or disability. Therefore, the output would be 1 (Offensive).\n",
      "\n",
      "However, it's important to note that this text could still be considered problematic due to its use of derogatory language and potential reinforcement of harmful stereotypes. It's always crucial to promote respectful and inclusive communication in all contexts.\n",
      "Sample 911 Results:  This text appears to be a hate speech towards Muslims. It devalues and attacks the Muslim community by making generalizations about them, linking them to negative stereotypes such as terrorism, pedophilia, and welfare fraud. The use of derogatory language like \"ghettos\" and the prediction of civil war and a future where Muhammad becomes the most common name of dead people further reinforces this hate speech.\n",
      "\n",
      "Output: 2 (Hatespeech)\n",
      "Sample 912 Results:  The provided text \"you forgot faggots like azzmador and greg johnson\" can be interpreted as devaluing a specific group, in this case, the LGBTQ+ community by using a derogatory slur. However, it does not directly link to race, gender, religion, or disability.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 913 Results:  The provided text contains derogatory language towards a specific group, in this case, refugees. It also suggests violent and harmful actions towards them, such as bombing, raping, killing, and thieving. This can be interpreted as devaluing and directing an attack on the protected group of refugees.\n",
      "\n",
      "Reasoning: The text not only mentions but also involves devaluation of a protected group (refugees) linking to race, ethnicity, and nationality. It also suggests violent actions towards them, which can be considered hatespeech.\n",
      "\n",
      "Output: 2\n",
      "Sample 914 Results:  The provided text \"this white ass la does not sell colada the smoothie lady did not even know wtf i was talking about ðŸ¤¦ ðŸ» â€ â™€ï¸\" can be interpreted as offensive due to the use of \"white ass\" as an insult, but it does not specifically target a protected group based on race. Therefore, the output would be 1 (Offensive).\n",
      "Sample 915 Results:  The provided text, \"the muzrat euro marathon,\" does not explicitly mention or devalue any protected groups based on gender, race, sexuality, religion, or disability. It seems to refer to a term, \"muzrat,\" which may be derogatory or offensive in certain contexts, but without additional information, it's hard to definitively classify it as hatespeech.\n",
      "\n",
      "However, since the text does not directly involve devaluation of protected groups and its main intent is unclear, I would classify it as:\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 916 Results:  The provided text contains derogatory language towards a specific group, in this case, individuals who are perceived as \"retarded.\" However, it also includes a political statement about the diversity lottery and Trump. The main intent of the text seems to be criticizing a news source (Gateway Pundit) and expressing a political opinion, rather than directly devaluing or attacking a protected group.\n",
      "\n",
      "However, using derogatory language towards any group can be considered offensive. In this case, I would classify it as '1 - Offensive' because while the main intent is not hatespeech, it does contain language that can be perceived as demeaning towards individuals with intellectual disabilities.\n",
      "Sample 917 Results:  The provided text \"<user> <user> <user> all those illegal aliens ðŸ¤¦ ðŸ» â€ â™‚ï¸\" does not specifically target a protected group based on race, gender, sexuality, religion, or disability. Instead, it seems to be referring to immigrants without legal documentation, which is a broader category rather than a specific protected group. However, the term \"illegal aliens\" can be considered offensive by some due to its negative connotation towards immigrants.\n",
      "\n",
      "In this context, I would classify the text as \"1 - Offensive.\" While it may not meet the criteria for hatespeech, it does contain language that could be perceived as derogatory or disrespectful towards a particular group of people.\n",
      "Sample 918 Results:  The provided text does not specifically target or devalue a protected group based on gender, race, sexuality, religion, or disability. Instead, it discusses the visibility and vocalness of Asian immigrants in comparison to a homogeneous entity, which could be interpreted as a general observation rather than hate speech or offensive language.\n",
      "\n",
      "Output: 0 (Normal)\n",
      "Sample 919 Results:  The provided text \"fb so ghetto ðŸ˜­ ðŸ˜­ whew\" does not specifically mention or devalue any protected groups such as race, gender, sexuality, religion, or disability. It seems to be expressing disapproval or amusement towards a perceived lack of sophistication or class, which can be associated with the term \"ghetto\". However, without additional context, it's hard to definitively classify this text as hatespeech, offensive, or normal.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 920 Results:  The provided text \"head cannon sougou is an incel and oma zi o is the result of being told by one to many women that he can not smell they are feet\" does not specifically target any protected groups based on gender, race, sexuality, religion, or disability. It seems to be a humorous or sarcastic commentary about fictional characters from anime, and as such, it doesn't appear to be hatespeech or offensive.\n",
      "\n",
      "Output: 0 (Normal)\n",
      "Sample 921 Results:  The provided text \"exactly what i have been saying let them live with pelosi what her name shut and that dumass jigaboo from fla and csli\" contains multiple derogatory terms (\"dumass\", \"jigaboo\") that are historically used as racial slurs against black people. Additionally, the term \"shut\" can be interpreted as devaluing towards women (Pelosi). Therefore, this text can be classified as 'Hatespeech' with an output of '2'.\n",
      "Sample 922 Results:  The provided text \"went varmint hunting earlier i shot six squirrels and a jackrabbit no kike rats though <sad>\" contains the term \"kike\", which is historically and currently used as an anti-Semitic slur. This term is used to devalue or attack Jewish people, making it a form of hate speech.\n",
      "\n",
      "Output: 2\n",
      "Sample 923 Results:  Output: 0\n",
      "\n",
      "Reasoning: The text does not mention or devalue any protected groups, nor is it used as an insult against individuals. It simply describes a scene at an outdoor concert in Monroe featuring Motown music and older attendees wearing orthopedic shoes.\n",
      "Sample 924 Results:  The provided text seems to target a specific religious group (Muslims) and implies blame for certain actions. However, it does not devalue or directly attack individuals within the group, but rather criticizes their leaders. Therefore, according to the given classification system, this text would be classified as '1 - Offensive'.\n",
      "\n",
      "Reasoning: While the text could potentially be interpreted as hate speech due to its targeting of a religious group, it does not involve devaluation or direct attacks on individuals within that group. Instead, it criticizes their leaders, which might be considered offensive but not necessarily hatespeech.\n",
      "Sample 925 Results:  2 (Hatespeech)\n",
      "\n",
      "Reasoning: The text directly targets and devalues two protected groups, Muslims (referred to as \"ragheads\") and Jews (referred to as \"kikes\"). It also promotes violence against these groups. This is a clear example of hatespeech.\n",
      "Sample 926 Results:  The provided text does not mention any protected groups, nor does it involve devaluation or direct an attack. It is a request for marriage, albeit with specific criteria. Therefore, the output should be '0' - Normal.\n",
      "Sample 927 Results:  The provided text clearly targets multiple protected groups, including Jews (Kikes), Black people (niggers), and Muslims (muzzos). It devalues and attacks these groups, which aligns with the definition of hatespeech. Therefore, the output for this text is 2.\n",
      "Sample 928 Results:  The provided text contains multiple offensive terms, including \"nigger\" which is a racial slur and considered highly derogatory towards black people. However, the context suggests that it might be used in a derisive or disrespectful manner towards Minecraft fans, rather than as an expression of hate or devaluation of black people as a group.\n",
      "\n",
      "The term \"butthurt\" is also offensive and disrespectful, but it doesn't specifically target any protected groups. The rest of the text seems to be about a disagreement related to Minecraft and Bitcoin.\n",
      "\n",
      "Given this analysis, I would classify the provided text as '1 - Offensive'. It contains language that can be interpreted as derogatory or disrespectful, but it may not meet the criteria for hatespeech as defined in the given context (directly devaluing or attacking a protected group).\n",
      "Sample 929 Results:  The provided text \"they turned cancun ' into the ghetto\" does not specifically mention or devalue a protected group such as race, gender, sexuality, religion, or disability. However, it could be interpreted as implying that a certain group of people have negatively impacted Cancun, which might be seen as offensive or stereotypical towards that unspecified group.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 930 Results:  The provided text contains derogatory language towards a specific ethnic group, Jews, using the term \"kike.\" This term is historically and currently used as a pejorative against Jewish people. Therefore, this text can be classified as 'Hatespeech' with an output of '2'. It directly involves devaluation of a protected group (religion).\n",
      "Sample 931 Results:  The provided text seems to express a critical viewpoint towards certain institutions (white cishet, in this case) and suggests that there should be more representation of queer people. However, it doesn't directly involve devaluation or an attack on any protected group. Therefore, based on the given classification system, the output would be:\n",
      "\n",
      "Output: 0 (Normal)\n",
      "Sample 932 Results:  Output: 0\n",
      "\n",
      "Reasoning: The provided text does not mention or devalue any protected groups based on gender, race, sexuality, religion, or disability. It is a statement of dislike towards a company (Valve), which is not a protected group. Therefore, it can be classified as 'Normal'.\n",
      "Sample 933 Results:  2\n",
      "\n",
      "Reasoning: The text specifically targets protected groups such as refugees, women, and people of certain religious beliefs (church cucks is a derogatory term often used to demean Christians). It also links these groups to negative actions or characteristics, and implies that opposition to refugee resettlement is racist. This text can be interpreted as hatespeech due to its devaluation and attack on multiple protected groups.\n",
      "Sample 934 Results:  Output: 0\n",
      "\n",
      "Reasoning: The text is making a sarcastic or ironic statement, implying that Nazi Germany was not LGBTQ+ inclusive. It does not devalue or attack any protected group directly. Instead, it uses hyperbole to criticize the historical record of Nazi Germany on human rights.\n",
      "Sample 935 Results:  This text seems to be discussing political affiliations and demographics, but it doesn't explicitly devalue or attack any protected groups. However, the phrase \"look at the media\" could potentially be interpreted as implying bias in the media, which might be considered offensive by some. But the main intent of the text doesn't seem to involve directing an attack on a specific group.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 936 Results:  1 - Offensive. The user expresses frustration and disapproval towards a specific group, but it's not clear that they are devaluing or attacking the group based on protected characteristics such as race, gender, sexuality, religion, or disability. Instead, the user is criticizing the group's actions and policies. However, the use of strong language like \"fucking\" and \"hate group\" may be considered inappropriate or offensive by some.\n",
      "Sample 937 Results:  The provided text contains derogatory language and stereotypes towards a specific religious group, Muslims. It also uses offensive terms such as \"muzzies\" and compares them to rats (skaven), which is degrading. Furthermore, the statement implies that this group is untrustworthy and reproduces excessively, both of which are negative generalizations.\n",
      "\n",
      "Based on the given classification system:\n",
      "Output: 2 (Hatespeech)\n",
      "Sample 938 Results:  The provided text is \"bad bitch she conceited\". In this context, the term \"bitch\" can be perceived as disrespectful or offensive towards women. However, it doesn't specifically devalue or attack a protected group based on gender. The word \"conceited\" means having an excessively high opinion of oneself, which is not directly related to any protected groups.\n",
      "\n",
      "Therefore, the output would be: 1 (Offensive)\n",
      "Sample 939 Results:  1 - Offensive\n",
      "\n",
      "Reasoning: The text discusses a situation where the author took a small portion from the Quran and replaced a term with \"Muslim.\" While this action might be seen as disrespectful towards Muslims, it is not clear that the intention was to devalue or attack Muslims as a group. Instead, it appears to be more of a commentary on the content of the Quran and Facebook's response to it. However, the text does contain language that could be considered offensive due to its disrespectful treatment of religious texts.\n",
      "Sample 940 Results:  Output: 1\n",
      "\n",
      "Reasoning: The term \"slut\" can be considered offensive, but it does not specifically target a protected group or involve devaluation based on gender. It is used as a personal choice of self-expression, although it may be perceived negatively by some. However, the main intent doesn't not involve devaluing or directing an attack on any specific group.\n",
      "Sample 941 Results:  Output: 2\n",
      "\n",
      "Reasoning: The text explicitly uses a derogatory slur (\"faggots\") towards a protected group (LGBTQ+ individuals) and also implies violence against them. This is a clear example of hate speech.\n",
      "Sample 942 Results:  The provided text, \"hugo lloris could not catch corona if a chinaman sneezed in his gob,\" contains racial slurs and derogatory language towards Asian people. This can be considered as 'Hatespeech' because it devalues and attacks a protected group based on their race.\n",
      "\n",
      "Output: 2\n",
      "Sample 943 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The text does not mention or devalue any protected groups, nor is it used to attack or devalue individuals based on gender, race, sexuality, religion, or disability. It appears to be a statement about fallen heroes and their impact on history and communities.\n",
      "Sample 944 Results:  The provided text does not specifically target any protected group or individual, and it doesn't involve devaluation of any group. It is a general statement about a perceived behavior between two groups (men and gold diggers). Therefore, the output would be 0, indicating that the text can't be interpreted as hatespeech. However, it's important to note that this text could still be considered offensive or disrespectful due to its tone and potential stereotyping of certain behaviors.\n",
      "Sample 945 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The text does not mention or devalue any protected groups, nor is it used as an attack on them. It appears to be a personal reflection or joke about the speaker's financial decisions and social life. There are no derogatory terms or slurs used against any group.\n",
      "Sample 946 Results:  0 (Normal)\n",
      "Reasoning: The text does not involve devaluation or direct an attack on any specific religion, race, gender, sexuality, or disability. It simply states a personal belief about the clarity of Islamic teachings.\n",
      "Sample 947 Results:  The provided text is: \"why niggas worry bout me when i do not even checc on them faggots\"\n",
      "\n",
      "Reasoning: This text uses derogatory and offensive language towards both black people (\"niggas\") and the LGBTQ+ community (\"faggots\"). It implies a devaluation of these protected groups, and it is used to express disdain or contempt. Therefore, the output should be '2' as this text can be classified as Hatespeech.\n",
      "Sample 948 Results:  The provided text \"you wanna defend this hasbara kike thot too\" can be interpreted as offensive due to the use of the term \"kike,\" which is a derogatory slur against Jewish people. However, it's not necessarily hatespeech because it seems to be used in a specific context related to an individual or a debate, rather than a general attack on Jews as a group.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 949 Results:  This text contains multiple offensive elements. It uses derogatory terms such as \"douche,\" \"kike\" (which is an anti-Semitic slur), and \"hooker.\" The use of these terms is intended to devalue or attack specific groups based on religion and gender, making it a form of hatespeech.\n",
      "\n",
      "Output: 2\n",
      "Sample 950 Results:  The provided text is clearly a hate speech as it involves devaluation of a protected group (black people) and directly targets them with offensive language. It also expresses disregard for their lives, poverty, crime rates, families, and overall well-being. Therefore, the output would be '2'.\n",
      "Sample 951 Results:  1 (Offensive)\n",
      "\n",
      "Reasoning: The text expresses discomfort and a negative attitude towards homosexuality, but it does not specifically devalue or attack a protected group. It is more about the individual's personal preference and discomfort rather than a generalized hatred or devaluation of a specific group. However, the language used can be considered offensive due to its dismissive and derogatory tone towards sexual orientation.\n",
      "Sample 952 Results:  The provided text is: \"when i drink big red i feel really ghetto\"\n",
      "\n",
      "Reasoning:\n",
      "The term \"ghetto\" has been historically used to stereotype and devalue urban African American communities. However, in this context, it seems to be used as a colloquial expression to describe a feeling of being rough or uncultured, not specifically targeting any racial group. The term Big Red is a reference to a specific drink, so there's no mention of race, gender, sexuality, religion, or disability.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 953 Results:  The provided text \"you white republican atheists who stayed home will pay the price you can forget your tax break now\" can be classified as '1 - Offensive'.\n",
      "\n",
      "Reasoning: While the text does mention specific groups (white, Republican, and atheist), it is not necessarily devaluing or attacking them directly. Instead, it seems to express anger towards a particular group of individuals who stayed home during a certain event or situation. The offensive part lies in the threatening tone (\"you will pay the price\") and the implied insult that those who stayed home are being punished for their political beliefs and religious affiliations. However, without additional context, it's hard to definitively say whether this text constitutes hatespeech.\n",
      "Sample 954 Results:  Based on the provided context, this text seems to be discussing a controversial figure (Epstein) who is accused of heinous crimes, including sexual assault of minors. The user is referring to another user and questioning if they are defending Epstein's actions. While the text does not directly devalue or attack any protected group, it might be perceived as offensive due to its reference to a controversial and sensitive topic.\n",
      "\n",
      "However, the classification of this text as 'Hatespeech', 'Offensive', or 'Normal' is somewhat subjective and depends on the context in which it was used. In this case, I would classify it as '1 - Offensive'. The main intent does not involve devaluing or directing an attack on protected groups, but it can be interpreted as toxic due to its reference to a sensitive topic.\n",
      "Sample 955 Results:  The provided text does not specifically target any protected groups based on gender, race, sexuality, religion, or disability. However, the phrase \"mussie\" is derogatory towards Muslims. But in this context, it seems to be used as a part of an accusation against Bill Clinton, not as a general attack on all Muslims.\n",
      "\n",
      "So, the output would be: 1 (Offensive)\n",
      "Sample 956 Results:  The provided text \"moslem ban and libtard ban but not gun ban\" can be interpreted as expressing a political viewpoint, rather than directly devaluing or attacking a specific protected group. However, it does imply a negative stereotype towards Muslims and liberals (libtards). This stereotype could potentially be considered offensive due to the generalization and potential for harm.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 957 Results:  The provided text is: \"i tole sum brillohaided nigger bich off last nite cuz it try to get uppity wit me\"\n",
      "\n",
      "Reasoning: This text uses racial slurs (\"nigger\") and derogatory language towards women (\"bitch\"), both of which are highly offensive. It also implies violence (\"told off\") and disrespect (\"uppity\"). The use of these terms in this context is intended to devalue and attack protected groups (race and gender), making it a clear example of hatespeech.\n",
      "\n",
      "Output: 2\n",
      "Sample 958 Results:  The provided text \"i bet kike molars cracked when they heard all the in jesus name we pray\" can be interpreted as offensive due to the use of the term \"kike,\" which is historically and currently used as a derogatory slur against Jewish people. However, it does not specifically involve devaluation or an attack on Jewish people as a protected group in this context. It's more about mocking religious fervor rather than directly targeting Jews.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 959 Results:  The text \"ah can honestly say ave never had a deep fried mars bar they do not do them here prefer a nice deep fried faggot and chippies ðŸ¤ª ðŸ¤ª\" does not mention or involve devaluation of any protected groups (gender, race, sexuality, religion, disability). It is about food preference.\n",
      "Output: 0\n",
      "Sample 960 Results:  The provided text seems to express dissatisfaction with a government's policies, specifically focusing on immigration. However, it does not directly devalue or attack any specific protected group based on race, gender, sexuality, religion, or disability. Therefore, according to the given classification system, this text would be classified as '0 - Normal'.\n",
      "\n",
      "However, it's important to note that the tone and choice of words could potentially be perceived as offensive or inflammatory by some readers, especially if they hold strong opinions about immigration policies. But in terms of hatespeech, which specifically involves devaluation of protected groups, this text does not seem to fit that definition.\n",
      "Sample 961 Results:  The provided text is: \"people calling undocumented immigrants labor unskilled are dumb af ya ever built a house shit ainâ€™t easy\"\n",
      "\n",
      "Reasoning:\n",
      "The text does not specifically target any protected group based on gender, race, sexuality, religion, or disability. Instead, it seems to be expressing frustration towards people who stereotype undocumented immigrants as unskilled workers. The use of \"dumb\" can be interpreted as an insult, but it is not directed at a specific individual or group in a discriminatory manner.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 962 Results:  The provided text is: \"stop blaming niggers and women for what is obviously being caused by russian hackers\"\n",
      "\n",
      "Reasoning: This text does not directly devalue or attack a specific group based on race, gender, sexuality, religion, or disability. However, it uses the racial slur \"nigger\", which is highly offensive towards black people. The use of this slur in any context can be considered hate speech.\n",
      "\n",
      "However, in this case, the text seems to be criticizing the act of blaming certain groups (black people and women) for something that is actually caused by Russian hackers. This could imply a sense of unfairness or misdirection of blame, but it does not necessarily promote hatred towards these groups.\n",
      "\n",
      "Given the complexity of this text, it might be challenging to classify it strictly as 'Hatespeech' or 'Normal'. But considering the use of the racial slur \"nigger\", I would lean towards classifying it as '1 - Offensive'. It's important to note that using such language is harmful and disrespectful, even if not intended as hate speech.\n",
      "Sample 963 Results:  The provided text \"i needed you and you were not there that made me hate you\" does not specifically target any protected group based on gender, race, sexuality, religion, or disability. It seems to be a personal expression of frustration towards an individual. Therefore, the output would be 0 (Normal).\n",
      "Sample 964 Results:  The provided text is: \"snickers have come out with a white chocolate bar ice cream bar i can not stand snickers because i like my candy like i like my women no nuts\"\n",
      "\n",
      "Reasoning: This text does not mention or involve devaluation of any protected groups linking to gender, race, sexuality, religion, or disability. It is a personal preference statement about Snickers and candy, using a metaphor comparing candy to women without nuts. The use of the phrase \"no nuts\" in this context can be seen as a playful or humorous reference to a common saying, not intended to devalue or attack any group.\n",
      "\n",
      "Output: 0 (Normal)\n",
      "Sample 965 Results:  The provided text contains the word \"nigger\" which is highly offensive towards black people. However, in this context, it seems to be used to describe someone else's behavior rather than directly targeting or devaluing black people as a group. Therefore, according to the given classification system, the output would be 1 (Offensive).\n",
      "\n",
      "However, it's important to note that even if not intended as such, the use of this word can still be perceived as hatespeech due to its historical and current connotations. It's always crucial to consider the potential impact of our words on others, especially when discussing sensitive topics or protected groups.\n",
      "Sample 966 Results:  The provided text appears to be a list of various Islamic extremist groups. However, it does not explicitly devalue or attack any specific protected group based on race, gender, sexuality, religion, or disability. Instead, it seems to generalize all these groups as \"muzzie terrorists.\" This generalization could potentially be seen as offensive or biased towards a certain religious group.\n",
      "\n",
      "However, the intent of the text is not clear from the provided context. It's important to note that the text does not directly target individuals but rather organizations. Therefore, it might be more appropriate to classify this text as '1 - Offensive.'\n",
      "\n",
      "Reasoning: While the text could be interpreted as devaluing a religious group (Muslims), it is not specifically directed at an individual or a protected group based on gender, race, sexuality, religion, or disability. The text seems to generalize all these groups as \"muzzie terrorists,\" which might be offensive due to its potential bias towards a certain religious group. However, the intent of the text is not explicitly clear from the provided context.\n",
      "Sample 967 Results:  1 (Offensive)\n",
      "\n",
      "Reasoning: While the text does express a negative sentiment towards certain ethnic groups, it is not explicitly devaluing or attacking them based on their race, gender, sexuality, religion, or disability. Instead, it seems to be more about cultural identity and national pride. However, the tone and language used can still be considered offensive due to its disrespectful and insensitive nature.\n",
      "Sample 968 Results:  The provided text is \"i love how feminists only like women who break the glass ceiling when they agree with them kellyanneconway\".\n",
      "\n",
      "Reasoning: This text seems to express a critical opinion about certain feminists, specifically implying that they only support successful women if those women share their views. However, it does not directly devalue or attack any specific protected group (gender in this case) based on their identity. It is more of a commentary on the perceived behavior of some individuals within a group.\n",
      "\n",
      "Output: 0 (Normal)\n",
      "Sample 969 Results:  Output: 0\n",
      "\n",
      "Reasoning: The statement does not mention or devalue any protected groups based on gender, race, sexuality, religion, or disability. It's simply an expression of disapproval towards the individual named \"courtois\". While it may be perceived as negative, it doesn't qualify as hatespeech or offensive speech.\n",
      "Sample 970 Results:  The provided text does not directly mention or involve devaluation of protected groups linking to gender, race, sexuality, religion, or disability. However, it does contain potentially offensive language and stereotypes, such as the use of \"ghetto\" in a negative context. This can be interpreted as reinforcing harmful stereotypes about certain communities.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 971 Results:  The provided text seems to be criticizing certain groups, including \"far right,\" \"neo-nazi,\" \"Islamic,\" and \"corporate.\" However, it does not explicitly devalue or attack these groups based on their race, gender, sexuality, religion, or disability. Instead, it appears to be a political commentary or conspiracy theory.\n",
      "\n",
      "Therefore, according to the provided classification system, this text would be classified as '0' - Normal. However, it's important to note that the interpretation of such texts can vary greatly depending on context and personal beliefs. This classification is based solely on the provided statement without considering any additional information or context.\n",
      "Sample 972 Results:  Output: 0\n",
      "\n",
      "Reasoning: The text is a humorous comparison between two types of bread and expresses a personal preference for white bread over wheat. It does not involve devaluation or direct an attack on any protected group, race, gender, sexuality, religion, or disability. Instead, it is a light-hearted statement that can be interpreted as a joke or sarcasm.\n",
      "Sample 973 Results:  The provided text \"i just found out my term is called queer curious so basically no one likes my type but the girls low key live âœ¨\" does not specifically target or devalue a protected group. It seems to be about self-discovery and personal feelings, albeit with some use of slang (\"low key\"). Therefore, based on the provided classification system, the output would be:\n",
      "\n",
      "Output (number only): 0\n",
      "Sample 974 Results:  The provided text contains multiple derogatory terms and offensive language towards various groups, including racial slurs (\"kikes\", \"sandniggers\"), religious slurs (\"worthless\"), and ethnic slurs (\"kebab\"). It also shows disregard for human rights issues, such as the beheading of children. This text can be classified as 'Hatespeech' (2) due to its intent to devalue and attack multiple protected groups based on race, religion, and ethnicity.\n",
      "Sample 975 Results:  The provided text is: \"we should kill a white person every day until the Grenfell residents are housed in mansions huffington post blogs\"\n",
      "\n",
      "Reasoning: This text directly targets a specific race (white people) and suggests violence against them, which is a clear form of hate speech. It also implies that the lives of white people can be sacrificed for the benefit of others, devaluing white lives in the process. Furthermore, it's important to note that the reference to Grenfell Tower fire tragedy is being exploited to justify this hateful sentiment.\n",
      "\n",
      "Output: 2 (Hatespeech)\n",
      "Sample 976 Results:  The provided text does not specifically target any protected group based on gender, race, sexuality, religion, or disability. Instead, it seems to be discussing a particular behavior or attitude associated with certain individuals (those who shame others). Therefore, the output would be '0' as this text can't be interpreted as hatespeech.\n",
      "Sample 977 Results:  The provided text does not explicitly mention or devalue a protected group based on gender, race, sexuality, religion, or disability. However, it seems to imply a stereotype about Muslim women and their behavior, which could be perceived as offensive or disrespectful.\n",
      "\n",
      "Reasoning: While the statement is factually incorrect (Muslim women can walk before men in many cultures and societies), it suggests a generalization that may not accurately represent all Muslim women. This could potentially lead to misunderstandings or negative perceptions about this group.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 978 Results:  The provided text contains multiple instances of hate speech and offensive language. It targets protected groups such as Muslims, LGBTQ+ individuals, and women (implied by \"the queers\"). The text also includes derogatory slurs (\"faggots\") and dehumanizing language (\"godless filthy bunch\"). Therefore, the output for this text would be: 2 (Hatespeech)\n",
      "Sample 979 Results:  The provided text is: \"fuck her she nothing but a kike that will play which ever side that will get her paid\"\n",
      "\n",
      "Reasoning: This text uses the derogatory term \"kike,\" which is historically and currently offensive towards Jewish people. It also implies that the person being referred to is manipulative, which can be seen as devaluing. Therefore, this text fits the definition of 'Hatespeech'.\n",
      "\n",
      "Output: 2\n",
      "Sample 980 Results:  The provided text, \"my wife and i agree <percent> let mother nature cull the nigger herd,\" clearly involves devaluation of a protected group based on race. It suggests a desire for violence or elimination towards black people, which is a direct attack. Therefore, the output should be '2' indicating Hatespeech.\n",
      "Sample 981 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The text does not mention or devalue any protected groups, nor is it used as an insult against individuals. It appears to be a descriptive narrative about a picture.\n",
      "Sample 982 Results:  Output: 0\n",
      "\n",
      "Reasoning: The text expresses a personal belief about religion, specifically stating that the user considers Islam to be the true religion. It also mentions respect for other religions, which suggests an inclusive and tolerant attitude. There is no evidence of devaluation or direct attack towards any protected group in this statement.\n",
      "Sample 983 Results:  The provided text does not explicitly mention or devalue any protected groups based on gender, race, sexuality, religion, or disability. However, it does contain a threat of violence (\"threatening to rape\") which is generally considered inappropriate and offensive.\n",
      "\n",
      "Reasoning: While the user seems to be discussing a specific individual (presumably \"syntche\"), the text does not target any protected groups directly. The laughter emojis could be interpreted as mocking or belittling, but without additional context, it's hard to definitively classify the intent. However, the threat of violence is unacceptable and offensive.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 984 Results:  The provided text is: \"will all of the white people who want to move to a ghetto or third world country please raise your hand\"\n",
      "\n",
      "Reasoning: This text seems to be making a generalization about white people, suggesting they might want to move to dangerous or impoverished areas. However, it does not directly devalue or attack any specific protected group based on race, gender, sexuality, religion, or disability. Instead, it appears to be more of a sarcastic or mocking commentary towards a perceived behavior or preference of white people.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 985 Results:  The provided text \"fellas would you fuck a bitch with no arms\" can be considered offensive due to the derogatory language used towards women. However, it does not specifically target a protected group based on gender, race, sexuality, religion, or disability in a way that devalues them. Therefore, the output should be 1 (Offensive).\n",
      "\n",
      "Reasoning: The text uses derogatory terms (\"bitch\") and objectifies women by asking about their physical appearance and sexual desirability. While it does not explicitly target a specific group based on race, sexuality, religion, or disability, the language used is disrespectful and demeaning towards women in general. It's important to note that such language can contribute to harmful attitudes and behaviors towards women.\n",
      "Sample 986 Results:  This text seems to be discussing a population issue, expressing frustration with overpopulation and the potential increase in refugees. The term \"bachhe\" (children) is used, but it doesn't specifically target any protected group based on gender, race, sexuality, religion, or disability. However, the phrase \"refugee bhi u want\" could be interpreted as offensive due to its dismissive tone towards refugees.\n",
      "\n",
      "However, the text does not involve devaluation of these groups, and it's main intent doesn't seem to be an attack on any specific group. Therefore, I would classify this text as '1 - Offensive'.\n",
      "Sample 987 Results:  The provided text is \"welp gave the negro too much credit because he currently ruining my bath by coming in here taking a shit.\"\n",
      "\n",
      "Reasoning: This text uses the racial slur \"negro,\" which is highly offensive towards black people. It also devalues and attacks the individual being referred to, as they are accused of ruining someone's bath. Therefore, it can be classified as 'Hatespeech'.\n",
      "\n",
      "Output: 2\n",
      "Sample 988 Results:  The provided text uses the term \"little nigger,\" which is highly offensive and derogatory towards black people. However, in this context, it seems to be used as an insult against the user, rather than a general attack on all black people. Therefore, while it's still offensive, it might not necessarily fall under the category of 'Hatespeech'.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 989 Results:  The provided text seems to be targeting a specific group, Islamic Jihadis. However, it's important to note that not all Muslims are Jihadis, and the term \"Islamic\" could potentially be used to devalue or stereotype all Muslims. Therefore, this text might be interpreted as having the potential for hate speech towards a protected group (religion).\n",
      "\n",
      "Output: 2 (Hatespeech)\n",
      "Sample 990 Results:  The text \"i have offered quite a few constructive and gentle criticisms of her kike face and it modern art paint shellacking ðŸ˜¬ buffalo bill was not very appreciative\" contains the term \"kike\", which is historically and currently used as an anti-Semitic slur. Therefore, this text can be classified as 'Hatespeech' (2). The use of \"constructive and gentle criticisms\" does not change the fact that the term \"kike\" is being used in a derogatory manner towards Jewish people.\n",
      "Sample 991 Results:  The provided text does not mention any protected groups, gender, race, sexuality, religion, or disability. It is a common phrase that expresses dislike or anger. Therefore, the output would be '0' as it can't be interpreted as hatespeech.\n",
      "Sample 992 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The text expresses positive sentiments towards making new friends, specifically mentioning the desire to make friends with someone who identifies as queer. It does not involve devaluation or direct attacks on any protected groups. Instead, it is a friendly and inclusive invitation.\n",
      "Sample 993 Results:  The provided text \"the only people that hang outside of rofo are ghetto people and old men with there yee yee trucks\" can be interpreted as offensive due to the use of the term \"ghetto\", which may be perceived as devaluing or stereotyping a certain group of people, typically associated with lower-income urban neighborhoods. However, it does not specifically target a protected group based on race, gender, sexuality, religion, or disability.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 994 Results:  Based on the provided criteria, this text does not seem to involve devaluation or direct attacks towards any protected groups. It appears to be a statement about continuing to expose cyberstalking and harassment. Therefore, the output would be '0' for 'Normal'. However, it's important to note that context can sometimes influence the interpretation of texts. If this text is part of a larger conversation or if it's used in a threatening or aggressive manner, it could potentially change the classification. But based on the provided text alone, it seems normal.\n",
      "Sample 995 Results:  The provided text seems to express opposition towards certain concepts, including Sharia law and specific political groups such as the Muslim Brotherhood. However, it does not explicitly devalue or attack a protected group based on race, gender, sexuality, religion, or disability. Therefore, according to the given classification system, this text would be classified as '1' (Offensive).\n",
      "\n",
      "However, it's important to note that the context and tone of the text can significantly influence its interpretation. In this case, the text could potentially be perceived as hostile towards Muslims due to the repeated mention of Muslim-related terms. While it doesn't directly devalue or attack individuals based on their religion, it does express strong opposition to certain religious concepts, which some might find offensive.\n",
      "\n",
      "In a broader sense, it's crucial to remember that any form of speech that incites hatred, violence, or discrimination against protected groups should be considered inappropriate and addressed accordingly.\n",
      "Sample 996 Results:  In this case, the text \"you know how retarded it is to get a â€˜iâ€™m coming to you as a womanâ€™ dm at the age of <number> ðŸ˜­ ðŸ˜­ ðŸ˜­\" does not specifically target or devalue women. The word \"retarded\" is often used in a derogatory manner towards people with intellectual disabilities, but in this context, it seems to be used metaphorically to express frustration rather than as an attack on a specific group. Therefore, the output would be 1 (Offensive). However, if the number were included, it could potentially change the interpretation of the text, making it more specific and possibly moving it towards the Hatespeech category. For example, if the number were very young, it might imply that the sender finds it inappropriate for someone of that age to express romantic interest, which could be seen as devaluing or targeting women. In such a case, the output might be 2 (Hatespeech). Without the number, it's hard to definitively classify it as Hatespeech.\n",
      "Sample 997 Results:  Output: 2\n",
      "\n",
      "Reasoning: The text explicitly targets people of color, specifically \"paki\" and \"nigger,\" and devalues them by suggesting they are used as tokens to manipulate public opinion and hide underlying racism. This is a clear example of hate speech directed at protected groups based on race.\n",
      "Sample 998 Results:  2\n",
      "\n",
      "Reasoning: The text directly targets and devalues a specific racial group (Asians) by making false claims about their intelligence, using derogatory terms like \"commie chinks,\" and promoting racist ideologies. This is considered hate speech.\n",
      "Sample 999 Results:  The provided text seems to contain derogatory and offensive language towards Muslims, which could be interpreted as an attempt to devalue or attack a protected group based on religion. However, it's important to note that the text does not explicitly call for violence or harm against individuals or the group as a whole.\n",
      "\n",
      "To classify this text, we should consider the intent and impact of the language used. While the text is offensive and disrespectful, it might not necessarily fall under the category of 'Hatespeech' because it doesn't directly incite violence or dehumanize Muslims.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 1000 Results:  The provided text \"hoe you can not touch this\" does not specifically mention or devalue any protected groups based on gender, race, sexuality, religion, or disability. It is a common phrase used in popular culture, often associated with hip-hop music and movies, and is typically used as a boastful statement rather than an insult. Therefore, the output would be 0 (Normal).\n",
      "Sample 1001 Results:  The provided text contains derogatory language towards people of Muslim faith, referring to them as \"savage 3rd world cretins,\" and also uses the term \"muzzie\" which is a pejorative slur. It also implies that all Muslims are responsible for the alleged crimes committed by some individuals, which can be seen as devaluing and attacking a protected group based on religion. Therefore, the output should be '2' indicating Hatespeech.\n",
      "Sample 1002 Results:  The provided text \"imagine thinking that fat dyke in dallas a better rb than kamara lmfao\" can be interpreted as offensive due to the use of derogatory terms towards women, specifically lesbians (\"dyke\"), and potentially towards overweight individuals (\"fat\"). However, it does not specifically target a protected group based on gender or sexuality with the intent to devalue them. Therefore, the output would be 1 (Offensive).\n",
      "Sample 1003 Results:  The provided text \"<user> nice ching chong hat\" can be interpreted as offensive due to the use of racial slurs associated with Asian people, specifically \"ching chong\". However, it does not directly involve devaluation or an attack on a protected group. Therefore, the output would be 1 (Offensive).\n",
      "Sample 1004 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The text criticizes Justin Trudeau's actions, specifically his inability to differentiate between ISIS fighters and regular refugees. It does not involve devaluation or direct attacks on any protected groups such as race, gender, sexuality, religion, or disability. Instead, it is a political commentary about the leader's performance in office.\n",
      "Sample 1005 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The text expresses a need for awareness campaign, shows empathy towards internally displaced persons (IDPs), and does not use derogatory or devaluing language towards any protected group. It is important to note that the term \"refugee\" is used in a factual context, referring to people who have been forced to leave their homes due to circumstances beyond their control. The text does not contain any hate speech or offensive language.\n",
      "Sample 1006 Results:  The provided text \"oh i got these vegas dykes mad today\" can be interpreted as using a derogatory term for lesbians (\"dykes\"). However, it does not specifically devalue or attack them based on their sexuality. It seems to be expressing that some lesbians in Vegas are upset with the speaker.\n",
      "\n",
      "Output: 1 (Offensive)\n",
      "Sample 1007 Results:  0 (Normal)\n",
      "\n",
      "Reasoning: The provided text does not mention or devalue any protected groups based on gender, race, sexuality, religion, or disability. It seems to be an expression of frustration or anger, but it doesn't contain any hateful or offensive language towards these groups.\n"
     ]
    }
   ],
   "source": [
    "# There have been outputs that are invalid causing the prediction to not be tracked. This is to see why that is.\n",
    "for i in range(len(reasoning_after_fewshot_eng)):\n",
    "    print(f\"Sample {i} Results: {reasoning_after_fewshot_eng[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62c1efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.540\n",
      "Precision: 0.608\n",
      "Recall: 0.608\n",
      "F1 score: 0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zhongxian\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Importing libraries\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#The following is printing out the results to be analysed.\n",
    "acc = accuracy_score(data_labels, y_pred_after_fewshot_eng)\n",
    "precision, recall, f1, support = precision_recall_fscore_support(y_true=data_labels,y_pred=y_pred_after_fewshot_eng, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {acc:.3f}\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall: {recall:.3f}\")\n",
    "print(f\"F1 score: {f1:.3f}\")\n",
    "\n",
    "con_matrix = confusion_matrix(data_labels, y_pred_after_fewshot_eng)\n",
    "disp = ConfusionMatrixDisplay(con_matrix, display_labels=['Missing', 'Normal', 'Offensive', 'Hatespeech'])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
